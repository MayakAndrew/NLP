{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "09c6b555",
      "metadata": {
        "id": "09c6b555"
      },
      "source": [
        "### Тема «POS-tagger и NER»"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "752064c5",
      "metadata": {
        "id": "752064c5"
      },
      "source": [
        "**Задание 1. Написать теггер на данных с русским языком.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54b2bf4b",
      "metadata": {
        "id": "54b2bf4b"
      },
      "source": [
        "1. проверить UnigramTagger, BigramTagger, TrigramTagger и их комбинации.\n",
        "2. написать свой теггер как на занятии, попробовать разные векторайзеры, добавить знание не только букв но и слов.\n",
        "3. сравнить все реализованные методы, сделать выводы.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "472097f2",
      "metadata": {
        "id": "472097f2"
      },
      "source": [
        "**Задание 2. Проверить, насколько хорошо работает NER.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0466dd1",
      "metadata": {
        "id": "e0466dd1"
      },
      "source": [
        "1. проверить NER из nltk/spacy/deeppavlov."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d105d23",
      "metadata": {
        "id": "9d105d23"
      },
      "source": [
        "2. написать свой NER, попробовать разные подходы."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07fb226f",
      "metadata": {
        "id": "07fb226f"
      },
      "source": [
        "*a. передаём в сетку токен и его соседей.*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6b3952d",
      "metadata": {
        "id": "b6b3952d"
      },
      "source": [
        "*b. передаём в сетку только токен.*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d7b680e",
      "metadata": {
        "id": "0d7b680e"
      },
      "source": [
        "*c. свой вариант.*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "817fb742",
      "metadata": {
        "id": "817fb742"
      },
      "source": [
        "3. сравнить свои реализованные подходы на качество — вывести precision/recall/f1_score."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "146f889e",
      "metadata": {
        "id": "146f889e"
      },
      "source": [
        "### Задание 1."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c430b1f",
      "metadata": {
        "id": "4c430b1f"
      },
      "source": [
        "**Загрузим необходимые библиотеки и данные.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2425ed0a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2425ed0a",
        "outputId": "526cb1b6-c7b7-407a-eca7-04c3a8cde93c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyconll in /usr/local/lib/python3.10/dist-packages (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyconll"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f29a589a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f29a589a",
        "outputId": "c05100ac-9a3c-480c-bf4a-ceac7f91dc6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-16 10:20:06--  https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-train-a.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 40736581 (39M) [text/plain]\n",
            "Saving to: ‘ru_syntagrus-ud-train.conllu’\n",
            "\n",
            "ru_syntagrus-ud-tra 100%[===================>]  38.85M   200MB/s    in 0.2s    \n",
            "\n",
            "2023-10-16 10:20:07 (200 MB/s) - ‘ru_syntagrus-ud-train.conllu’ saved [40736581/40736581]\n",
            "\n",
            "--2023-10-16 10:20:07--  https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-dev.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14704579 (14M) [text/plain]\n",
            "Saving to: ‘ru_syntagrus-ud-dev.conllu’\n",
            "\n",
            "ru_syntagrus-ud-dev 100%[===================>]  14.02M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-10-16 10:20:08 (119 MB/s) - ‘ru_syntagrus-ud-dev.conllu’ saved [14704579/14704579]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O ru_syntagrus-ud-train.conllu https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-train-a.conllu\n",
        "!wget -O ru_syntagrus-ud-dev.conllu https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-dev.conllu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1b9148fc",
      "metadata": {
        "id": "1b9148fc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import pyconll\n",
        "import nltk\n",
        "from nltk.tag import DefaultTagger, UnigramTagger, BigramTagger, TrigramTagger, RegexpTagger\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4daf456d",
      "metadata": {
        "id": "4daf456d"
      },
      "outputs": [],
      "source": [
        "data_train = pyconll.load_from_file('ru_syntagrus-ud-train.conllu')\n",
        "data_test = pyconll.load_from_file('ru_syntagrus-ud-dev.conllu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f171783e",
      "metadata": {
        "id": "f171783e"
      },
      "outputs": [],
      "source": [
        "fdata_train = []\n",
        "for sent in data_train[:]:\n",
        "    fdata_train.append([(token.form, token.upos) for token in sent])\n",
        "\n",
        "fdata_test = []\n",
        "for sent in data_test[:]:\n",
        "    fdata_test.append([(token.form, token.upos) for token in sent])\n",
        "\n",
        "fdata_sent_test = []\n",
        "for sent in data_test[:]:\n",
        "    fdata_sent_test.append([token.form for token in sent])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "80a1fd46",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80a1fd46",
        "outputId": "f80355b6-d6a0-4f2e-c8e1-5980f924ede6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24516, 8906, 8906)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "len(fdata_train), len(fdata_test), len(fdata_sent_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "849d0189",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "849d0189",
        "outputId": "55415817-db28-4a9d-864c-ee7f660a1e52"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('Анкета', 'NOUN'), ('.', 'PUNCT')],\n",
              " [('Начальник', 'NOUN'),\n",
              "  ('областного', 'ADJ'),\n",
              "  ('управления', 'NOUN'),\n",
              "  ('связи', 'NOUN'),\n",
              "  ('Семен', 'PROPN'),\n",
              "  ('Еремеевич', 'PROPN'),\n",
              "  ('был', 'AUX'),\n",
              "  ('человек', 'NOUN'),\n",
              "  ('простой', 'ADJ'),\n",
              "  (',', 'PUNCT'),\n",
              "  ('приходил', 'VERB'),\n",
              "  ('на', 'ADP'),\n",
              "  ('работу', 'NOUN'),\n",
              "  ('всегда', 'ADV'),\n",
              "  ('вовремя', 'ADV'),\n",
              "  (',', 'PUNCT'),\n",
              "  ('здоровался', 'VERB'),\n",
              "  ('с', 'ADP'),\n",
              "  ('секретаршей', 'NOUN'),\n",
              "  ('за', 'ADP'),\n",
              "  ('руку', 'NOUN'),\n",
              "  ('и', 'CCONJ'),\n",
              "  ('иногда', 'ADV'),\n",
              "  ('даже', 'PART'),\n",
              "  ('писал', 'VERB'),\n",
              "  ('в', 'ADP'),\n",
              "  ('стенгазету', 'NOUN'),\n",
              "  ('заметки', 'NOUN'),\n",
              "  ('под', 'ADP'),\n",
              "  ('псевдонимом', 'NOUN'),\n",
              "  ('\"', 'PUNCT'),\n",
              "  ('Муха', 'NOUN'),\n",
              "  ('\"', 'PUNCT'),\n",
              "  ('.', 'PUNCT')]]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "fdata_train[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64ce401f",
      "metadata": {
        "id": "64ce401f"
      },
      "source": [
        "**Проверим работу всех теггеров поочередно.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "5a2e767e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a2e767e",
        "outputId": "7f5329f7-cbc3-411c-b9f4-621f5d7d201a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:\n",
            "Default Tagger: 0.0,\n",
            "Unigram Tagger: 0.824,\n",
            "Bigram Tagger: 0.60939,\n",
            "Trigram Tagger: 0.178,\n",
            "Bigram and Unigram Tagger: 0.82928,\n",
            "Trigram, Bigram and Unigram Tagger: 0.82914,\n",
            "\n"
          ]
        }
      ],
      "source": [
        "default_tagger = nltk.DefaultTagger('NN')\n",
        "default_acc = default_tagger.evaluate(fdata_test)\n",
        "\n",
        "unigram_tagger = UnigramTagger(fdata_train)\n",
        "unigram_acc = unigram_tagger.evaluate(fdata_test)\n",
        "\n",
        "bigram_tagger = BigramTagger(fdata_train)\n",
        "bigram_acc = bigram_tagger.evaluate(fdata_test)\n",
        "\n",
        "trigram_tagger = TrigramTagger(fdata_train)\n",
        "trigram_acc = trigram_tagger.evaluate(fdata_test)\n",
        "\n",
        "bigram_tagger = BigramTagger(fdata_train, backoff=unigram_tagger)\n",
        "bigram_unigram_acc = bigram_tagger.evaluate(fdata_test)\n",
        "\n",
        "trigram_tagger = TrigramTagger(fdata_train, backoff=bigram_tagger)\n",
        "trigram_bigram_unigram_acc = trigram_tagger.evaluate(fdata_test)\n",
        "\n",
        "print(f'Accuracy:\\nDefault Tagger: {round(default_acc, 3)},\\nUnigram Tagger: {round(unigram_acc, 3)},\\nBigram Tagger: {round(bigram_acc, 5)},\\n'\n",
        "      f'Trigram Tagger: {round(trigram_acc, 3)},\\nBigram and Unigram Tagger: {round(bigram_unigram_acc, 5)},\\n'\n",
        "      f'Trigram, Bigram and Unigram Tagger: {round(trigram_bigram_unigram_acc, 5)},\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c24e279e",
      "metadata": {
        "id": "c24e279e"
      },
      "source": [
        "**Различные комбинации теггеров могут давать прирост качества.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bd8e481",
      "metadata": {
        "id": "7bd8e481"
      },
      "source": [
        "**Для эксперимента попробуем объединить работу всех теггеров с помощью функции.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "4c5a6181",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c5a6181",
        "outputId": "19de2aa8-72d9-466c-bd64-f5a948b1d4fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.827905462595221"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "def union_taggers(train_sents, tagger_classes, backoff=None):\n",
        "    for cls in tagger_classes:\n",
        "        backoff = cls(train_sents, backoff=backoff)\n",
        "    return backoff\n",
        "\n",
        "\n",
        "backoff = DefaultTagger('NN')\n",
        "tag = union_taggers(fdata_train,\n",
        "                     [UnigramTagger, BigramTagger, TrigramTagger],\n",
        "                     backoff = backoff)\n",
        "\n",
        "tag.evaluate(fdata_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f3180f4",
      "metadata": {
        "id": "1f3180f4"
      },
      "source": [
        "**Получили некий усредненный результат. Не самый высокий.**\n",
        "**ВЫВОД: на каждом корпусе пробовать все варианты и выбирать наилучший.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64f5b4c7",
      "metadata": {
        "id": "64f5b4c7"
      },
      "source": [
        "### Попробуем написать теггер."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "25363624",
      "metadata": {
        "id": "25363624"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef89f288",
      "metadata": {
        "id": "ef89f288"
      },
      "source": [
        "**Преобразуем тренировочный датасет в списки слов и списки POS-разметки.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "580036e9",
      "metadata": {
        "id": "580036e9"
      },
      "outputs": [],
      "source": [
        "train_tok = []\n",
        "train_label = []\n",
        "for sent in fdata_train[:]:\n",
        "    for tok in sent:\n",
        "        train_tok.append(tok[0])\n",
        "        train_label.append('NO_TAG' if tok[1] is None else tok[1])\n",
        "\n",
        "test_tok = []\n",
        "test_label = []\n",
        "for sent in fdata_test[:]:\n",
        "    for tok in sent:\n",
        "        test_tok.append(' ' if tok[0] is None else tok[0])\n",
        "        test_label.append('NO_TAG' if tok[1] is None else tok[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a54080ac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a54080ac",
        "outputId": "a9e75665-4735-4c9d-c01b-26b2691d3b5b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Анкета', '.', 'Начальник', 'областного', 'управления', 'связи', 'Семен'],\n",
              " ['NOUN', 'PUNCT', 'NOUN', 'ADJ', 'NOUN', 'NOUN', 'PROPN'])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "train_tok[:7], train_label[:7]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "76b46219",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76b46219",
        "outputId": "2fb88e8f-b116-4270-ec33-33dd86b801c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7, 13,  7, ...,  1, 11, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "le = LabelEncoder()\n",
        "train_enc_labels = le.fit_transform(train_label)\n",
        "train_enc_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "e2e4861a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2e4861a",
        "outputId": "1ef10552-c489-4651-b4ec-63de5be0719e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7, 13,  1, ...,  0,  7, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "test_enc_labels = le.transform(test_label)\n",
        "test_enc_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "075c4e47",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "075c4e47",
        "outputId": "fbac11cb-f689-4f26-c0ea-8e926388bce3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN',\n",
              "       'NO_TAG', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SYM',\n",
              "       'VERB', 'X'], dtype='<U6')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "le.classes_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "824b4045",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "824b4045",
        "outputId": "d372c488-8dd6-46f9-f74f-8b8eefc2044a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
            "Wall time: 4.77 µs\n",
            "CountVectorizer(analyzer='char', ngram_range=(1, 5))\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ADJ       0.94      0.92      0.93     15103\n",
            "         ADP       0.98      1.00      0.99     13717\n",
            "         ADV       0.91      0.93      0.92      7783\n",
            "         AUX       0.82      0.96      0.88      1390\n",
            "       CCONJ       0.89      0.97      0.93      5672\n",
            "         DET       0.83      0.79      0.81      4265\n",
            "        INTJ       0.39      0.29      0.33        24\n",
            "        NOUN       0.94      0.97      0.96     36238\n",
            "      NO_TAG       1.00      0.77      0.87       265\n",
            "         NUM       0.86      0.89      0.88      1734\n",
            "        PART       0.95      0.77      0.85      5125\n",
            "        PRON       0.90      0.84      0.87      7444\n",
            "       PROPN       0.84      0.66      0.73      5473\n",
            "       PUNCT       1.00      1.00      1.00     29186\n",
            "       SCONJ       0.75      0.97      0.85      2865\n",
            "         SYM       1.00      0.85      0.92        62\n",
            "        VERB       0.97      0.96      0.96     17110\n",
            "           X       0.43      0.07      0.13       134\n",
            "\n",
            "    accuracy                           0.94    153590\n",
            "   macro avg       0.86      0.81      0.82    153590\n",
            "weighted avg       0.94      0.94      0.94    153590\n",
            "\n",
            "TfidfVectorizer(analyzer='char', ngram_range=(1, 5))\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ADJ       0.92      0.91      0.92     15103\n",
            "         ADP       0.99      1.00      0.99     13717\n",
            "         ADV       0.92      0.89      0.90      7783\n",
            "         AUX       0.82      0.97      0.88      1390\n",
            "       CCONJ       0.89      0.97      0.93      5672\n",
            "         DET       0.89      0.70      0.78      4265\n",
            "        INTJ       0.00      0.00      0.00        24\n",
            "        NOUN       0.91      0.97      0.94     36238\n",
            "      NO_TAG       1.00      0.77      0.87       265\n",
            "         NUM       0.85      0.90      0.87      1734\n",
            "        PART       0.94      0.78      0.85      5125\n",
            "        PRON       0.86      0.89      0.87      7444\n",
            "       PROPN       0.81      0.54      0.65      5473\n",
            "       PUNCT       1.00      1.00      1.00     29186\n",
            "       SCONJ       0.76      0.97      0.85      2865\n",
            "         SYM       1.00      0.85      0.92        62\n",
            "        VERB       0.95      0.93      0.94     17110\n",
            "           X       0.25      0.15      0.19       134\n",
            "\n",
            "    accuracy                           0.93    153590\n",
            "   macro avg       0.82      0.79      0.80    153590\n",
            "weighted avg       0.93      0.93      0.93    153590\n",
            "\n",
            "HashingVectorizer(analyzer='char', n_features=1000, ngram_range=(1, 5))\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ADJ       0.82      0.80      0.81     15103\n",
            "         ADP       0.97      0.99      0.98     13717\n",
            "         ADV       0.81      0.79      0.80      7783\n",
            "         AUX       0.81      0.96      0.88      1390\n",
            "       CCONJ       0.87      1.00      0.93      5672\n",
            "         DET       0.82      0.76      0.79      4265\n",
            "        INTJ       0.00      0.00      0.00        24\n",
            "        NOUN       0.81      0.89      0.85     36238\n",
            "      NO_TAG       1.00      0.77      0.87       265\n",
            "         NUM       0.82      0.80      0.81      1734\n",
            "        PART       0.96      0.74      0.83      5125\n",
            "        PRON       0.84      0.87      0.86      7444\n",
            "       PROPN       0.65      0.37      0.47      5473\n",
            "       PUNCT       1.00      1.00      1.00     29186\n",
            "       SCONJ       0.80      0.90      0.85      2865\n",
            "         SYM       1.00      0.69      0.82        62\n",
            "        VERB       0.85      0.81      0.83     17110\n",
            "           X       0.23      0.04      0.06       134\n",
            "\n",
            "    accuracy                           0.87    153590\n",
            "   macro avg       0.78      0.73      0.75    153590\n",
            "weighted avg       0.87      0.87      0.87    153590\n",
            "\n",
            "CountVectorizer(ngram_range=(1, 5))\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ADJ       0.92      0.41      0.57     15103\n",
            "         ADP       0.99      0.48      0.64     13717\n",
            "         ADV       0.91      0.76      0.83      7783\n",
            "         AUX       0.84      0.87      0.85      1390\n",
            "       CCONJ       0.73      0.20      0.32      5672\n",
            "         DET       0.85      0.64      0.73      4265\n",
            "        INTJ       0.00      0.00      0.00        24\n",
            "        NOUN       0.98      0.71      0.82     36238\n",
            "      NO_TAG       0.00      0.00      0.00       265\n",
            "         NUM       0.87      0.56      0.68      1734\n",
            "        PART       0.97      0.67      0.79      5125\n",
            "        PRON       0.84      0.80      0.82      7444\n",
            "       PROPN       0.92      0.16      0.27      5473\n",
            "       PUNCT       0.38      1.00      0.55     29186\n",
            "       SCONJ       0.72      0.85      0.78      2865\n",
            "         SYM       0.00      0.00      0.00        62\n",
            "        VERB       0.97      0.44      0.60     17110\n",
            "           X       0.00      0.00      0.00       134\n",
            "\n",
            "    accuracy                           0.65    153590\n",
            "   macro avg       0.66      0.47      0.51    153590\n",
            "weighted avg       0.82      0.65      0.66    153590\n",
            "\n",
            "TfidfVectorizer(ngram_range=(1, 5))\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ADJ       0.93      0.41      0.57     15103\n",
            "         ADP       0.99      0.48      0.64     13717\n",
            "         ADV       0.94      0.78      0.85      7783\n",
            "         AUX       0.84      0.87      0.85      1390\n",
            "       CCONJ       0.88      0.20      0.33      5672\n",
            "         DET       0.84      0.68      0.75      4265\n",
            "        INTJ       0.00      0.00      0.00        24\n",
            "        NOUN       0.98      0.65      0.78     36238\n",
            "      NO_TAG       0.00      0.00      0.00       265\n",
            "         NUM       0.88      0.55      0.68      1734\n",
            "        PART       0.97      0.73      0.83      5125\n",
            "        PRON       0.83      0.82      0.82      7444\n",
            "       PROPN       0.93      0.15      0.25      5473\n",
            "       PUNCT       0.37      1.00      0.54     29186\n",
            "       SCONJ       0.78      0.85      0.82      2865\n",
            "         SYM       0.00      0.00      0.00        62\n",
            "        VERB       0.97      0.44      0.60     17110\n",
            "           X       0.00      0.00      0.00       134\n",
            "\n",
            "    accuracy                           0.64    153590\n",
            "   macro avg       0.67      0.48      0.52    153590\n",
            "weighted avg       0.83      0.64      0.65    153590\n",
            "\n",
            "HashingVectorizer(n_features=1000, ngram_range=(1, 5))\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ADJ       0.41      0.20      0.27     15103\n",
            "         ADP       0.83      0.47      0.60     13717\n",
            "         ADV       0.56      0.62      0.59      7783\n",
            "         AUX       0.72      0.86      0.78      1390\n",
            "       CCONJ       0.88      0.18      0.29      5672\n",
            "         DET       0.49      0.65      0.56      4265\n",
            "        INTJ       0.00      0.00      0.00        24\n",
            "        NOUN       0.25      0.53      0.34     36238\n",
            "      NO_TAG       0.00      0.00      0.00       265\n",
            "         NUM       0.39      0.43      0.41      1734\n",
            "        PART       0.84      0.75      0.79      5125\n",
            "        PRON       0.68      0.68      0.68      7444\n",
            "       PROPN       0.28      0.08      0.12      5473\n",
            "       PUNCT       0.00      0.00      0.00     29186\n",
            "       SCONJ       0.66      0.96      0.78      2865\n",
            "         SYM       0.00      0.00      0.00        62\n",
            "        VERB       0.45      0.25      0.32     17110\n",
            "           X       0.00      0.00      0.00       134\n",
            "\n",
            "    accuracy                           0.36    153590\n",
            "   macro avg       0.41      0.37      0.36    153590\n",
            "weighted avg       0.39      0.36      0.34    153590\n",
            "\n",
            "HashingVectorizer(analyzer='char', n_features=2000, ngram_range=(1, 5))\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ADJ       0.86      0.86      0.86     15103\n",
            "         ADP       0.98      0.99      0.99     13717\n",
            "         ADV       0.87      0.82      0.84      7783\n",
            "         AUX       0.81      0.97      0.88      1390\n",
            "       CCONJ       0.89      0.97      0.93      5672\n",
            "         DET       0.83      0.77      0.80      4265\n",
            "        INTJ       0.00      0.00      0.00        24\n",
            "        NOUN       0.85      0.92      0.89     36238\n",
            "      NO_TAG       1.00      0.77      0.87       265\n",
            "         NUM       0.82      0.85      0.84      1734\n",
            "        PART       0.93      0.78      0.85      5125\n",
            "        PRON       0.85      0.87      0.86      7444\n",
            "       PROPN       0.69      0.41      0.52      5473\n",
            "       PUNCT       1.00      1.00      1.00     29186\n",
            "       SCONJ       0.81      0.90      0.85      2865\n",
            "         SYM       1.00      0.69      0.82        62\n",
            "        VERB       0.89      0.87      0.88     17110\n",
            "           X       0.30      0.04      0.08       134\n",
            "\n",
            "    accuracy                           0.90    153590\n",
            "   macro avg       0.80      0.75      0.76    153590\n",
            "weighted avg       0.89      0.90      0.89    153590\n",
            "\n",
            "HashingVectorizer(analyzer='char', n_features=3000, ngram_range=(1, 5))\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ADJ       0.87      0.87      0.87     15103\n",
            "         ADP       0.98      0.99      0.99     13717\n",
            "         ADV       0.88      0.84      0.86      7783\n",
            "         AUX       0.81      0.97      0.88      1390\n",
            "       CCONJ       0.88      0.98      0.93      5672\n",
            "         DET       0.85      0.76      0.80      4265\n",
            "        INTJ       0.00      0.00      0.00        24\n",
            "        NOUN       0.87      0.93      0.90     36238\n",
            "      NO_TAG       1.00      0.77      0.87       265\n",
            "         NUM       0.85      0.83      0.84      1734\n",
            "        PART       0.94      0.76      0.84      5125\n",
            "        PRON       0.83      0.87      0.85      7444\n",
            "       PROPN       0.73      0.42      0.53      5473\n",
            "       PUNCT       1.00      1.00      1.00     29186\n",
            "       SCONJ       0.81      0.90      0.85      2865\n",
            "         SYM       1.00      0.82      0.90        62\n",
            "        VERB       0.89      0.88      0.89     17110\n",
            "           X       0.53      0.06      0.11       134\n",
            "\n",
            "    accuracy                           0.90    153590\n",
            "   macro avg       0.82      0.76      0.77    153590\n",
            "weighted avg       0.90      0.90      0.90    153590\n",
            "\n",
            "HashingVectorizer(analyzer='char', n_features=5000, ngram_range=(1, 5))\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ADJ       0.88      0.89      0.89     15103\n",
            "         ADP       0.98      0.99      0.99     13717\n",
            "         ADV       0.90      0.84      0.87      7783\n",
            "         AUX       0.82      0.97      0.89      1390\n",
            "       CCONJ       0.89      0.97      0.93      5672\n",
            "         DET       0.88      0.72      0.79      4265\n",
            "        INTJ       0.00      0.00      0.00        24\n",
            "        NOUN       0.88      0.95      0.91     36238\n",
            "      NO_TAG       1.00      0.77      0.87       265\n",
            "         NUM       0.84      0.87      0.85      1734\n",
            "        PART       0.93      0.78      0.85      5125\n",
            "        PRON       0.83      0.90      0.86      7444\n",
            "       PROPN       0.79      0.46      0.58      5473\n",
            "       PUNCT       1.00      1.00      1.00     29186\n",
            "       SCONJ       0.81      0.90      0.85      2865\n",
            "         SYM       1.00      0.85      0.92        62\n",
            "        VERB       0.92      0.91      0.91     17110\n",
            "           X       0.29      0.07      0.12       134\n",
            "\n",
            "    accuracy                           0.91    153590\n",
            "   macro avg       0.81      0.77      0.78    153590\n",
            "weighted avg       0.91      0.91      0.91    153590\n",
            "\n",
            "HashingVectorizer(n_features=2000, ngram_range=(1, 5))\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ADJ       0.47      0.25      0.32     15103\n",
            "         ADP       0.89      0.47      0.62     13717\n",
            "         ADV       0.66      0.67      0.66      7783\n",
            "         AUX       0.75      0.94      0.84      1390\n",
            "       CCONJ       0.89      0.18      0.31      5672\n",
            "         DET       0.64      0.57      0.60      4265\n",
            "        INTJ       0.00      0.00      0.00        24\n",
            "        NOUN       0.60      0.57      0.59     36238\n",
            "      NO_TAG       0.00      0.00      0.00       265\n",
            "         NUM       0.50      0.48      0.49      1734\n",
            "        PART       0.91      0.74      0.82      5125\n",
            "        PRON       0.71      0.79      0.75      7444\n",
            "       PROPN       0.37      0.09      0.15      5473\n",
            "       PUNCT       0.48      1.00      0.65     29186\n",
            "       SCONJ       0.76      0.90      0.82      2865\n",
            "         SYM       0.00      0.00      0.00        62\n",
            "        VERB       0.54      0.30      0.38     17110\n",
            "           X       0.00      0.00      0.00       134\n",
            "\n",
            "    accuracy                           0.58    153590\n",
            "   macro avg       0.51      0.44      0.44    153590\n",
            "weighted avg       0.61      0.58      0.55    153590\n",
            "\n",
            "HashingVectorizer(n_features=3000, ngram_range=(1, 5))\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ADJ       0.53      0.28      0.36     15103\n",
            "         ADP       0.91      0.47      0.62     13717\n",
            "         ADV       0.75      0.69      0.72      7783\n",
            "         AUX       0.77      0.94      0.85      1390\n",
            "       CCONJ       0.93      0.18      0.30      5672\n",
            "         DET       0.71      0.53      0.61      4265\n",
            "        INTJ       0.00      0.00      0.00        24\n",
            "        NOUN       0.64      0.59      0.61     36238\n",
            "      NO_TAG       0.00      0.00      0.00       265\n",
            "         NUM       0.55      0.53      0.54      1734\n",
            "        PART       0.88      0.78      0.83      5125\n",
            "        PRON       0.74      0.82      0.78      7444\n",
            "       PROPN       0.43      0.11      0.18      5473\n",
            "       PUNCT       0.46      1.00      0.63     29186\n",
            "       SCONJ       0.73      0.95      0.82      2865\n",
            "         SYM       0.00      0.00      0.00        62\n",
            "        VERB       0.59      0.32      0.41     17110\n",
            "           X       0.00      0.00      0.00       134\n",
            "\n",
            "    accuracy                           0.59    153590\n",
            "   macro avg       0.54      0.45      0.46    153590\n",
            "weighted avg       0.64      0.59      0.57    153590\n",
            "\n",
            "HashingVectorizer(n_features=5000, ngram_range=(1, 5))\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ADJ       0.61      0.31      0.41     15103\n",
            "         ADP       0.92      0.48      0.63     13717\n",
            "         ADV       0.81      0.70      0.75      7783\n",
            "         AUX       0.81      0.86      0.83      1390\n",
            "       CCONJ       0.85      0.20      0.33      5672\n",
            "         DET       0.73      0.63      0.68      4265\n",
            "        INTJ       0.00      0.00      0.00        24\n",
            "        NOUN       0.69      0.60      0.64     36238\n",
            "      NO_TAG       0.00      0.00      0.00       265\n",
            "         NUM       0.63      0.49      0.55      1734\n",
            "        PART       0.96      0.72      0.82      5125\n",
            "        PRON       0.76      0.80      0.78      7444\n",
            "       PROPN       0.51      0.14      0.22      5473\n",
            "       PUNCT       0.44      1.00      0.61     29186\n",
            "       SCONJ       0.76      0.91      0.83      2865\n",
            "         SYM       0.00      0.00      0.00        62\n",
            "        VERB       0.66      0.35      0.46     17110\n",
            "           X       0.00      0.00      0.00       134\n",
            "\n",
            "    accuracy                           0.60    153590\n",
            "   macro avg       0.56      0.45      0.47    153590\n",
            "weighted avg       0.67      0.60      0.58    153590\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%time\n",
        "\n",
        "vectorizers = [CountVectorizer(ngram_range=(1, 5), analyzer='char'),\n",
        "               TfidfVectorizer(ngram_range=(1, 5), analyzer='char'),\n",
        "               HashingVectorizer(ngram_range=(1, 5), analyzer='char', n_features=1000)]\n",
        "vectorizers_word = [CountVectorizer(ngram_range=(1, 5), analyzer='word'),\n",
        "               TfidfVectorizer(ngram_range=(1, 5), analyzer='word'),\n",
        "               HashingVectorizer(ngram_range=(1, 5), analyzer='word', n_features=1000)]\n",
        "n_features = [2000, 3000, 5000]\n",
        "vectorizers_hash = [HashingVectorizer(ngram_range=(1, 5), analyzer='char', n_features=feat) for feat in n_features]\n",
        "vectorizers_hash_word = [HashingVectorizer(ngram_range=(1, 5), analyzer='word', n_features=feat) for feat in n_features]\n",
        "f1_scores = []\n",
        "accuracy_scores = []\n",
        "\n",
        "for vectorizer in vectorizers + vectorizers_word + vectorizers_hash + vectorizers_hash_word:\n",
        "    X_train = vectorizer.fit_transform(train_tok)\n",
        "    X_test = vectorizer.transform(test_tok)\n",
        "\n",
        "    lr = LogisticRegression(random_state=0, max_iter=100)\n",
        "    lr.fit(X_train, train_enc_labels)\n",
        "    pred = lr.predict(X_test)\n",
        "    f1 = f1_score(test_enc_labels, pred, average='weighted')\n",
        "    f1_scores.append(f1)\n",
        "    acc = accuracy_score(test_enc_labels, pred)\n",
        "    accuracy_scores.append(acc)\n",
        "\n",
        "    print(vectorizer)\n",
        "    print(classification_report(test_enc_labels, pred, target_names=le.classes_))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "995ef775",
      "metadata": {
        "id": "995ef775"
      },
      "source": [
        "**Для удобства представим данные в виде таблицы:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "58394e33",
      "metadata": {
        "id": "58394e33"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.expand_frame_repr', False)\n",
        "pd.set_option('max_colwidth', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "dd3a78e1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "dd3a78e1",
        "outputId": "01b18fab-f5f5-48db-d0a6-c14689791e1b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                 Vectorizer  f1_score\n",
              "0                      CountVectorizer(analyzer='char', ngram_range=(1, 5))  0.938119\n",
              "1                      TfidfVectorizer(analyzer='char', ngram_range=(1, 5))  0.926643\n",
              "8   HashingVectorizer(analyzer='char', n_features=5000, ngram_range=(1, 5))  0.909308\n",
              "7   HashingVectorizer(analyzer='char', n_features=3000, ngram_range=(1, 5))  0.898656\n",
              "6   HashingVectorizer(analyzer='char', n_features=2000, ngram_range=(1, 5))  0.892840\n",
              "2   HashingVectorizer(analyzer='char', n_features=1000, ngram_range=(1, 5))  0.866909\n",
              "3                                       CountVectorizer(ngram_range=(1, 5))  0.657903\n",
              "4                                       TfidfVectorizer(ngram_range=(1, 5))  0.650296\n",
              "11                   HashingVectorizer(n_features=5000, ngram_range=(1, 5))  0.584730\n",
              "10                   HashingVectorizer(n_features=3000, ngram_range=(1, 5))  0.567713\n",
              "9                    HashingVectorizer(n_features=2000, ngram_range=(1, 5))  0.550458\n",
              "5                    HashingVectorizer(n_features=1000, ngram_range=(1, 5))  0.341387"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f7a60046-4006-4c14-b590-7996b9a83b59\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Vectorizer</th>\n",
              "      <th>f1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CountVectorizer(analyzer='char', ngram_range=(1, 5))</td>\n",
              "      <td>0.938119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TfidfVectorizer(analyzer='char', ngram_range=(1, 5))</td>\n",
              "      <td>0.926643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>HashingVectorizer(analyzer='char', n_features=5000, ngram_range=(1, 5))</td>\n",
              "      <td>0.909308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>HashingVectorizer(analyzer='char', n_features=3000, ngram_range=(1, 5))</td>\n",
              "      <td>0.898656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>HashingVectorizer(analyzer='char', n_features=2000, ngram_range=(1, 5))</td>\n",
              "      <td>0.892840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HashingVectorizer(analyzer='char', n_features=1000, ngram_range=(1, 5))</td>\n",
              "      <td>0.866909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CountVectorizer(ngram_range=(1, 5))</td>\n",
              "      <td>0.657903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TfidfVectorizer(ngram_range=(1, 5))</td>\n",
              "      <td>0.650296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>HashingVectorizer(n_features=5000, ngram_range=(1, 5))</td>\n",
              "      <td>0.584730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>HashingVectorizer(n_features=3000, ngram_range=(1, 5))</td>\n",
              "      <td>0.567713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>HashingVectorizer(n_features=2000, ngram_range=(1, 5))</td>\n",
              "      <td>0.550458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>HashingVectorizer(n_features=1000, ngram_range=(1, 5))</td>\n",
              "      <td>0.341387</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7a60046-4006-4c14-b590-7996b9a83b59')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f7a60046-4006-4c14-b590-7996b9a83b59 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f7a60046-4006-4c14-b590-7996b9a83b59');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-73bde76c-4d88-483f-a895-db1a749cab2d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-73bde76c-4d88-483f-a895-db1a749cab2d')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-73bde76c-4d88-483f-a895-db1a749cab2d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "result_model = pd.DataFrame({'Vectorizer': vectorizers + vectorizers_word + vectorizers_hash + vectorizers_hash_word,\n",
        "                            'f1_score': f1_scores})\n",
        "result_model.sort_values('f1_score', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "c5b04824",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "c5b04824",
        "outputId": "6411c461-5d11-47e2-960c-b5048850a1b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                 Vectorizer  Accuracy\n",
              "0                      CountVectorizer(analyzer='char', ngram_range=(1, 5))  0.939469\n",
              "1                      TfidfVectorizer(analyzer='char', ngram_range=(1, 5))  0.928986\n",
              "8   HashingVectorizer(analyzer='char', n_features=5000, ngram_range=(1, 5))  0.912540\n",
              "7   HashingVectorizer(analyzer='char', n_features=3000, ngram_range=(1, 5))  0.902181\n",
              "6   HashingVectorizer(analyzer='char', n_features=2000, ngram_range=(1, 5))  0.896243\n",
              "2   HashingVectorizer(analyzer='char', n_features=1000, ngram_range=(1, 5))  0.870734\n",
              "3                                       CountVectorizer(ngram_range=(1, 5))  0.649248\n",
              "4                                       TfidfVectorizer(ngram_range=(1, 5))  0.640016\n",
              "11                   HashingVectorizer(n_features=5000, ngram_range=(1, 5))  0.601947\n",
              "10                   HashingVectorizer(n_features=3000, ngram_range=(1, 5))  0.592669\n",
              "9                    HashingVectorizer(n_features=2000, ngram_range=(1, 5))  0.578833\n",
              "5                    HashingVectorizer(n_features=1000, ngram_range=(1, 5))  0.360648"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c85bd6a7-862b-4d3b-9c00-418576c5a615\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Vectorizer</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CountVectorizer(analyzer='char', ngram_range=(1, 5))</td>\n",
              "      <td>0.939469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TfidfVectorizer(analyzer='char', ngram_range=(1, 5))</td>\n",
              "      <td>0.928986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>HashingVectorizer(analyzer='char', n_features=5000, ngram_range=(1, 5))</td>\n",
              "      <td>0.912540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>HashingVectorizer(analyzer='char', n_features=3000, ngram_range=(1, 5))</td>\n",
              "      <td>0.902181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>HashingVectorizer(analyzer='char', n_features=2000, ngram_range=(1, 5))</td>\n",
              "      <td>0.896243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HashingVectorizer(analyzer='char', n_features=1000, ngram_range=(1, 5))</td>\n",
              "      <td>0.870734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CountVectorizer(ngram_range=(1, 5))</td>\n",
              "      <td>0.649248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TfidfVectorizer(ngram_range=(1, 5))</td>\n",
              "      <td>0.640016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>HashingVectorizer(n_features=5000, ngram_range=(1, 5))</td>\n",
              "      <td>0.601947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>HashingVectorizer(n_features=3000, ngram_range=(1, 5))</td>\n",
              "      <td>0.592669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>HashingVectorizer(n_features=2000, ngram_range=(1, 5))</td>\n",
              "      <td>0.578833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>HashingVectorizer(n_features=1000, ngram_range=(1, 5))</td>\n",
              "      <td>0.360648</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c85bd6a7-862b-4d3b-9c00-418576c5a615')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c85bd6a7-862b-4d3b-9c00-418576c5a615 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c85bd6a7-862b-4d3b-9c00-418576c5a615');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bf42b1cd-1999-4f45-b656-96d53032e48e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bf42b1cd-1999-4f45-b656-96d53032e48e')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bf42b1cd-1999-4f45-b656-96d53032e48e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "result_model_acc = pd.DataFrame({'Vectorizer': vectorizers + vectorizers_word + vectorizers_hash + vectorizers_hash_word,\n",
        "                            'Accuracy': accuracy_scores})\n",
        "result_model_acc.sort_values('Accuracy', ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "818cfc2c",
      "metadata": {
        "id": "818cfc2c"
      },
      "source": [
        "### В результате эксперимента проверили различные векторайзеры для разного количества символов. Наилучший результат показали символьные N-граммы. Результат N-грамм для слов оказался значительно хуже."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54ff2cba",
      "metadata": {
        "id": "54ff2cba"
      },
      "source": [
        "### Задание 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "14f25a01",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14f25a01",
        "outputId": "c3ac7b3e-c80d-47f9-f05c-d0ce72af3890"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: corus in /usr/local/lib/python3.10/dist-packages (0.10.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install corus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "d3f9531d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3f9531d",
        "outputId": "1260084f-70f9-4b2c-fce6-08e195b4fc27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: razdel in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.3.3)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.64.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n",
            "2023-10-16 10:36:38.477188: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-10-16 10:36:41.595379: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_sm' (3.6.0) was trained with spaCy v3.6.0 and may not be 100% compatible with the current version (3.7.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n",
            "\u001b[1m\n",
            "============================== Info about spaCy ==============================\u001b[0m\n",
            "\n",
            "spaCy version    3.7.1                         \n",
            "Location         /usr/local/lib/python3.10/dist-packages/spacy\n",
            "Platform         Linux-5.15.120+-x86_64-with-glibc2.35\n",
            "Python version   3.10.12                       \n",
            "Pipelines        ru_core_news_sm (3.7.0), en_core_web_sm (3.6.0)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install razdel\n",
        "!pip install -U spacy\n",
        "!python -m spacy info"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdb7b9eb",
      "metadata": {
        "id": "fdb7b9eb"
      },
      "source": [
        "### NLTK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "18e78eb4",
      "metadata": {
        "id": "18e78eb4"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import matplotlib\n",
        "import pyconll\n",
        "import corus\n",
        "from corus import load_ne5\n",
        "import re\n",
        "import spacy\n",
        "from spacy import displacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "a3ec0cbe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3ec0cbe",
        "outputId": "403d839a-ef35-4419-dc64-06fcd16519dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Package tagsets is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('tagsets')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "18f358fa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18f358fa",
        "outputId": "23447616-2083-4560-8d13-f0c4faa4a5f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RB: adverb\n",
            "    occasionally unabatingly maddeningly adventurously professedly\n",
            "    stirringly prominently technologically magisterially predominately\n",
            "    swiftly fiscally pitilessly ...\n",
            "NN: noun, common, singular or mass\n",
            "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
            "    investment slide humour falloff slick wind hyena override subhumanity\n",
            "    machinist ...\n",
            "VB: verb, base form\n",
            "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
            "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
            "    boost brace break bring broil brush build ...\n"
          ]
        }
      ],
      "source": [
        "nltk.help.upenn_tagset('RB')\n",
        "nltk.help.upenn_tagset('NN')\n",
        "nltk.help.upenn_tagset('VB')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "92fce672",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92fce672",
        "outputId": "4ab34f22-92ee-4fac-bee0-3defcf0d7249"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-16 10:37:44--  http://www.labinform.ru/pub/named_entities/collection5.zip\n",
            "Resolving www.labinform.ru (www.labinform.ru)... 95.181.230.181\n",
            "Connecting to www.labinform.ru (www.labinform.ru)|95.181.230.181|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1899530 (1.8M) [application/zip]\n",
            "Saving to: ‘collection5.zip.3’\n",
            "\n",
            "collection5.zip.3   100%[===================>]   1.81M  1.90MB/s    in 1.0s    \n",
            "\n",
            "2023-10-16 10:37:46 (1.90 MB/s) - ‘collection5.zip.3’ saved [1899530/1899530]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://www.labinform.ru/pub/named_entities/collection5.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "5c19ad79",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c19ad79",
        "outputId": "9d72446b-8aa0-49fc-fc6e-27fbf2b06cdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  collection5.zip\n",
            "replace Collection5/001.ann? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: Collection5/001.ann     \n",
            "  inflating: Collection5/001.txt     \n",
            "  inflating: Collection5/002.ann     \n",
            "  inflating: Collection5/002.txt     \n",
            "  inflating: Collection5/003.ann     \n",
            "  inflating: Collection5/003.txt     \n",
            "  inflating: Collection5/004.ann     \n",
            "  inflating: Collection5/004.txt     \n",
            "  inflating: Collection5/005.ann     \n",
            "  inflating: Collection5/005.txt     \n",
            "  inflating: Collection5/006.ann     \n",
            "  inflating: Collection5/006.txt     \n",
            "  inflating: Collection5/007.ann     \n",
            "  inflating: Collection5/007.txt     \n",
            "  inflating: Collection5/008.ann     \n",
            "  inflating: Collection5/008.txt     \n",
            "  inflating: Collection5/009.ann     \n",
            "  inflating: Collection5/009.txt     \n",
            "  inflating: Collection5/010.ann     \n",
            "  inflating: Collection5/010.txt     \n",
            "  inflating: Collection5/011.ann     \n",
            "  inflating: Collection5/011.txt     \n",
            "  inflating: Collection5/012.ann     \n",
            "  inflating: Collection5/012.txt     \n",
            "  inflating: Collection5/013.ann     \n",
            "  inflating: Collection5/013.txt     \n",
            "  inflating: Collection5/014.ann     \n",
            "  inflating: Collection5/014.txt     \n",
            "  inflating: Collection5/015 (!).ann  \n",
            "  inflating: Collection5/015 (!).txt  \n",
            "  inflating: Collection5/016.ann     \n",
            "  inflating: Collection5/016.txt     \n",
            "  inflating: Collection5/017.ann     \n",
            "  inflating: Collection5/017.txt     \n",
            "  inflating: Collection5/018.ann     \n",
            "  inflating: Collection5/018.txt     \n",
            "  inflating: Collection5/019.ann     \n",
            "  inflating: Collection5/019.txt     \n",
            "  inflating: Collection5/020.ann     \n",
            "  inflating: Collection5/020.txt     \n",
            "  inflating: Collection5/021.ann     \n",
            "  inflating: Collection5/021.txt     \n",
            "  inflating: Collection5/022.ann     \n",
            "  inflating: Collection5/022.txt     \n",
            "  inflating: Collection5/023.ann     \n",
            "  inflating: Collection5/023.txt     \n",
            "  inflating: Collection5/025.ann     \n",
            "  inflating: Collection5/025.txt     \n",
            "  inflating: Collection5/026.ann     \n",
            "  inflating: Collection5/026.txt     \n",
            "  inflating: Collection5/027.ann     \n",
            "  inflating: Collection5/027.txt     \n",
            "  inflating: Collection5/028.ann     \n",
            "  inflating: Collection5/028.txt     \n",
            "  inflating: Collection5/029.ann     \n",
            "  inflating: Collection5/029.txt     \n",
            "  inflating: Collection5/030.ann     \n",
            "  inflating: Collection5/030.txt     \n",
            "  inflating: Collection5/031.ann     \n",
            "  inflating: Collection5/031.txt     \n",
            "  inflating: Collection5/032.ann     \n",
            "  inflating: Collection5/032.txt     \n",
            "  inflating: Collection5/033.ann     \n",
            "  inflating: Collection5/033.txt     \n",
            "  inflating: Collection5/034.ann     \n",
            "  inflating: Collection5/034.txt     \n",
            "  inflating: Collection5/035.ann     \n",
            "  inflating: Collection5/035.txt     \n",
            "  inflating: Collection5/036.ann     \n",
            "  inflating: Collection5/036.txt     \n",
            "  inflating: Collection5/037.ann     \n",
            "  inflating: Collection5/037.txt     \n",
            "  inflating: Collection5/038.ann     \n",
            "  inflating: Collection5/038.txt     \n",
            "  inflating: Collection5/039.ann     \n",
            "  inflating: Collection5/039.txt     \n",
            "  inflating: Collection5/03_12_12a.ann  \n",
            "  inflating: Collection5/03_12_12a.txt  \n",
            "  inflating: Collection5/03_12_12b.ann  \n",
            "  inflating: Collection5/03_12_12b.txt  \n",
            "  inflating: Collection5/03_12_12c.ann  \n",
            "  inflating: Collection5/03_12_12c.txt  \n",
            "  inflating: Collection5/03_12_12d.ann  \n",
            "  inflating: Collection5/03_12_12d.txt  \n",
            "  inflating: Collection5/03_12_12g.ann  \n",
            "  inflating: Collection5/03_12_12g.txt  \n",
            "  inflating: Collection5/03_12_12h.ann  \n",
            "  inflating: Collection5/03_12_12h.txt  \n",
            "  inflating: Collection5/040.ann     \n",
            "  inflating: Collection5/040.txt     \n",
            "  inflating: Collection5/041.ann     \n",
            "  inflating: Collection5/041.txt     \n",
            "  inflating: Collection5/042.ann     \n",
            "  inflating: Collection5/042.txt     \n",
            "  inflating: Collection5/043.ann     \n",
            "  inflating: Collection5/043.txt     \n",
            "  inflating: Collection5/044.ann     \n",
            "  inflating: Collection5/044.txt     \n",
            "  inflating: Collection5/045.ann     \n",
            "  inflating: Collection5/045.txt     \n",
            "  inflating: Collection5/046.ann     \n",
            "  inflating: Collection5/046.txt     \n",
            "  inflating: Collection5/047.ann     \n",
            "  inflating: Collection5/047.txt     \n",
            "  inflating: Collection5/048.ann     \n",
            "  inflating: Collection5/048.txt     \n",
            "  inflating: Collection5/049.ann     \n",
            "  inflating: Collection5/049.txt     \n",
            "  inflating: Collection5/04_02_13a_abdulatipov.ann  \n",
            "  inflating: Collection5/04_02_13a_abdulatipov.txt  \n",
            "  inflating: Collection5/04_03_13a_sorokin.ann  \n",
            "  inflating: Collection5/04_03_13a_sorokin.txt  \n",
            "  inflating: Collection5/04_12_12b.ann  \n",
            "  inflating: Collection5/04_12_12b.txt  \n",
            "  inflating: Collection5/04_12_12d.ann  \n",
            "  inflating: Collection5/04_12_12d.txt  \n",
            "  inflating: Collection5/04_12_12f.ann  \n",
            "  inflating: Collection5/04_12_12f.txt  \n",
            "  inflating: Collection5/04_12_12g.ann  \n",
            "  inflating: Collection5/04_12_12g.txt  \n",
            "  inflating: Collection5/04_12_12h_corr.ann  \n",
            "  inflating: Collection5/04_12_12h_corr.txt  \n",
            "  inflating: Collection5/050.ann     \n",
            "  inflating: Collection5/050.txt     \n",
            "  inflating: Collection5/051.ann     \n",
            "  inflating: Collection5/051.txt     \n",
            "  inflating: Collection5/052.ann     \n",
            "  inflating: Collection5/052.txt     \n",
            "  inflating: Collection5/053.ann     \n",
            "  inflating: Collection5/053.txt     \n",
            "  inflating: Collection5/054.ann     \n",
            "  inflating: Collection5/054.txt     \n",
            "  inflating: Collection5/055.ann     \n",
            "  inflating: Collection5/055.txt     \n",
            "  inflating: Collection5/056.ann     \n",
            "  inflating: Collection5/056.txt     \n",
            "  inflating: Collection5/057.ann     \n",
            "  inflating: Collection5/057.txt     \n",
            "  inflating: Collection5/058.ann     \n",
            "  inflating: Collection5/058.txt     \n",
            "  inflating: Collection5/059.ann     \n",
            "  inflating: Collection5/059.txt     \n",
            "  inflating: Collection5/060.ann     \n",
            "  inflating: Collection5/060.txt     \n",
            "  inflating: Collection5/061.ann     \n",
            "  inflating: Collection5/061.txt     \n",
            "  inflating: Collection5/062.ann     \n",
            "  inflating: Collection5/062.txt     \n",
            "  inflating: Collection5/063.ann     \n",
            "  inflating: Collection5/063.txt     \n",
            "  inflating: Collection5/064.ann     \n",
            "  inflating: Collection5/064.txt     \n",
            "  inflating: Collection5/065.ann     \n",
            "  inflating: Collection5/065.txt     \n",
            "  inflating: Collection5/066.ann     \n",
            "  inflating: Collection5/066.txt     \n",
            "  inflating: Collection5/067.ann     \n",
            "  inflating: Collection5/067.txt     \n",
            "  inflating: Collection5/068.ann     \n",
            "  inflating: Collection5/068.txt     \n",
            "  inflating: Collection5/069.ann     \n",
            "  inflating: Collection5/069.txt     \n",
            "  inflating: Collection5/070.ann     \n",
            "  inflating: Collection5/070.txt     \n",
            "  inflating: Collection5/071.ann     \n",
            "  inflating: Collection5/071.txt     \n",
            "  inflating: Collection5/072.ann     \n",
            "  inflating: Collection5/072.txt     \n",
            "  inflating: Collection5/073.ann     \n",
            "  inflating: Collection5/073.txt     \n",
            "  inflating: Collection5/074.ann     \n",
            "  inflating: Collection5/074.txt     \n",
            "  inflating: Collection5/075.ann     \n",
            "  inflating: Collection5/075.txt     \n",
            "  inflating: Collection5/076.ann     \n",
            "  inflating: Collection5/076.txt     \n",
            "  inflating: Collection5/077.ann     \n",
            "  inflating: Collection5/077.txt     \n",
            "  inflating: Collection5/078.ann     \n",
            "  inflating: Collection5/078.txt     \n",
            "  inflating: Collection5/079.ann     \n",
            "  inflating: Collection5/079.txt     \n",
            "  inflating: Collection5/080.ann     \n",
            "  inflating: Collection5/080.txt     \n",
            "  inflating: Collection5/081.ann     \n",
            "  inflating: Collection5/081.txt     \n",
            "  inflating: Collection5/082.ann     \n",
            "  inflating: Collection5/082.txt     \n",
            "  inflating: Collection5/083.ann     \n",
            "  inflating: Collection5/083.txt     \n",
            "  inflating: Collection5/084.ann     \n",
            "  inflating: Collection5/084.txt     \n",
            "  inflating: Collection5/085.ann     \n",
            "  inflating: Collection5/085.txt     \n",
            "  inflating: Collection5/086.ann     \n",
            "  inflating: Collection5/086.txt     \n",
            "  inflating: Collection5/087.ann     \n",
            "  inflating: Collection5/087.txt     \n",
            "  inflating: Collection5/088.ann     \n",
            "  inflating: Collection5/088.txt     \n",
            "  inflating: Collection5/089.ann     \n",
            "  inflating: Collection5/089.txt     \n",
            "  inflating: Collection5/090.ann     \n",
            "  inflating: Collection5/090.txt     \n",
            "  inflating: Collection5/091.ann     \n",
            "  inflating: Collection5/091.txt     \n",
            "  inflating: Collection5/092.ann     \n",
            "  inflating: Collection5/092.txt     \n",
            "  inflating: Collection5/093.ann     \n",
            "  inflating: Collection5/093.txt     \n",
            "  inflating: Collection5/094.ann     \n",
            "  inflating: Collection5/094.txt     \n",
            "  inflating: Collection5/095.ann     \n",
            "  inflating: Collection5/095.txt     \n",
            "  inflating: Collection5/096.ann     \n",
            "  inflating: Collection5/096.txt     \n",
            "  inflating: Collection5/097.ann     \n",
            "  inflating: Collection5/097.txt     \n",
            "  inflating: Collection5/098.ann     \n",
            "  inflating: Collection5/098.txt     \n",
            "  inflating: Collection5/099.ann     \n",
            "  inflating: Collection5/099.txt     \n",
            "  inflating: Collection5/09_01_13.ann  \n",
            "  inflating: Collection5/09_01_13.txt  \n",
            "  inflating: Collection5/09_01_13a.ann  \n",
            "  inflating: Collection5/09_01_13a.txt  \n",
            "  inflating: Collection5/09_01_13c.ann  \n",
            "  inflating: Collection5/09_01_13c.txt  \n",
            "  inflating: Collection5/09_01_13d.ann  \n",
            "  inflating: Collection5/09_01_13d.txt  \n",
            "  inflating: Collection5/09_01_13e.ann  \n",
            "  inflating: Collection5/09_01_13e.txt  \n",
            "  inflating: Collection5/09_01_13h.ann  \n",
            "  inflating: Collection5/09_01_13h.txt  \n",
            "  inflating: Collection5/09_01_13i.ann  \n",
            "  inflating: Collection5/09_01_13i.txt  \n",
            "  inflating: Collection5/100.ann     \n",
            "  inflating: Collection5/100.txt     \n",
            "  inflating: Collection5/1000.ann    \n",
            "  inflating: Collection5/1000.txt    \n",
            "  inflating: Collection5/1001.ann    \n",
            "  inflating: Collection5/1001.txt    \n",
            "  inflating: Collection5/1002.ann    \n",
            "  inflating: Collection5/1002.txt    \n",
            "  inflating: Collection5/1003.ann    \n",
            "  inflating: Collection5/1003.txt    \n",
            "  inflating: Collection5/1004.ann    \n",
            "  inflating: Collection5/1004.txt    \n",
            "  inflating: Collection5/1005.ann    \n",
            "  inflating: Collection5/1005.txt    \n",
            "  inflating: Collection5/1006.ann    \n",
            "  inflating: Collection5/1006.txt    \n",
            "  inflating: Collection5/1007.ann    \n",
            "  inflating: Collection5/1007.txt    \n",
            "  inflating: Collection5/1008.ann    \n",
            "  inflating: Collection5/1008.txt    \n",
            "  inflating: Collection5/1009.ann    \n",
            "  inflating: Collection5/1009.txt    \n",
            "  inflating: Collection5/101.ann     \n",
            "  inflating: Collection5/101.txt     \n",
            "  inflating: Collection5/1010.ann    \n",
            "  inflating: Collection5/1010.txt    \n",
            "  inflating: Collection5/1011.ann    \n",
            "  inflating: Collection5/1011.txt    \n",
            "  inflating: Collection5/1012.ann    \n",
            "  inflating: Collection5/1012.txt    \n",
            "  inflating: Collection5/1013.ann    \n",
            "  inflating: Collection5/1013.txt    \n",
            "  inflating: Collection5/1014.ann    \n",
            "  inflating: Collection5/1014.txt    \n",
            "  inflating: Collection5/1015.ann    \n",
            "  inflating: Collection5/1015.txt    \n",
            "  inflating: Collection5/1016.ann    \n",
            "  inflating: Collection5/1016.txt    \n",
            "  inflating: Collection5/1017.ann    \n",
            "  inflating: Collection5/1017.txt    \n",
            "  inflating: Collection5/1018.ann    \n",
            "  inflating: Collection5/1018.txt    \n",
            "  inflating: Collection5/1019.ann    \n",
            "  inflating: Collection5/1019.txt    \n",
            "  inflating: Collection5/102.ann     \n",
            "  inflating: Collection5/102.txt     \n",
            "  inflating: Collection5/1020.ann    \n",
            "  inflating: Collection5/1020.txt    \n",
            "  inflating: Collection5/1021.ann    \n",
            "  inflating: Collection5/1021.txt    \n",
            "  inflating: Collection5/1022.ann    \n",
            "  inflating: Collection5/1022.txt    \n",
            "  inflating: Collection5/1023.ann    \n",
            "  inflating: Collection5/1023.txt    \n",
            "  inflating: Collection5/1024.ann    \n",
            "  inflating: Collection5/1024.txt    \n",
            "  inflating: Collection5/1025.ann    \n",
            "  inflating: Collection5/1025.txt    \n",
            "  inflating: Collection5/1026.ann    \n",
            "  inflating: Collection5/1026.txt    \n",
            "  inflating: Collection5/1027.ann    \n",
            "  inflating: Collection5/1027.txt    \n",
            "  inflating: Collection5/1028.ann    \n",
            "  inflating: Collection5/1028.txt    \n",
            "  inflating: Collection5/1029.ann    \n",
            "  inflating: Collection5/1029.txt    \n",
            "  inflating: Collection5/103.ann     \n",
            "  inflating: Collection5/103.txt     \n",
            "  inflating: Collection5/1030.ann    \n",
            "  inflating: Collection5/1030.txt    \n",
            "  inflating: Collection5/1031.ann    \n",
            "  inflating: Collection5/1031.txt    \n",
            "  inflating: Collection5/1032.ann    \n",
            "  inflating: Collection5/1032.txt    \n",
            "  inflating: Collection5/1033.ann    \n",
            "  inflating: Collection5/1033.txt    \n",
            "  inflating: Collection5/1034.ann    \n",
            "  inflating: Collection5/1034.txt    \n",
            "  inflating: Collection5/1035.ann    \n",
            "  inflating: Collection5/1035.txt    \n",
            "  inflating: Collection5/1036.ann    \n",
            "  inflating: Collection5/1036.txt    \n",
            "  inflating: Collection5/1037.ann    \n",
            "  inflating: Collection5/1037.txt    \n",
            "  inflating: Collection5/1038.ann    \n",
            "  inflating: Collection5/1038.txt    \n",
            "  inflating: Collection5/1039.ann    \n",
            "  inflating: Collection5/1039.txt    \n",
            "  inflating: Collection5/104.ann     \n",
            "  inflating: Collection5/104.txt     \n",
            "  inflating: Collection5/1040.ann    \n",
            "  inflating: Collection5/1040.txt    \n",
            "  inflating: Collection5/1041.ann    \n",
            "  inflating: Collection5/1041.txt    \n",
            "  inflating: Collection5/1042.ann    \n",
            "  inflating: Collection5/1042.txt    \n",
            "  inflating: Collection5/1043.ann    \n",
            "  inflating: Collection5/1043.txt    \n",
            "  inflating: Collection5/1044.ann    \n",
            "  inflating: Collection5/1044.txt    \n",
            "  inflating: Collection5/1045.ann    \n",
            "  inflating: Collection5/1045.txt    \n",
            "  inflating: Collection5/1046.ann    \n",
            "  inflating: Collection5/1046.txt    \n",
            "  inflating: Collection5/1047.ann    \n",
            "  inflating: Collection5/1047.txt    \n",
            "  inflating: Collection5/1048.ann    \n",
            "  inflating: Collection5/1048.txt    \n",
            "  inflating: Collection5/1049.ann    \n",
            "  inflating: Collection5/1049.txt    \n",
            "  inflating: Collection5/105.ann     \n",
            "  inflating: Collection5/105.txt     \n",
            "  inflating: Collection5/1050.ann    \n",
            "  inflating: Collection5/1050.txt    \n",
            "  inflating: Collection5/106.ann     \n",
            "  inflating: Collection5/106.txt     \n",
            "  inflating: Collection5/107.ann     \n",
            "  inflating: Collection5/107.txt     \n",
            "  inflating: Collection5/108.ann     \n",
            "  inflating: Collection5/108.txt     \n",
            "  inflating: Collection5/109.ann     \n",
            "  inflating: Collection5/109.txt     \n",
            "  inflating: Collection5/10_01_13a.ann  \n",
            "  inflating: Collection5/10_01_13a.txt  \n",
            "  inflating: Collection5/10_01_13d.ann  \n",
            "  inflating: Collection5/10_01_13d.txt  \n",
            "  inflating: Collection5/10_01_13i.ann  \n",
            "  inflating: Collection5/10_01_13i.txt  \n",
            "  inflating: Collection5/110.ann     \n",
            "  inflating: Collection5/110.txt     \n",
            "  inflating: Collection5/1100.ann    \n",
            "  inflating: Collection5/1100.txt    \n",
            "  inflating: Collection5/1101.ann    \n",
            "  inflating: Collection5/1101.txt    \n",
            "  inflating: Collection5/1102.ann    \n",
            "  inflating: Collection5/1102.txt    \n",
            "  inflating: Collection5/1103.ann    \n",
            "  inflating: Collection5/1103.txt    \n",
            "  inflating: Collection5/1104.ann    \n",
            "  inflating: Collection5/1104.txt    \n",
            "  inflating: Collection5/1105.ann    \n",
            "  inflating: Collection5/1105.txt    \n",
            "  inflating: Collection5/1106.ann    \n",
            "  inflating: Collection5/1106.txt    \n",
            "  inflating: Collection5/1107.ann    \n",
            "  inflating: Collection5/1107.txt    \n",
            "  inflating: Collection5/1108.ann    \n",
            "  inflating: Collection5/1108.txt    \n",
            "  inflating: Collection5/1109.ann    \n",
            "  inflating: Collection5/1109.txt    \n",
            "  inflating: Collection5/111.ann     \n",
            "  inflating: Collection5/111.txt     \n",
            "  inflating: Collection5/1110.ann    \n",
            "  inflating: Collection5/1110.txt    \n",
            "  inflating: Collection5/1111.ann    \n",
            "  inflating: Collection5/1111.txt    \n",
            "  inflating: Collection5/1112.ann    \n",
            "  inflating: Collection5/1112.txt    \n",
            "  inflating: Collection5/1113.ann    \n",
            "  inflating: Collection5/1113.txt    \n",
            "  inflating: Collection5/1114.ann    \n",
            "  inflating: Collection5/1114.txt    \n",
            "  inflating: Collection5/1115.ann    \n",
            "  inflating: Collection5/1115.txt    \n",
            "  inflating: Collection5/1116.ann    \n",
            "  inflating: Collection5/1116.txt    \n",
            "  inflating: Collection5/1117.ann    \n",
            "  inflating: Collection5/1117.txt    \n",
            "  inflating: Collection5/1118.ann    \n",
            "  inflating: Collection5/1118.txt    \n",
            "  inflating: Collection5/1119.ann    \n",
            "  inflating: Collection5/1119.txt    \n",
            "  inflating: Collection5/112.ann     \n",
            "  inflating: Collection5/112.txt     \n",
            "  inflating: Collection5/1120.ann    \n",
            "  inflating: Collection5/1120.txt    \n",
            "  inflating: Collection5/1121.ann    \n",
            "  inflating: Collection5/1121.txt    \n",
            "  inflating: Collection5/1122.ann    \n",
            "  inflating: Collection5/1122.txt    \n",
            "  inflating: Collection5/1123.ann    \n",
            "  inflating: Collection5/1123.txt    \n",
            "  inflating: Collection5/1124.ann    \n",
            "  inflating: Collection5/1124.txt    \n",
            "  inflating: Collection5/1125.ann    \n",
            "  inflating: Collection5/1125.txt    \n",
            "  inflating: Collection5/1126.ann    \n",
            "  inflating: Collection5/1126.txt    \n",
            "  inflating: Collection5/1127.ann    \n",
            "  inflating: Collection5/1127.txt    \n",
            "  inflating: Collection5/1128.ann    \n",
            "  inflating: Collection5/1128.txt    \n",
            "  inflating: Collection5/113.ann     \n",
            "  inflating: Collection5/113.txt     \n",
            "  inflating: Collection5/1130.ann    \n",
            "  inflating: Collection5/1130.txt    \n",
            "  inflating: Collection5/1131.ann    \n",
            "  inflating: Collection5/1131.txt    \n",
            "  inflating: Collection5/1132.ann    \n",
            "  inflating: Collection5/1132.txt    \n",
            "  inflating: Collection5/1133.ann    \n",
            "  inflating: Collection5/1133.txt    \n",
            "  inflating: Collection5/1134.ann    \n",
            "  inflating: Collection5/1134.txt    \n",
            "  inflating: Collection5/1135.ann    \n",
            "  inflating: Collection5/1135.txt    \n",
            "  inflating: Collection5/1136.ann    \n",
            "  inflating: Collection5/1136.txt    \n",
            "  inflating: Collection5/1137.ann    \n",
            "  inflating: Collection5/1137.txt    \n",
            "  inflating: Collection5/1138.ann    \n",
            "  inflating: Collection5/1138.txt    \n",
            "  inflating: Collection5/1139.ann    \n",
            "  inflating: Collection5/1139.txt    \n",
            "  inflating: Collection5/114.ann     \n",
            "  inflating: Collection5/114.txt     \n",
            "  inflating: Collection5/1140.ann    \n",
            "  inflating: Collection5/1140.txt    \n",
            "  inflating: Collection5/1141.ann    \n",
            "  inflating: Collection5/1141.txt    \n",
            "  inflating: Collection5/1142.ann    \n",
            "  inflating: Collection5/1142.txt    \n",
            "  inflating: Collection5/1143.ann    \n",
            "  inflating: Collection5/1143.txt    \n",
            "  inflating: Collection5/1144.ann    \n",
            "  inflating: Collection5/1144.txt    \n",
            "  inflating: Collection5/1145.ann    \n",
            "  inflating: Collection5/1145.txt    \n",
            "  inflating: Collection5/1146.ann    \n",
            "  inflating: Collection5/1146.txt    \n",
            "  inflating: Collection5/1147.ann    \n",
            "  inflating: Collection5/1147.txt    \n",
            "  inflating: Collection5/1148.ann    \n",
            "  inflating: Collection5/1148.txt    \n",
            "  inflating: Collection5/1149.ann    \n",
            "  inflating: Collection5/1149.txt    \n",
            "  inflating: Collection5/115.ann     \n",
            "  inflating: Collection5/115.txt     \n",
            "  inflating: Collection5/1150.ann    \n",
            "  inflating: Collection5/1150.txt    \n",
            "  inflating: Collection5/1151.ann    \n",
            "  inflating: Collection5/1151.txt    \n",
            "  inflating: Collection5/1152.ann    \n",
            "  inflating: Collection5/1152.txt    \n",
            "  inflating: Collection5/1153.ann    \n",
            "  inflating: Collection5/1153.txt    \n",
            "  inflating: Collection5/1154.ann    \n",
            "  inflating: Collection5/1154.txt    \n",
            "  inflating: Collection5/1155.ann    \n",
            "  inflating: Collection5/1155.txt    \n",
            "  inflating: Collection5/1156.ann    \n",
            "  inflating: Collection5/1156.txt    \n",
            "  inflating: Collection5/1157.ann    \n",
            "  inflating: Collection5/1157.txt    \n",
            "  inflating: Collection5/1158.ann    \n",
            "  inflating: Collection5/1158.txt    \n",
            "  inflating: Collection5/1159.ann    \n",
            "  inflating: Collection5/1159.txt    \n",
            "  inflating: Collection5/116.ann     \n",
            "  inflating: Collection5/116.txt     \n",
            "  inflating: Collection5/1160.ann    \n",
            "  inflating: Collection5/1160.txt    \n",
            "  inflating: Collection5/1161.ann    \n",
            "  inflating: Collection5/1161.txt    \n",
            "  inflating: Collection5/1162.ann    \n",
            "  inflating: Collection5/1162.txt    \n",
            "  inflating: Collection5/1163.ann    \n",
            "  inflating: Collection5/1163.txt    \n",
            "  inflating: Collection5/1164.ann    \n",
            "  inflating: Collection5/1164.txt    \n",
            "  inflating: Collection5/1165.ann    \n",
            "  inflating: Collection5/1165.txt    \n",
            "  inflating: Collection5/1166.ann    \n",
            "  inflating: Collection5/1166.txt    \n",
            "  inflating: Collection5/1167.ann    \n",
            "  inflating: Collection5/1167.txt    \n",
            "  inflating: Collection5/1168.ann    \n",
            "  inflating: Collection5/1168.txt    \n",
            "  inflating: Collection5/1169.ann    \n",
            "  inflating: Collection5/1169.txt    \n",
            "  inflating: Collection5/117.ann     \n",
            "  inflating: Collection5/117.txt     \n",
            "  inflating: Collection5/1170.ann    \n",
            "  inflating: Collection5/1170.txt    \n",
            "  inflating: Collection5/1171.ann    \n",
            "  inflating: Collection5/1171.txt    \n",
            "  inflating: Collection5/1172.ann    \n",
            "  inflating: Collection5/1172.txt    \n",
            "  inflating: Collection5/1173.ann    \n",
            "  inflating: Collection5/1173.txt    \n",
            "  inflating: Collection5/1174.ann    \n",
            "  inflating: Collection5/1174.txt    \n",
            "  inflating: Collection5/1175.ann    \n",
            "  inflating: Collection5/1175.txt    \n",
            "  inflating: Collection5/1176.ann    \n",
            "  inflating: Collection5/1176.txt    \n",
            "  inflating: Collection5/1177.ann    \n",
            "  inflating: Collection5/1177.txt    \n",
            "  inflating: Collection5/1178.ann    \n",
            "  inflating: Collection5/1178.txt    \n",
            "  inflating: Collection5/1179.ann    \n",
            "  inflating: Collection5/1179.txt    \n",
            "  inflating: Collection5/118.ann     \n",
            "  inflating: Collection5/118.txt     \n",
            "  inflating: Collection5/1180.ann    \n",
            "  inflating: Collection5/1180.txt    \n",
            "  inflating: Collection5/1181.ann    \n",
            "  inflating: Collection5/1181.txt    \n",
            "  inflating: Collection5/1182.ann    \n",
            "  inflating: Collection5/1182.txt    \n",
            "  inflating: Collection5/1183.ann    \n",
            "  inflating: Collection5/1183.txt    \n",
            "  inflating: Collection5/1184.ann    \n",
            "  inflating: Collection5/1184.txt    \n",
            "  inflating: Collection5/1185.ann    \n",
            "  inflating: Collection5/1185.txt    \n",
            "  inflating: Collection5/1186.ann    \n",
            "  inflating: Collection5/1186.txt    \n",
            "  inflating: Collection5/1187.ann    \n",
            "  inflating: Collection5/1187.txt    \n",
            "  inflating: Collection5/1188.ann    \n",
            "  inflating: Collection5/1188.txt    \n",
            "  inflating: Collection5/1189.ann    \n",
            "  inflating: Collection5/1189.txt    \n",
            "  inflating: Collection5/119.ann     \n",
            "  inflating: Collection5/119.txt     \n",
            "  inflating: Collection5/1190.ann    \n",
            "  inflating: Collection5/1190.txt    \n",
            "  inflating: Collection5/1191.ann    \n",
            "  inflating: Collection5/1191.txt    \n",
            "  inflating: Collection5/1192.ann    \n",
            "  inflating: Collection5/1192.txt    \n",
            "  inflating: Collection5/1193.ann    \n",
            "  inflating: Collection5/1193.txt    \n",
            "  inflating: Collection5/1194.ann    \n",
            "  inflating: Collection5/1194.txt    \n",
            "  inflating: Collection5/1195.ann    \n",
            "  inflating: Collection5/1195.txt    \n",
            "  inflating: Collection5/1196.ann    \n",
            "  inflating: Collection5/1196.txt    \n",
            "  inflating: Collection5/1197.ann    \n",
            "  inflating: Collection5/1197.txt    \n",
            "  inflating: Collection5/1198.ann    \n",
            "  inflating: Collection5/1198.txt    \n",
            "  inflating: Collection5/1199.ann    \n",
            "  inflating: Collection5/1199.txt    \n",
            "  inflating: Collection5/11_01_13b.ann  \n",
            "  inflating: Collection5/11_01_13b.txt  \n",
            "  inflating: Collection5/11_01_13e.ann  \n",
            "  inflating: Collection5/11_01_13e.txt  \n",
            "  inflating: Collection5/120.ann     \n",
            "  inflating: Collection5/120.txt     \n",
            "  inflating: Collection5/1200.ann    \n",
            "  inflating: Collection5/1200.txt    \n",
            "  inflating: Collection5/121.ann     \n",
            "  inflating: Collection5/121.txt     \n",
            "  inflating: Collection5/122.ann     \n",
            "  inflating: Collection5/122.txt     \n",
            "  inflating: Collection5/123.ann     \n",
            "  inflating: Collection5/123.txt     \n",
            "  inflating: Collection5/124.ann     \n",
            "  inflating: Collection5/124.txt     \n",
            "  inflating: Collection5/125.ann     \n",
            "  inflating: Collection5/125.txt     \n",
            "  inflating: Collection5/126.ann     \n",
            "  inflating: Collection5/126.txt     \n",
            "  inflating: Collection5/127.ann     \n",
            "  inflating: Collection5/127.txt     \n",
            "  inflating: Collection5/128.ann     \n",
            "  inflating: Collection5/128.txt     \n",
            "  inflating: Collection5/129.ann     \n",
            "  inflating: Collection5/129.txt     \n",
            "  inflating: Collection5/130.ann     \n",
            "  inflating: Collection5/130.txt     \n",
            "  inflating: Collection5/131.ann     \n",
            "  inflating: Collection5/131.txt     \n",
            "  inflating: Collection5/132.ann     \n",
            "  inflating: Collection5/132.txt     \n",
            "  inflating: Collection5/133.ann     \n",
            "  inflating: Collection5/133.txt     \n",
            "  inflating: Collection5/134.ann     \n",
            "  inflating: Collection5/134.txt     \n",
            "  inflating: Collection5/135.ann     \n",
            "  inflating: Collection5/135.txt     \n",
            "  inflating: Collection5/136.ann     \n",
            "  inflating: Collection5/136.txt     \n",
            "  inflating: Collection5/137.ann     \n",
            "  inflating: Collection5/137.txt     \n",
            "  inflating: Collection5/138.ann     \n",
            "  inflating: Collection5/138.txt     \n",
            "  inflating: Collection5/139.ann     \n",
            "  inflating: Collection5/139.txt     \n",
            "  inflating: Collection5/140.ann     \n",
            "  inflating: Collection5/140.txt     \n",
            "  inflating: Collection5/141.ann     \n",
            "  inflating: Collection5/141.txt     \n",
            "  inflating: Collection5/142.ann     \n",
            "  inflating: Collection5/142.txt     \n",
            "  inflating: Collection5/143.ann     \n",
            "  inflating: Collection5/143.txt     \n",
            "  inflating: Collection5/144.ann     \n",
            "  inflating: Collection5/144.txt     \n",
            "  inflating: Collection5/145.ann     \n",
            "  inflating: Collection5/145.txt     \n",
            "  inflating: Collection5/146.ann     \n",
            "  inflating: Collection5/146.txt     \n",
            "  inflating: Collection5/147.ann     \n",
            "  inflating: Collection5/147.txt     \n",
            "  inflating: Collection5/148.ann     \n",
            "  inflating: Collection5/148.txt     \n",
            "  inflating: Collection5/149.ann     \n",
            "  inflating: Collection5/149.txt     \n",
            "  inflating: Collection5/14_01_13c.ann  \n",
            "  inflating: Collection5/14_01_13c.txt  \n",
            "  inflating: Collection5/14_01_13g.ann  \n",
            "  inflating: Collection5/14_01_13g.txt  \n",
            "  inflating: Collection5/14_01_13i.ann  \n",
            "  inflating: Collection5/14_01_13i.txt  \n",
            "  inflating: Collection5/150.ann     \n",
            "  inflating: Collection5/150.txt     \n",
            "  inflating: Collection5/151.ann     \n",
            "  inflating: Collection5/151.txt     \n",
            "  inflating: Collection5/152.ann     \n",
            "  inflating: Collection5/152.txt     \n",
            "  inflating: Collection5/153.ann     \n",
            "  inflating: Collection5/153.txt     \n",
            "  inflating: Collection5/154.ann     \n",
            "  inflating: Collection5/154.txt     \n",
            "  inflating: Collection5/155.ann     \n",
            "  inflating: Collection5/155.txt     \n",
            "  inflating: Collection5/156.ann     \n",
            "  inflating: Collection5/156.txt     \n",
            "  inflating: Collection5/157.ann     \n",
            "  inflating: Collection5/157.txt     \n",
            "  inflating: Collection5/158.ann     \n",
            "  inflating: Collection5/158.txt     \n",
            "  inflating: Collection5/159.ann     \n",
            "  inflating: Collection5/159.txt     \n",
            "  inflating: Collection5/15_01_13a.ann  \n",
            "  inflating: Collection5/15_01_13a.txt  \n",
            "  inflating: Collection5/15_01_13b.ann  \n",
            "  inflating: Collection5/15_01_13b.txt  \n",
            "  inflating: Collection5/15_01_13e.ann  \n",
            "  inflating: Collection5/15_01_13e.txt  \n",
            "  inflating: Collection5/15_01_13f.ann  \n",
            "  inflating: Collection5/15_01_13f.txt  \n",
            "  inflating: Collection5/160.ann     \n",
            "  inflating: Collection5/160.txt     \n",
            "  inflating: Collection5/161.ann     \n",
            "  inflating: Collection5/161.txt     \n",
            "  inflating: Collection5/162.ann     \n",
            "  inflating: Collection5/162.txt     \n",
            "  inflating: Collection5/163.ann     \n",
            "  inflating: Collection5/163.txt     \n",
            "  inflating: Collection5/164.ann     \n",
            "  inflating: Collection5/164.txt     \n",
            "  inflating: Collection5/165.ann     \n",
            "  inflating: Collection5/165.txt     \n",
            "  inflating: Collection5/166.ann     \n",
            "  inflating: Collection5/166.txt     \n",
            "  inflating: Collection5/167.ann     \n",
            "  inflating: Collection5/167.txt     \n",
            "  inflating: Collection5/168.ann     \n",
            "  inflating: Collection5/168.txt     \n",
            "  inflating: Collection5/169.ann     \n",
            "  inflating: Collection5/169.txt     \n",
            "  inflating: Collection5/170.ann     \n",
            "  inflating: Collection5/170.txt     \n",
            "  inflating: Collection5/171.ann     \n",
            "  inflating: Collection5/171.txt     \n",
            "  inflating: Collection5/172.ann     \n",
            "  inflating: Collection5/172.txt     \n",
            "  inflating: Collection5/173.ann     \n",
            "  inflating: Collection5/173.txt     \n",
            "  inflating: Collection5/174.ann     \n",
            "  inflating: Collection5/174.txt     \n",
            "  inflating: Collection5/175.ann     \n",
            "  inflating: Collection5/175.txt     \n",
            "  inflating: Collection5/176.ann     \n",
            "  inflating: Collection5/176.txt     \n",
            "  inflating: Collection5/177.ann     \n",
            "  inflating: Collection5/177.txt     \n",
            "  inflating: Collection5/178.ann     \n",
            "  inflating: Collection5/178.txt     \n",
            "  inflating: Collection5/179.ann     \n",
            "  inflating: Collection5/179.txt     \n",
            "  inflating: Collection5/180.ann     \n",
            "  inflating: Collection5/180.txt     \n",
            "  inflating: Collection5/181.ann     \n",
            "  inflating: Collection5/181.txt     \n",
            "  inflating: Collection5/182.ann     \n",
            "  inflating: Collection5/182.txt     \n",
            "  inflating: Collection5/183.ann     \n",
            "  inflating: Collection5/183.txt     \n",
            "  inflating: Collection5/184.ann     \n",
            "  inflating: Collection5/184.txt     \n",
            "  inflating: Collection5/185.ann     \n",
            "  inflating: Collection5/185.txt     \n",
            "  inflating: Collection5/186.ann     \n",
            "  inflating: Collection5/186.txt     \n",
            "  inflating: Collection5/187.ann     \n",
            "  inflating: Collection5/187.txt     \n",
            "  inflating: Collection5/188.ann     \n",
            "  inflating: Collection5/188.txt     \n",
            "  inflating: Collection5/189.ann     \n",
            "  inflating: Collection5/189.txt     \n",
            "  inflating: Collection5/190.ann     \n",
            "  inflating: Collection5/190.txt     \n",
            "  inflating: Collection5/191.ann     \n",
            "  inflating: Collection5/191.txt     \n",
            "  inflating: Collection5/192.ann     \n",
            "  inflating: Collection5/192.txt     \n",
            "  inflating: Collection5/193.ann     \n",
            "  inflating: Collection5/193.txt     \n",
            "  inflating: Collection5/194.ann     \n",
            "  inflating: Collection5/194.txt     \n",
            "  inflating: Collection5/195.ann     \n",
            "  inflating: Collection5/195.txt     \n",
            "  inflating: Collection5/196.ann     \n",
            "  inflating: Collection5/196.txt     \n",
            "  inflating: Collection5/197.ann     \n",
            "  inflating: Collection5/197.txt     \n",
            "  inflating: Collection5/198.ann     \n",
            "  inflating: Collection5/198.txt     \n",
            "  inflating: Collection5/199.ann     \n",
            "  inflating: Collection5/199.txt     \n",
            "  inflating: Collection5/19_11_12d.ann  \n",
            "  inflating: Collection5/19_11_12d.txt  \n",
            "  inflating: Collection5/19_11_12h.ann  \n",
            "  inflating: Collection5/19_11_12h.txt  \n",
            "  inflating: Collection5/200.ann     \n",
            "  inflating: Collection5/200.txt     \n",
            "  inflating: Collection5/2001.ann    \n",
            "  inflating: Collection5/2001.txt    \n",
            "  inflating: Collection5/2002.ann    \n",
            "  inflating: Collection5/2002.txt    \n",
            "  inflating: Collection5/2003.ann    \n",
            "  inflating: Collection5/2003.txt    \n",
            "  inflating: Collection5/2004.ann    \n",
            "  inflating: Collection5/2004.txt    \n",
            "  inflating: Collection5/2005.ann    \n",
            "  inflating: Collection5/2005.txt    \n",
            "  inflating: Collection5/2006.ann    \n",
            "  inflating: Collection5/2006.txt    \n",
            "  inflating: Collection5/2007.ann    \n",
            "  inflating: Collection5/2007.txt    \n",
            "  inflating: Collection5/2008.ann    \n",
            "  inflating: Collection5/2008.txt    \n",
            "  inflating: Collection5/2009.ann    \n",
            "  inflating: Collection5/2009.txt    \n",
            "  inflating: Collection5/201.ann     \n",
            "  inflating: Collection5/201.txt     \n",
            "  inflating: Collection5/2010.ann    \n",
            "  inflating: Collection5/2010.txt    \n",
            "  inflating: Collection5/2011.ann    \n",
            "  inflating: Collection5/2011.txt    \n",
            "  inflating: Collection5/2012.ann    \n",
            "  inflating: Collection5/2012.txt    \n",
            "  inflating: Collection5/2013.ann    \n",
            "  inflating: Collection5/2013.txt    \n",
            "  inflating: Collection5/2014.ann    \n",
            "  inflating: Collection5/2014.txt    \n",
            "  inflating: Collection5/2015.ann    \n",
            "  inflating: Collection5/2015.txt    \n",
            "  inflating: Collection5/2016.ann    \n",
            "  inflating: Collection5/2016.txt    \n",
            "  inflating: Collection5/2017.ann    \n",
            "  inflating: Collection5/2017.txt    \n",
            "  inflating: Collection5/2018.ann    \n",
            "  inflating: Collection5/2018.txt    \n",
            "  inflating: Collection5/2019.ann    \n",
            "  inflating: Collection5/2019.txt    \n",
            "  inflating: Collection5/202.ann     \n",
            "  inflating: Collection5/202.txt     \n",
            "  inflating: Collection5/2020.ann    \n",
            "  inflating: Collection5/2020.txt    \n",
            "  inflating: Collection5/2021.ann    \n",
            "  inflating: Collection5/2021.txt    \n",
            "  inflating: Collection5/2022.ann    \n",
            "  inflating: Collection5/2022.txt    \n",
            "  inflating: Collection5/2023.ann    \n",
            "  inflating: Collection5/2023.txt    \n",
            "  inflating: Collection5/2024.ann    \n",
            "  inflating: Collection5/2024.txt    \n",
            "  inflating: Collection5/2025.ann    \n",
            "  inflating: Collection5/2025.txt    \n",
            "  inflating: Collection5/2026.ann    \n",
            "  inflating: Collection5/2026.txt    \n",
            "  inflating: Collection5/2027.ann    \n",
            "  inflating: Collection5/2027.txt    \n",
            "  inflating: Collection5/2028.ann    \n",
            "  inflating: Collection5/2028.txt    \n",
            "  inflating: Collection5/2029.ann    \n",
            "  inflating: Collection5/2029.txt    \n",
            "  inflating: Collection5/203.ann     \n",
            "  inflating: Collection5/203.txt     \n",
            "  inflating: Collection5/2030.ann    \n",
            "  inflating: Collection5/2030.txt    \n",
            "  inflating: Collection5/2031.ann    \n",
            "  inflating: Collection5/2031.txt    \n",
            "  inflating: Collection5/2032.ann    \n",
            "  inflating: Collection5/2032.txt    \n",
            "  inflating: Collection5/2034.ann    \n",
            "  inflating: Collection5/2034.txt    \n",
            "  inflating: Collection5/2035.ann    \n",
            "  inflating: Collection5/2035.txt    \n",
            "  inflating: Collection5/2036.ann    \n",
            "  inflating: Collection5/2036.txt    \n",
            "  inflating: Collection5/2037.ann    \n",
            "  inflating: Collection5/2037.txt    \n",
            "  inflating: Collection5/2038.ann    \n",
            "  inflating: Collection5/2038.txt    \n",
            "  inflating: Collection5/2039.ann    \n",
            "  inflating: Collection5/2039.txt    \n",
            "  inflating: Collection5/204.ann     \n",
            "  inflating: Collection5/204.txt     \n",
            "  inflating: Collection5/2040.ann    \n",
            "  inflating: Collection5/2040.txt    \n",
            "  inflating: Collection5/2041.ann    \n",
            "  inflating: Collection5/2041.txt    \n",
            "  inflating: Collection5/2042.ann    \n",
            "  inflating: Collection5/2042.txt    \n",
            "  inflating: Collection5/2043.ann    \n",
            "  inflating: Collection5/2043.txt    \n",
            "  inflating: Collection5/2044.ann    \n",
            "  inflating: Collection5/2044.txt    \n",
            "  inflating: Collection5/2045.ann    \n",
            "  inflating: Collection5/2045.txt    \n",
            "  inflating: Collection5/2046.ann    \n",
            "  inflating: Collection5/2046.txt    \n",
            "  inflating: Collection5/2047.ann    \n",
            "  inflating: Collection5/2047.txt    \n",
            "  inflating: Collection5/2048.ann    \n",
            "  inflating: Collection5/2048.txt    \n",
            "  inflating: Collection5/2049.ann    \n",
            "  inflating: Collection5/2049.txt    \n",
            "  inflating: Collection5/205.ann     \n",
            "  inflating: Collection5/205.txt     \n",
            "  inflating: Collection5/2050.ann    \n",
            "  inflating: Collection5/2050.txt    \n",
            "  inflating: Collection5/206.ann     \n",
            "  inflating: Collection5/206.txt     \n",
            "  inflating: Collection5/207.ann     \n",
            "  inflating: Collection5/207.txt     \n",
            "  inflating: Collection5/208.ann     \n",
            "  inflating: Collection5/208.txt     \n",
            "  inflating: Collection5/209.ann     \n",
            "  inflating: Collection5/209.txt     \n",
            "  inflating: Collection5/20_11_12a.ann  \n",
            "  inflating: Collection5/20_11_12a.txt  \n",
            "  inflating: Collection5/20_11_12b.ann  \n",
            "  inflating: Collection5/20_11_12b.txt  \n",
            "  inflating: Collection5/20_11_12c.ann  \n",
            "  inflating: Collection5/20_11_12c.txt  \n",
            "  inflating: Collection5/20_11_12d.ann  \n",
            "  inflating: Collection5/20_11_12d.txt  \n",
            "  inflating: Collection5/20_11_12i.ann  \n",
            "  inflating: Collection5/20_11_12i.txt  \n",
            "  inflating: Collection5/210.ann     \n",
            "  inflating: Collection5/210.txt     \n",
            "  inflating: Collection5/211.ann     \n",
            "  inflating: Collection5/211.txt     \n",
            "  inflating: Collection5/212.ann     \n",
            "  inflating: Collection5/212.txt     \n",
            "  inflating: Collection5/213.ann     \n",
            "  inflating: Collection5/213.txt     \n",
            "  inflating: Collection5/214.ann     \n",
            "  inflating: Collection5/214.txt     \n",
            "  inflating: Collection5/215.ann     \n",
            "  inflating: Collection5/215.txt     \n",
            "  inflating: Collection5/216.ann     \n",
            "  inflating: Collection5/216.txt     \n",
            "  inflating: Collection5/217.ann     \n",
            "  inflating: Collection5/217.txt     \n",
            "  inflating: Collection5/218.ann     \n",
            "  inflating: Collection5/218.txt     \n",
            "  inflating: Collection5/219.ann     \n",
            "  inflating: Collection5/219.txt     \n",
            "  inflating: Collection5/21_11_12c.ann  \n",
            "  inflating: Collection5/21_11_12c.txt  \n",
            "  inflating: Collection5/21_11_12h.ann  \n",
            "  inflating: Collection5/21_11_12h.txt  \n",
            "  inflating: Collection5/21_11_12i.ann  \n",
            "  inflating: Collection5/21_11_12i.txt  \n",
            "  inflating: Collection5/21_11_12j.ann  \n",
            "  inflating: Collection5/21_11_12j.txt  \n",
            "  inflating: Collection5/220.ann     \n",
            "  inflating: Collection5/220.txt     \n",
            "  inflating: Collection5/221.ann     \n",
            "  inflating: Collection5/221.txt     \n",
            "  inflating: Collection5/222.ann     \n",
            "  inflating: Collection5/222.txt     \n",
            "  inflating: Collection5/223.ann     \n",
            "  inflating: Collection5/223.txt     \n",
            "  inflating: Collection5/224.ann     \n",
            "  inflating: Collection5/224.txt     \n",
            "  inflating: Collection5/225.ann     \n",
            "  inflating: Collection5/225.txt     \n",
            "  inflating: Collection5/226.ann     \n",
            "  inflating: Collection5/226.txt     \n",
            "  inflating: Collection5/227.ann     \n",
            "  inflating: Collection5/227.txt     \n",
            "  inflating: Collection5/228.ann     \n",
            "  inflating: Collection5/228.txt     \n",
            "  inflating: Collection5/229.ann     \n",
            "  inflating: Collection5/229.txt     \n",
            "  inflating: Collection5/22_11_12a.ann  \n",
            "  inflating: Collection5/22_11_12a.txt  \n",
            "  inflating: Collection5/22_11_12c.ann  \n",
            "  inflating: Collection5/22_11_12c.txt  \n",
            "  inflating: Collection5/22_11_12d.ann  \n",
            "  inflating: Collection5/22_11_12d.txt  \n",
            "  inflating: Collection5/22_11_12g.ann  \n",
            "  inflating: Collection5/22_11_12g.txt  \n",
            "  inflating: Collection5/22_11_12h.ann  \n",
            "  inflating: Collection5/22_11_12h.txt  \n",
            "  inflating: Collection5/22_11_12i.ann  \n",
            "  inflating: Collection5/22_11_12i.txt  \n",
            "  inflating: Collection5/22_11_12j.ann  \n",
            "  inflating: Collection5/22_11_12j.txt  \n",
            "  inflating: Collection5/230.ann     \n",
            "  inflating: Collection5/230.txt     \n",
            "  inflating: Collection5/231.ann     \n",
            "  inflating: Collection5/231.txt     \n",
            "  inflating: Collection5/232.ann     \n",
            "  inflating: Collection5/232.txt     \n",
            "  inflating: Collection5/233.ann     \n",
            "  inflating: Collection5/233.txt     \n",
            "  inflating: Collection5/234.ann     \n",
            "  inflating: Collection5/234.txt     \n",
            "  inflating: Collection5/235.ann     \n",
            "  inflating: Collection5/235.txt     \n",
            "  inflating: Collection5/236.ann     \n",
            "  inflating: Collection5/236.txt     \n",
            "  inflating: Collection5/237.ann     \n",
            "  inflating: Collection5/237.txt     \n",
            "  inflating: Collection5/238.ann     \n",
            "  inflating: Collection5/238.txt     \n",
            "  inflating: Collection5/239.ann     \n",
            "  inflating: Collection5/239.txt     \n",
            "  inflating: Collection5/23_11_12a.ann  \n",
            "  inflating: Collection5/23_11_12a.txt  \n",
            "  inflating: Collection5/23_11_12b.ann  \n",
            "  inflating: Collection5/23_11_12b.txt  \n",
            "  inflating: Collection5/23_11_12c.ann  \n",
            "  inflating: Collection5/23_11_12c.txt  \n",
            "  inflating: Collection5/23_11_12d.ann  \n",
            "  inflating: Collection5/23_11_12d.txt  \n",
            "  inflating: Collection5/23_11_12e.ann  \n",
            "  inflating: Collection5/23_11_12e.txt  \n",
            "  inflating: Collection5/23_11_12f.ann  \n",
            "  inflating: Collection5/23_11_12f.txt  \n",
            "  inflating: Collection5/240.ann     \n",
            "  inflating: Collection5/240.txt     \n",
            "  inflating: Collection5/241.ann     \n",
            "  inflating: Collection5/241.txt     \n",
            "  inflating: Collection5/242.ann     \n",
            "  inflating: Collection5/242.txt     \n",
            "  inflating: Collection5/243.ann     \n",
            "  inflating: Collection5/243.txt     \n",
            "  inflating: Collection5/244.ann     \n",
            "  inflating: Collection5/244.txt     \n",
            "  inflating: Collection5/245.ann     \n",
            "  inflating: Collection5/245.txt     \n",
            "  inflating: Collection5/246.ann     \n",
            "  inflating: Collection5/246.txt     \n",
            "  inflating: Collection5/247.ann     \n",
            "  inflating: Collection5/247.txt     \n",
            "  inflating: Collection5/248.ann     \n",
            "  inflating: Collection5/248.txt     \n",
            "  inflating: Collection5/249.ann     \n",
            "  inflating: Collection5/249.txt     \n",
            "  inflating: Collection5/250.ann     \n",
            "  inflating: Collection5/250.txt     \n",
            "  inflating: Collection5/251.ann     \n",
            "  inflating: Collection5/251.txt     \n",
            "  inflating: Collection5/252.ann     \n",
            "  inflating: Collection5/252.txt     \n",
            "  inflating: Collection5/253.ann     \n",
            "  inflating: Collection5/253.txt     \n",
            "  inflating: Collection5/254.ann     \n",
            "  inflating: Collection5/254.txt     \n",
            "  inflating: Collection5/255.ann     \n",
            "  inflating: Collection5/255.txt     \n",
            "  inflating: Collection5/256.ann     \n",
            "  inflating: Collection5/256.txt     \n",
            "  inflating: Collection5/257.ann     \n",
            "  inflating: Collection5/257.txt     \n",
            "  inflating: Collection5/258.ann     \n",
            "  inflating: Collection5/258.txt     \n",
            "  inflating: Collection5/259.ann     \n",
            "  inflating: Collection5/259.txt     \n",
            "  inflating: Collection5/25_12_12a.ann  \n",
            "  inflating: Collection5/25_12_12a.txt  \n",
            "  inflating: Collection5/25_12_12c.ann  \n",
            "  inflating: Collection5/25_12_12c.txt  \n",
            "  inflating: Collection5/25_12_12d.ann  \n",
            "  inflating: Collection5/25_12_12d.txt  \n",
            "  inflating: Collection5/25_12_12e.ann  \n",
            "  inflating: Collection5/25_12_12e.txt  \n",
            "  inflating: Collection5/260.ann     \n",
            "  inflating: Collection5/260.txt     \n",
            "  inflating: Collection5/261.ann     \n",
            "  inflating: Collection5/261.txt     \n",
            "  inflating: Collection5/262.ann     \n",
            "  inflating: Collection5/262.txt     \n",
            "  inflating: Collection5/263.ann     \n",
            "  inflating: Collection5/263.txt     \n",
            "  inflating: Collection5/264.ann     \n",
            "  inflating: Collection5/264.txt     \n",
            "  inflating: Collection5/265.ann     \n",
            "  inflating: Collection5/265.txt     \n",
            "  inflating: Collection5/266.ann     \n",
            "  inflating: Collection5/266.txt     \n",
            "  inflating: Collection5/267.ann     \n",
            "  inflating: Collection5/267.txt     \n",
            "  inflating: Collection5/268.ann     \n",
            "  inflating: Collection5/268.txt     \n",
            "  inflating: Collection5/269.ann     \n",
            "  inflating: Collection5/269.txt     \n",
            "  inflating: Collection5/26_11_12b.ann  \n",
            "  inflating: Collection5/26_11_12b.txt  \n",
            "  inflating: Collection5/26_11_12c.ann  \n",
            "  inflating: Collection5/26_11_12c.txt  \n",
            "  inflating: Collection5/26_11_12e.ann  \n",
            "  inflating: Collection5/26_11_12e.txt  \n",
            "  inflating: Collection5/26_11_12f.ann  \n",
            "  inflating: Collection5/26_11_12f.txt  \n",
            "  inflating: Collection5/270.ann     \n",
            "  inflating: Collection5/270.txt     \n",
            "  inflating: Collection5/271.ann     \n",
            "  inflating: Collection5/271.txt     \n",
            "  inflating: Collection5/272.ann     \n",
            "  inflating: Collection5/272.txt     \n",
            "  inflating: Collection5/273.ann     \n",
            "  inflating: Collection5/273.txt     \n",
            "  inflating: Collection5/274.ann     \n",
            "  inflating: Collection5/274.txt     \n",
            "  inflating: Collection5/275.ann     \n",
            "  inflating: Collection5/275.txt     \n",
            "  inflating: Collection5/276.ann     \n",
            "  inflating: Collection5/276.txt     \n",
            "  inflating: Collection5/277.ann     \n",
            "  inflating: Collection5/277.txt     \n",
            "  inflating: Collection5/278.ann     \n",
            "  inflating: Collection5/278.txt     \n",
            "  inflating: Collection5/279.ann     \n",
            "  inflating: Collection5/279.txt     \n",
            "  inflating: Collection5/27_11_12a.ann  \n",
            "  inflating: Collection5/27_11_12a.txt  \n",
            "  inflating: Collection5/27_11_12c.ann  \n",
            "  inflating: Collection5/27_11_12c.txt  \n",
            "  inflating: Collection5/27_11_12d.ann  \n",
            "  inflating: Collection5/27_11_12d.txt  \n",
            "  inflating: Collection5/27_11_12e.ann  \n",
            "  inflating: Collection5/27_11_12e.txt  \n",
            "  inflating: Collection5/27_11_12j.ann  \n",
            "  inflating: Collection5/27_11_12j.txt  \n",
            "  inflating: Collection5/280.ann     \n",
            "  inflating: Collection5/280.txt     \n",
            "  inflating: Collection5/281.ann     \n",
            "  inflating: Collection5/281.txt     \n",
            "  inflating: Collection5/282.ann     \n",
            "  inflating: Collection5/282.txt     \n",
            "  inflating: Collection5/283.ann     \n",
            "  inflating: Collection5/283.txt     \n",
            "  inflating: Collection5/284.ann     \n",
            "  inflating: Collection5/284.txt     \n",
            "  inflating: Collection5/285.ann     \n",
            "  inflating: Collection5/285.txt     \n",
            "  inflating: Collection5/286.ann     \n",
            "  inflating: Collection5/286.txt     \n",
            "  inflating: Collection5/287.ann     \n",
            "  inflating: Collection5/287.txt     \n",
            "  inflating: Collection5/288.ann     \n",
            "  inflating: Collection5/288.txt     \n",
            "  inflating: Collection5/289.ann     \n",
            "  inflating: Collection5/289.txt     \n",
            "  inflating: Collection5/28_11_12a.ann  \n",
            "  inflating: Collection5/28_11_12a.txt  \n",
            "  inflating: Collection5/28_11_12f.ann  \n",
            "  inflating: Collection5/28_11_12f.txt  \n",
            "  inflating: Collection5/28_11_12g.ann  \n",
            "  inflating: Collection5/28_11_12g.txt  \n",
            "  inflating: Collection5/28_11_12h.ann  \n",
            "  inflating: Collection5/28_11_12h.txt  \n",
            "  inflating: Collection5/28_11_12i.ann  \n",
            "  inflating: Collection5/28_11_12i.txt  \n",
            "  inflating: Collection5/28_11_12j.ann  \n",
            "  inflating: Collection5/28_11_12j.txt  \n",
            "  inflating: Collection5/290.ann     \n",
            "  inflating: Collection5/290.txt     \n",
            "  inflating: Collection5/291.ann     \n",
            "  inflating: Collection5/291.txt     \n",
            "  inflating: Collection5/292.ann     \n",
            "  inflating: Collection5/292.txt     \n",
            "  inflating: Collection5/293.ann     \n",
            "  inflating: Collection5/293.txt     \n",
            "  inflating: Collection5/294.ann     \n",
            "  inflating: Collection5/294.txt     \n",
            "  inflating: Collection5/295.ann     \n",
            "  inflating: Collection5/295.txt     \n",
            "  inflating: Collection5/296.ann     \n",
            "  inflating: Collection5/296.txt     \n",
            "  inflating: Collection5/297.ann     \n",
            "  inflating: Collection5/297.txt     \n",
            "  inflating: Collection5/298.ann     \n",
            "  inflating: Collection5/298.txt     \n",
            "  inflating: Collection5/299.ann     \n",
            "  inflating: Collection5/299.txt     \n",
            "  inflating: Collection5/29_11_12a.ann  \n",
            "  inflating: Collection5/29_11_12a.txt  \n",
            "  inflating: Collection5/29_11_12b.ann  \n",
            "  inflating: Collection5/29_11_12b.txt  \n",
            "  inflating: Collection5/300.ann     \n",
            "  inflating: Collection5/300.txt     \n",
            "  inflating: Collection5/301.ann     \n",
            "  inflating: Collection5/301.txt     \n",
            "  inflating: Collection5/302.ann     \n",
            "  inflating: Collection5/302.txt     \n",
            "  inflating: Collection5/303.ann     \n",
            "  inflating: Collection5/303.txt     \n",
            "  inflating: Collection5/304.ann     \n",
            "  inflating: Collection5/304.txt     \n",
            "  inflating: Collection5/305.ann     \n",
            "  inflating: Collection5/305.txt     \n",
            "  inflating: Collection5/306.ann     \n",
            "  inflating: Collection5/306.txt     \n",
            "  inflating: Collection5/307.ann     \n",
            "  inflating: Collection5/307.txt     \n",
            "  inflating: Collection5/308.ann     \n",
            "  inflating: Collection5/308.txt     \n",
            "  inflating: Collection5/309.ann     \n",
            "  inflating: Collection5/309.txt     \n",
            "  inflating: Collection5/30_11_12b.ann  \n",
            "  inflating: Collection5/30_11_12b.txt  \n",
            "  inflating: Collection5/30_11_12h.ann  \n",
            "  inflating: Collection5/30_11_12h.txt  \n",
            "  inflating: Collection5/30_11_12i.ann  \n",
            "  inflating: Collection5/30_11_12i.txt  \n",
            "  inflating: Collection5/310.ann     \n",
            "  inflating: Collection5/310.txt     \n",
            "  inflating: Collection5/311.ann     \n",
            "  inflating: Collection5/311.txt     \n",
            "  inflating: Collection5/312.ann     \n",
            "  inflating: Collection5/312.txt     \n",
            "  inflating: Collection5/313.ann     \n",
            "  inflating: Collection5/313.txt     \n",
            "  inflating: Collection5/314.ann     \n",
            "  inflating: Collection5/314.txt     \n",
            "  inflating: Collection5/315.ann     \n",
            "  inflating: Collection5/315.txt     \n",
            "  inflating: Collection5/316.ann     \n",
            "  inflating: Collection5/316.txt     \n",
            "  inflating: Collection5/317.ann     \n",
            "  inflating: Collection5/317.txt     \n",
            "  inflating: Collection5/318.ann     \n",
            "  inflating: Collection5/318.txt     \n",
            "  inflating: Collection5/319.ann     \n",
            "  inflating: Collection5/319.txt     \n",
            "  inflating: Collection5/320.ann     \n",
            "  inflating: Collection5/320.txt     \n",
            "  inflating: Collection5/321.ann     \n",
            "  inflating: Collection5/321.txt     \n",
            "  inflating: Collection5/322.ann     \n",
            "  inflating: Collection5/322.txt     \n",
            "  inflating: Collection5/323.ann     \n",
            "  inflating: Collection5/323.txt     \n",
            "  inflating: Collection5/324.ann     \n",
            "  inflating: Collection5/324.txt     \n",
            "  inflating: Collection5/325.ann     \n",
            "  inflating: Collection5/325.txt     \n",
            "  inflating: Collection5/326.ann     \n",
            "  inflating: Collection5/326.txt     \n",
            "  inflating: Collection5/327.ann     \n",
            "  inflating: Collection5/327.txt     \n",
            "  inflating: Collection5/328.ann     \n",
            "  inflating: Collection5/328.txt     \n",
            "  inflating: Collection5/329.ann     \n",
            "  inflating: Collection5/329.txt     \n",
            "  inflating: Collection5/330.ann     \n",
            "  inflating: Collection5/330.txt     \n",
            "  inflating: Collection5/331.ann     \n",
            "  inflating: Collection5/331.txt     \n",
            "  inflating: Collection5/332.ann     \n",
            "  inflating: Collection5/332.txt     \n",
            "  inflating: Collection5/333.ann     \n",
            "  inflating: Collection5/333.txt     \n",
            "  inflating: Collection5/334.ann     \n",
            "  inflating: Collection5/334.txt     \n",
            "  inflating: Collection5/335.ann     \n",
            "  inflating: Collection5/335.txt     \n",
            "  inflating: Collection5/336.ann     \n",
            "  inflating: Collection5/336.txt     \n",
            "  inflating: Collection5/337.ann     \n",
            "  inflating: Collection5/337.txt     \n",
            "  inflating: Collection5/338.ann     \n",
            "  inflating: Collection5/338.txt     \n",
            "  inflating: Collection5/339.ann     \n",
            "  inflating: Collection5/339.txt     \n",
            "  inflating: Collection5/340.ann     \n",
            "  inflating: Collection5/340.txt     \n",
            "  inflating: Collection5/341.ann     \n",
            "  inflating: Collection5/341.txt     \n",
            "  inflating: Collection5/342.ann     \n",
            "  inflating: Collection5/342.txt     \n",
            "  inflating: Collection5/343.ann     \n",
            "  inflating: Collection5/343.txt     \n",
            "  inflating: Collection5/344.ann     \n",
            "  inflating: Collection5/344.txt     \n",
            "  inflating: Collection5/345.ann     \n",
            "  inflating: Collection5/345.txt     \n",
            "  inflating: Collection5/346.ann     \n",
            "  inflating: Collection5/346.txt     \n",
            "  inflating: Collection5/347.ann     \n",
            "  inflating: Collection5/347.txt     \n",
            "  inflating: Collection5/348.ann     \n",
            "  inflating: Collection5/348.txt     \n",
            "  inflating: Collection5/349.ann     \n",
            "  inflating: Collection5/349.txt     \n",
            "  inflating: Collection5/350.ann     \n",
            "  inflating: Collection5/350.txt     \n",
            "  inflating: Collection5/351.ann     \n",
            "  inflating: Collection5/351.txt     \n",
            "  inflating: Collection5/352.ann     \n",
            "  inflating: Collection5/352.txt     \n",
            "  inflating: Collection5/353.ann     \n",
            "  inflating: Collection5/353.txt     \n",
            "  inflating: Collection5/354.ann     \n",
            "  inflating: Collection5/354.txt     \n",
            "  inflating: Collection5/355.ann     \n",
            "  inflating: Collection5/355.txt     \n",
            "  inflating: Collection5/356.ann     \n",
            "  inflating: Collection5/356.txt     \n",
            "  inflating: Collection5/357.ann     \n",
            "  inflating: Collection5/357.txt     \n",
            "  inflating: Collection5/358.ann     \n",
            "  inflating: Collection5/358.txt     \n",
            "  inflating: Collection5/359.ann     \n",
            "  inflating: Collection5/359.txt     \n",
            "  inflating: Collection5/360.ann     \n",
            "  inflating: Collection5/360.txt     \n",
            "  inflating: Collection5/361.ann     \n",
            "  inflating: Collection5/361.txt     \n",
            "  inflating: Collection5/362.ann     \n",
            "  inflating: Collection5/362.txt     \n",
            "  inflating: Collection5/363.ann     \n",
            "  inflating: Collection5/363.txt     \n",
            "  inflating: Collection5/364.ann     \n",
            "  inflating: Collection5/364.txt     \n",
            "  inflating: Collection5/365.ann     \n",
            "  inflating: Collection5/365.txt     \n",
            "  inflating: Collection5/366.ann     \n",
            "  inflating: Collection5/366.txt     \n",
            "  inflating: Collection5/367.ann     \n",
            "  inflating: Collection5/367.txt     \n",
            "  inflating: Collection5/368.ann     \n",
            "  inflating: Collection5/368.txt     \n",
            "  inflating: Collection5/369.ann     \n",
            "  inflating: Collection5/369.txt     \n",
            "  inflating: Collection5/370.ann     \n",
            "  inflating: Collection5/370.txt     \n",
            "  inflating: Collection5/371.ann     \n",
            "  inflating: Collection5/371.txt     \n",
            "  inflating: Collection5/372.ann     \n",
            "  inflating: Collection5/372.txt     \n",
            "  inflating: Collection5/373.ann     \n",
            "  inflating: Collection5/373.txt     \n",
            "  inflating: Collection5/374.ann     \n",
            "  inflating: Collection5/374.txt     \n",
            "  inflating: Collection5/375.ann     \n",
            "  inflating: Collection5/375.txt     \n",
            "  inflating: Collection5/376.ann     \n",
            "  inflating: Collection5/376.txt     \n",
            "  inflating: Collection5/377.ann     \n",
            "  inflating: Collection5/377.txt     \n",
            "  inflating: Collection5/378.ann     \n",
            "  inflating: Collection5/378.txt     \n",
            "  inflating: Collection5/379.ann     \n",
            "  inflating: Collection5/379.txt     \n",
            "  inflating: Collection5/380.ann     \n",
            "  inflating: Collection5/380.txt     \n",
            "  inflating: Collection5/381.ann     \n",
            "  inflating: Collection5/381.txt     \n",
            "  inflating: Collection5/382.ann     \n",
            "  inflating: Collection5/382.txt     \n",
            "  inflating: Collection5/383.ann     \n",
            "  inflating: Collection5/383.txt     \n",
            "  inflating: Collection5/384.ann     \n",
            "  inflating: Collection5/384.txt     \n",
            "  inflating: Collection5/385.ann     \n",
            "  inflating: Collection5/385.txt     \n",
            "  inflating: Collection5/386.ann     \n",
            "  inflating: Collection5/386.txt     \n",
            "  inflating: Collection5/387.ann     \n",
            "  inflating: Collection5/387.txt     \n",
            "  inflating: Collection5/388.ann     \n",
            "  inflating: Collection5/388.txt     \n",
            "  inflating: Collection5/389.ann     \n",
            "  inflating: Collection5/389.txt     \n",
            "  inflating: Collection5/390.ann     \n",
            "  inflating: Collection5/390.txt     \n",
            "  inflating: Collection5/391.ann     \n",
            "  inflating: Collection5/391.txt     \n",
            "  inflating: Collection5/392.ann     \n",
            "  inflating: Collection5/392.txt     \n",
            "  inflating: Collection5/393.ann     \n",
            "  inflating: Collection5/393.txt     \n",
            "  inflating: Collection5/394.ann     \n",
            "  inflating: Collection5/394.txt     \n",
            "  inflating: Collection5/395.ann     \n",
            "  inflating: Collection5/395.txt     \n",
            "  inflating: Collection5/396.ann     \n",
            "  inflating: Collection5/396.txt     \n",
            "  inflating: Collection5/397.ann     \n",
            "  inflating: Collection5/397.txt     \n",
            "  inflating: Collection5/398.ann     \n",
            "  inflating: Collection5/398.txt     \n",
            "  inflating: Collection5/399.ann     \n",
            "  inflating: Collection5/399.txt     \n",
            "  inflating: Collection5/400.ann     \n",
            "  inflating: Collection5/400.txt     \n",
            "  inflating: Collection5/401.ann     \n",
            "  inflating: Collection5/401.txt     \n",
            "  inflating: Collection5/402.ann     \n",
            "  inflating: Collection5/402.txt     \n",
            "  inflating: Collection5/403.ann     \n",
            "  inflating: Collection5/403.txt     \n",
            "  inflating: Collection5/404.ann     \n",
            "  inflating: Collection5/404.txt     \n",
            "  inflating: Collection5/405.ann     \n",
            "  inflating: Collection5/405.txt     \n",
            "  inflating: Collection5/406.ann     \n",
            "  inflating: Collection5/406.txt     \n",
            "  inflating: Collection5/407.ann     \n",
            "  inflating: Collection5/407.txt     \n",
            "  inflating: Collection5/408.ann     \n",
            "  inflating: Collection5/408.txt     \n",
            "  inflating: Collection5/409.ann     \n",
            "  inflating: Collection5/409.txt     \n",
            "  inflating: Collection5/410.ann     \n",
            "  inflating: Collection5/410.txt     \n",
            "  inflating: Collection5/411.ann     \n",
            "  inflating: Collection5/411.txt     \n",
            "  inflating: Collection5/412.ann     \n",
            "  inflating: Collection5/412.txt     \n",
            "  inflating: Collection5/413.ann     \n",
            "  inflating: Collection5/413.txt     \n",
            "  inflating: Collection5/414.ann     \n",
            "  inflating: Collection5/414.txt     \n",
            "  inflating: Collection5/415.ann     \n",
            "  inflating: Collection5/415.txt     \n",
            "  inflating: Collection5/416.ann     \n",
            "  inflating: Collection5/416.txt     \n",
            "  inflating: Collection5/417.ann     \n",
            "  inflating: Collection5/417.txt     \n",
            "  inflating: Collection5/418.ann     \n",
            "  inflating: Collection5/418.txt     \n",
            "  inflating: Collection5/419.ann     \n",
            "  inflating: Collection5/419.txt     \n",
            "  inflating: Collection5/420.ann     \n",
            "  inflating: Collection5/420.txt     \n",
            "  inflating: Collection5/421.ann     \n",
            "  inflating: Collection5/421.txt     \n",
            "  inflating: Collection5/422.ann     \n",
            "  inflating: Collection5/422.txt     \n",
            "  inflating: Collection5/423.ann     \n",
            "  inflating: Collection5/423.txt     \n",
            "  inflating: Collection5/424.ann     \n",
            "  inflating: Collection5/424.txt     \n",
            "  inflating: Collection5/425.ann     \n",
            "  inflating: Collection5/425.txt     \n",
            "  inflating: Collection5/426.ann     \n",
            "  inflating: Collection5/426.txt     \n",
            "  inflating: Collection5/427.ann     \n",
            "  inflating: Collection5/427.txt     \n",
            "  inflating: Collection5/428.ann     \n",
            "  inflating: Collection5/428.txt     \n",
            "  inflating: Collection5/429.ann     \n",
            "  inflating: Collection5/429.txt     \n",
            "  inflating: Collection5/430.ann     \n",
            "  inflating: Collection5/430.txt     \n",
            "  inflating: Collection5/431.ann     \n",
            "  inflating: Collection5/431.txt     \n",
            "  inflating: Collection5/432.ann     \n",
            "  inflating: Collection5/432.txt     \n",
            "  inflating: Collection5/433.ann     \n",
            "  inflating: Collection5/433.txt     \n",
            "  inflating: Collection5/434.ann     \n",
            "  inflating: Collection5/434.txt     \n",
            "  inflating: Collection5/435.ann     \n",
            "  inflating: Collection5/435.txt     \n",
            "  inflating: Collection5/436.ann     \n",
            "  inflating: Collection5/436.txt     \n",
            "  inflating: Collection5/437.ann     \n",
            "  inflating: Collection5/437.txt     \n",
            "  inflating: Collection5/438.ann     \n",
            "  inflating: Collection5/438.txt     \n",
            "  inflating: Collection5/439.ann     \n",
            "  inflating: Collection5/439.txt     \n",
            "  inflating: Collection5/440.ann     \n",
            "  inflating: Collection5/440.txt     \n",
            "  inflating: Collection5/441.ann     \n",
            "  inflating: Collection5/441.txt     \n",
            "  inflating: Collection5/442.ann     \n",
            "  inflating: Collection5/442.txt     \n",
            "  inflating: Collection5/443.ann     \n",
            "  inflating: Collection5/443.txt     \n",
            "  inflating: Collection5/444.ann     \n",
            "  inflating: Collection5/444.txt     \n",
            "  inflating: Collection5/445.ann     \n",
            "  inflating: Collection5/445.txt     \n",
            "  inflating: Collection5/446.ann     \n",
            "  inflating: Collection5/446.txt     \n",
            "  inflating: Collection5/447.ann     \n",
            "  inflating: Collection5/447.txt     \n",
            "  inflating: Collection5/448.ann     \n",
            "  inflating: Collection5/448.txt     \n",
            "  inflating: Collection5/449.ann     \n",
            "  inflating: Collection5/449.txt     \n",
            "  inflating: Collection5/450.ann     \n",
            "  inflating: Collection5/450.txt     \n",
            "  inflating: Collection5/451.ann     \n",
            "  inflating: Collection5/451.txt     \n",
            "  inflating: Collection5/452.ann     \n",
            "  inflating: Collection5/452.txt     \n",
            "  inflating: Collection5/453.ann     \n",
            "  inflating: Collection5/453.txt     \n",
            "  inflating: Collection5/454.ann     \n",
            "  inflating: Collection5/454.txt     \n",
            "  inflating: Collection5/455.ann     \n",
            "  inflating: Collection5/455.txt     \n",
            "  inflating: Collection5/457.ann     \n",
            "  inflating: Collection5/457.txt     \n",
            "  inflating: Collection5/458.ann     \n",
            "  inflating: Collection5/458.txt     \n",
            "  inflating: Collection5/459.ann     \n",
            "  inflating: Collection5/459.txt     \n",
            "  inflating: Collection5/460.ann     \n",
            "  inflating: Collection5/460.txt     \n",
            "  inflating: Collection5/461.ann     \n",
            "  inflating: Collection5/461.txt     \n",
            "  inflating: Collection5/462.ann     \n",
            "  inflating: Collection5/462.txt     \n",
            "  inflating: Collection5/463.ann     \n",
            "  inflating: Collection5/463.txt     \n",
            "  inflating: Collection5/464.ann     \n",
            "  inflating: Collection5/464.txt     \n",
            "  inflating: Collection5/465.ann     \n",
            "  inflating: Collection5/465.txt     \n",
            "  inflating: Collection5/466.ann     \n",
            "  inflating: Collection5/466.txt     \n",
            "  inflating: Collection5/467.ann     \n",
            "  inflating: Collection5/467.txt     \n",
            "  inflating: Collection5/468.ann     \n",
            "  inflating: Collection5/468.txt     \n",
            "  inflating: Collection5/469.ann     \n",
            "  inflating: Collection5/469.txt     \n",
            "  inflating: Collection5/470.ann     \n",
            "  inflating: Collection5/470.txt     \n",
            "  inflating: Collection5/471.ann     \n",
            "  inflating: Collection5/471.txt     \n",
            "  inflating: Collection5/472.ann     \n",
            "  inflating: Collection5/472.txt     \n",
            "  inflating: Collection5/473.ann     \n",
            "  inflating: Collection5/473.txt     \n",
            "  inflating: Collection5/474.ann     \n",
            "  inflating: Collection5/474.txt     \n",
            "  inflating: Collection5/475.ann     \n",
            "  inflating: Collection5/475.txt     \n",
            "  inflating: Collection5/476.ann     \n",
            "  inflating: Collection5/476.txt     \n",
            "  inflating: Collection5/477.ann     \n",
            "  inflating: Collection5/477.txt     \n",
            "  inflating: Collection5/478.ann     \n",
            "  inflating: Collection5/478.txt     \n",
            "  inflating: Collection5/479.ann     \n",
            "  inflating: Collection5/479.txt     \n",
            "  inflating: Collection5/480.ann     \n",
            "  inflating: Collection5/480.txt     \n",
            "  inflating: Collection5/481.ann     \n",
            "  inflating: Collection5/481.txt     \n",
            "  inflating: Collection5/482.ann     \n",
            "  inflating: Collection5/482.txt     \n",
            "  inflating: Collection5/483.ann     \n",
            "  inflating: Collection5/483.txt     \n",
            "  inflating: Collection5/484.ann     \n",
            "  inflating: Collection5/484.txt     \n",
            "  inflating: Collection5/485.ann     \n",
            "  inflating: Collection5/485.txt     \n",
            "  inflating: Collection5/486.ann     \n",
            "  inflating: Collection5/486.txt     \n",
            "  inflating: Collection5/487.ann     \n",
            "  inflating: Collection5/487.txt     \n",
            "  inflating: Collection5/488.ann     \n",
            "  inflating: Collection5/488.txt     \n",
            "  inflating: Collection5/489.ann     \n",
            "  inflating: Collection5/489.txt     \n",
            "  inflating: Collection5/490.ann     \n",
            "  inflating: Collection5/490.txt     \n",
            "  inflating: Collection5/491.ann     \n",
            "  inflating: Collection5/491.txt     \n",
            "  inflating: Collection5/492.ann     \n",
            "  inflating: Collection5/492.txt     \n",
            "  inflating: Collection5/493.ann     \n",
            "  inflating: Collection5/493.txt     \n",
            "  inflating: Collection5/494.ann     \n",
            "  inflating: Collection5/494.txt     \n",
            "  inflating: Collection5/495.ann     \n",
            "  inflating: Collection5/495.txt     \n",
            "  inflating: Collection5/496.ann     \n",
            "  inflating: Collection5/496.txt     \n",
            "  inflating: Collection5/497.ann     \n",
            "  inflating: Collection5/497.txt     \n",
            "  inflating: Collection5/498.ann     \n",
            "  inflating: Collection5/498.txt     \n",
            "  inflating: Collection5/499.ann     \n",
            "  inflating: Collection5/499.txt     \n",
            "  inflating: Collection5/500.ann     \n",
            "  inflating: Collection5/500.txt     \n",
            "  inflating: Collection5/501.ann     \n",
            "  inflating: Collection5/501.txt     \n",
            "  inflating: Collection5/502.ann     \n",
            "  inflating: Collection5/502.txt     \n",
            "  inflating: Collection5/503.ann     \n",
            "  inflating: Collection5/503.txt     \n",
            "  inflating: Collection5/504.ann     \n",
            "  inflating: Collection5/504.txt     \n",
            "  inflating: Collection5/505.ann     \n",
            "  inflating: Collection5/505.txt     \n",
            "  inflating: Collection5/506.ann     \n",
            "  inflating: Collection5/506.txt     \n",
            "  inflating: Collection5/507.ann     \n",
            "  inflating: Collection5/507.txt     \n",
            "  inflating: Collection5/508.ann     \n",
            "  inflating: Collection5/508.txt     \n",
            "  inflating: Collection5/509.ann     \n",
            "  inflating: Collection5/509.txt     \n",
            "  inflating: Collection5/510.ann     \n",
            "  inflating: Collection5/510.txt     \n",
            "  inflating: Collection5/511.ann     \n",
            "  inflating: Collection5/511.txt     \n",
            "  inflating: Collection5/512.ann     \n",
            "  inflating: Collection5/512.txt     \n",
            "  inflating: Collection5/513.ann     \n",
            "  inflating: Collection5/513.txt     \n",
            "  inflating: Collection5/514.ann     \n",
            "  inflating: Collection5/514.txt     \n",
            "  inflating: Collection5/515.ann     \n",
            "  inflating: Collection5/515.txt     \n",
            "  inflating: Collection5/516.ann     \n",
            "  inflating: Collection5/516.txt     \n",
            "  inflating: Collection5/517.ann     \n",
            "  inflating: Collection5/517.txt     \n",
            "  inflating: Collection5/518.ann     \n",
            "  inflating: Collection5/518.txt     \n",
            "  inflating: Collection5/519.ann     \n",
            "  inflating: Collection5/519.txt     \n",
            "  inflating: Collection5/520.ann     \n",
            "  inflating: Collection5/520.txt     \n",
            "  inflating: Collection5/521.ann     \n",
            "  inflating: Collection5/521.txt     \n",
            "  inflating: Collection5/522.ann     \n",
            "  inflating: Collection5/522.txt     \n",
            "  inflating: Collection5/523.ann     \n",
            "  inflating: Collection5/523.txt     \n",
            "  inflating: Collection5/524.ann     \n",
            "  inflating: Collection5/524.txt     \n",
            "  inflating: Collection5/525.ann     \n",
            "  inflating: Collection5/525.txt     \n",
            "  inflating: Collection5/526.ann     \n",
            "  inflating: Collection5/526.txt     \n",
            "  inflating: Collection5/527.ann     \n",
            "  inflating: Collection5/527.txt     \n",
            "  inflating: Collection5/528.ann     \n",
            "  inflating: Collection5/528.txt     \n",
            "  inflating: Collection5/529.ann     \n",
            "  inflating: Collection5/529.txt     \n",
            "  inflating: Collection5/530.ann     \n",
            "  inflating: Collection5/530.txt     \n",
            "  inflating: Collection5/531.ann     \n",
            "  inflating: Collection5/531.txt     \n",
            "  inflating: Collection5/532.ann     \n",
            "  inflating: Collection5/532.txt     \n",
            "  inflating: Collection5/533 (!).ann  \n",
            "  inflating: Collection5/533 (!).txt  \n",
            "  inflating: Collection5/534.ann     \n",
            "  inflating: Collection5/534.txt     \n",
            "  inflating: Collection5/535.ann     \n",
            "  inflating: Collection5/535.txt     \n",
            "  inflating: Collection5/536.ann     \n",
            "  inflating: Collection5/536.txt     \n",
            "  inflating: Collection5/537.ann     \n",
            "  inflating: Collection5/537.txt     \n",
            "  inflating: Collection5/538.ann     \n",
            "  inflating: Collection5/538.txt     \n",
            "  inflating: Collection5/539.ann     \n",
            "  inflating: Collection5/539.txt     \n",
            "  inflating: Collection5/540.ann     \n",
            "  inflating: Collection5/540.txt     \n",
            "  inflating: Collection5/541.ann     \n",
            "  inflating: Collection5/541.txt     \n",
            "  inflating: Collection5/542.ann     \n",
            "  inflating: Collection5/542.txt     \n",
            "  inflating: Collection5/543.ann     \n",
            "  inflating: Collection5/543.txt     \n",
            "  inflating: Collection5/544.ann     \n",
            "  inflating: Collection5/544.txt     \n",
            "  inflating: Collection5/545.ann     \n",
            "  inflating: Collection5/545.txt     \n",
            "  inflating: Collection5/546.ann     \n",
            "  inflating: Collection5/546.txt     \n",
            "  inflating: Collection5/547.ann     \n",
            "  inflating: Collection5/547.txt     \n",
            "  inflating: Collection5/548.ann     \n",
            "  inflating: Collection5/548.txt     \n",
            "  inflating: Collection5/549.ann     \n",
            "  inflating: Collection5/549.txt     \n",
            "  inflating: Collection5/550.ann     \n",
            "  inflating: Collection5/550.txt     \n",
            "  inflating: Collection5/551.ann     \n",
            "  inflating: Collection5/551.txt     \n",
            "  inflating: Collection5/552.ann     \n",
            "  inflating: Collection5/552.txt     \n",
            "  inflating: Collection5/553.ann     \n",
            "  inflating: Collection5/553.txt     \n",
            "  inflating: Collection5/554.ann     \n",
            "  inflating: Collection5/554.txt     \n",
            "  inflating: Collection5/555 (!).ann  \n",
            "  inflating: Collection5/555 (!).txt  \n",
            "  inflating: Collection5/556.ann     \n",
            "  inflating: Collection5/556.txt     \n",
            "  inflating: Collection5/557.ann     \n",
            "  inflating: Collection5/557.txt     \n",
            "  inflating: Collection5/558.ann     \n",
            "  inflating: Collection5/558.txt     \n",
            "  inflating: Collection5/559.ann     \n",
            "  inflating: Collection5/559.txt     \n",
            "  inflating: Collection5/560.ann     \n",
            "  inflating: Collection5/560.txt     \n",
            "  inflating: Collection5/561.ann     \n",
            "  inflating: Collection5/561.txt     \n",
            "  inflating: Collection5/562.ann     \n",
            "  inflating: Collection5/562.txt     \n",
            "  inflating: Collection5/563.ann     \n",
            "  inflating: Collection5/563.txt     \n",
            "  inflating: Collection5/564.ann     \n",
            "  inflating: Collection5/564.txt     \n",
            "  inflating: Collection5/565.ann     \n",
            "  inflating: Collection5/565.txt     \n",
            "  inflating: Collection5/567.ann     \n",
            "  inflating: Collection5/567.txt     \n",
            "  inflating: Collection5/568.ann     \n",
            "  inflating: Collection5/568.txt     \n",
            "  inflating: Collection5/569.ann     \n",
            "  inflating: Collection5/569.txt     \n",
            "  inflating: Collection5/570.ann     \n",
            "  inflating: Collection5/570.txt     \n",
            "  inflating: Collection5/571.ann     \n",
            "  inflating: Collection5/571.txt     \n",
            "  inflating: Collection5/572.ann     \n",
            "  inflating: Collection5/572.txt     \n",
            "  inflating: Collection5/574.ann     \n",
            "  inflating: Collection5/574.txt     \n",
            "  inflating: Collection5/575.ann     \n",
            "  inflating: Collection5/575.txt     \n",
            "  inflating: Collection5/576.ann     \n",
            "  inflating: Collection5/576.txt     \n",
            "  inflating: Collection5/577.ann     \n",
            "  inflating: Collection5/577.txt     \n",
            "  inflating: Collection5/578.ann     \n",
            "  inflating: Collection5/578.txt     \n",
            "  inflating: Collection5/579.ann     \n",
            "  inflating: Collection5/579.txt     \n",
            "  inflating: Collection5/581.ann     \n",
            "  inflating: Collection5/581.txt     \n",
            "  inflating: Collection5/582.ann     \n",
            "  inflating: Collection5/582.txt     \n",
            "  inflating: Collection5/583.ann     \n",
            "  inflating: Collection5/583.txt     \n",
            "  inflating: Collection5/584 (!).ann  \n",
            "  inflating: Collection5/584 (!).txt  \n",
            "  inflating: Collection5/585.ann     \n",
            "  inflating: Collection5/585.txt     \n",
            "  inflating: Collection5/586.ann     \n",
            "  inflating: Collection5/586.txt     \n",
            "  inflating: Collection5/587.ann     \n",
            "  inflating: Collection5/587.txt     \n",
            "  inflating: Collection5/588.ann     \n",
            "  inflating: Collection5/588.txt     \n",
            "  inflating: Collection5/589.ann     \n",
            "  inflating: Collection5/589.txt     \n",
            "  inflating: Collection5/590.ann     \n",
            "  inflating: Collection5/590.txt     \n",
            "  inflating: Collection5/591.ann     \n",
            "  inflating: Collection5/591.txt     \n",
            "  inflating: Collection5/592.ann     \n",
            "  inflating: Collection5/592.txt     \n",
            "  inflating: Collection5/593.ann     \n",
            "  inflating: Collection5/593.txt     \n",
            "  inflating: Collection5/594.ann     \n",
            "  inflating: Collection5/594.txt     \n",
            "  inflating: Collection5/595.ann     \n",
            "  inflating: Collection5/595.txt     \n",
            "  inflating: Collection5/596.ann     \n",
            "  inflating: Collection5/596.txt     \n",
            "  inflating: Collection5/597.ann     \n",
            "  inflating: Collection5/597.txt     \n",
            "  inflating: Collection5/598 (!).ann  \n",
            "  inflating: Collection5/598 (!).txt  \n",
            "  inflating: Collection5/599.ann     \n",
            "  inflating: Collection5/599.txt     \n",
            "  inflating: Collection5/600.ann     \n",
            "  inflating: Collection5/600.txt     \n",
            "  inflating: Collection5/601.ann     \n",
            "  inflating: Collection5/601.txt     \n",
            "  inflating: Collection5/602.ann     \n",
            "  inflating: Collection5/602.txt     \n",
            "  inflating: Collection5/610.ann     \n",
            "  inflating: Collection5/610.txt     \n",
            "  inflating: Collection5/611.ann     \n",
            "  inflating: Collection5/611.txt     \n",
            "  inflating: Collection5/612.ann     \n",
            "  inflating: Collection5/612.txt     \n",
            "  inflating: Collection5/613.ann     \n",
            "  inflating: Collection5/613.txt     \n",
            "  inflating: Collection5/614.ann     \n",
            "  inflating: Collection5/614.txt     \n",
            "  inflating: Collection5/615.ann     \n",
            "  inflating: Collection5/615.txt     \n",
            "  inflating: Collection5/616.ann     \n",
            "  inflating: Collection5/616.txt     \n",
            "  inflating: Collection5/617.ann     \n",
            "  inflating: Collection5/617.txt     \n",
            "  inflating: Collection5/618.ann     \n",
            "  inflating: Collection5/618.txt     \n",
            "  inflating: Collection5/619.ann     \n",
            "  inflating: Collection5/619.txt     \n",
            "  inflating: Collection5/620.ann     \n",
            "  inflating: Collection5/620.txt     \n",
            "  inflating: Collection5/621.ann     \n",
            "  inflating: Collection5/621.txt     \n",
            "  inflating: Collection5/622.ann     \n",
            "  inflating: Collection5/622.txt     \n",
            "  inflating: Collection5/623.ann     \n",
            "  inflating: Collection5/623.txt     \n",
            "  inflating: Collection5/624.ann     \n",
            "  inflating: Collection5/624.txt     \n",
            "  inflating: Collection5/625.ann     \n",
            "  inflating: Collection5/625.txt     \n",
            "  inflating: Collection5/626.ann     \n",
            "  inflating: Collection5/626.txt     \n",
            "  inflating: Collection5/627.ann     \n",
            "  inflating: Collection5/627.txt     \n",
            "  inflating: Collection5/628.ann     \n",
            "  inflating: Collection5/628.txt     \n",
            "  inflating: Collection5/629.ann     \n",
            "  inflating: Collection5/629.txt     \n",
            "  inflating: Collection5/630.ann     \n",
            "  inflating: Collection5/630.txt     \n",
            "  inflating: Collection5/631.ann     \n",
            "  inflating: Collection5/631.txt     \n",
            "  inflating: Collection5/632.ann     \n",
            "  inflating: Collection5/632.txt     \n",
            "  inflating: Collection5/633.ann     \n",
            "  inflating: Collection5/633.txt     \n",
            "  inflating: Collection5/abdulatipov.ann  \n",
            "  inflating: Collection5/abdulatipov.txt  \n",
            "  inflating: Collection5/artjakov.ann  \n",
            "  inflating: Collection5/artjakov.txt  \n",
            "  inflating: Collection5/Avtovaz.ann  \n",
            "  inflating: Collection5/Avtovaz.txt  \n",
            "  inflating: Collection5/blokhin.ann  \n",
            "  inflating: Collection5/blokhin.txt  \n",
            "  inflating: Collection5/chaves.ann  \n",
            "  inflating: Collection5/chaves.txt  \n",
            "  inflating: Collection5/chirkunov.ann  \n",
            "  inflating: Collection5/chirkunov.txt  \n",
            "  inflating: Collection5/kamchatka.ann  \n",
            "  inflating: Collection5/kamchatka.txt  \n",
            "  inflating: Collection5/klinton.ann  \n",
            "  inflating: Collection5/klinton.txt  \n",
            "  inflating: Collection5/kuleshov.ann  \n",
            "  inflating: Collection5/kuleshov.txt  \n",
            "  inflating: Collection5/last_01.ann  \n",
            "  inflating: Collection5/last_01.txt  \n",
            "  inflating: Collection5/last_02.ann  \n",
            "  inflating: Collection5/last_02.txt  \n",
            "  inflating: Collection5/last_03.ann  \n",
            "  inflating: Collection5/last_03.txt  \n",
            "  inflating: Collection5/last_04.ann  \n",
            "  inflating: Collection5/last_04.txt  \n",
            "  inflating: Collection5/last_05.ann  \n",
            "  inflating: Collection5/last_05.txt  \n",
            "  inflating: Collection5/last_06.ann  \n",
            "  inflating: Collection5/last_06.txt  \n",
            "  inflating: Collection5/last_07_new.ann  \n",
            "  inflating: Collection5/last_07_new.txt  \n",
            "  inflating: Collection5/last_08.ann  \n",
            "  inflating: Collection5/last_08.txt  \n",
            "  inflating: Collection5/last_09.ann  \n",
            "  inflating: Collection5/last_09.txt  \n",
            "  inflating: Collection5/last_10.ann  \n",
            "  inflating: Collection5/last_10.txt  \n",
            "  inflating: Collection5/last_11.ann  \n",
            "  inflating: Collection5/last_11.txt  \n",
            "  inflating: Collection5/last_12.ann  \n",
            "  inflating: Collection5/last_12.txt  \n",
            "  inflating: Collection5/last_13.ann  \n",
            "  inflating: Collection5/last_13.txt  \n",
            "  inflating: Collection5/last_14.ann  \n",
            "  inflating: Collection5/last_14.txt  \n",
            "  inflating: Collection5/last_15.ann  \n",
            "  inflating: Collection5/last_15.txt  \n",
            "  inflating: Collection5/last_16.ann  \n",
            "  inflating: Collection5/last_16.txt  \n",
            "  inflating: Collection5/last_17.ann  \n",
            "  inflating: Collection5/last_17.txt  \n",
            "  inflating: Collection5/last_18.ann  \n",
            "  inflating: Collection5/last_18.txt  \n",
            "  inflating: Collection5/last_19.ann  \n",
            "  inflating: Collection5/last_19.txt  \n",
            "  inflating: Collection5/last_20.ann  \n",
            "  inflating: Collection5/last_20.txt  \n",
            "  inflating: Collection5/last_21.ann  \n",
            "  inflating: Collection5/last_21.txt  \n",
            "  inflating: Collection5/last_22.ann  \n",
            "  inflating: Collection5/last_22.txt  \n",
            "  inflating: Collection5/last_23.ann  \n",
            "  inflating: Collection5/last_23.txt  \n",
            "  inflating: Collection5/last_24.ann  \n",
            "  inflating: Collection5/last_24.txt  \n",
            "  inflating: Collection5/last_25.ann  \n",
            "  inflating: Collection5/last_25.txt  \n",
            "  inflating: Collection5/last_26.ann  \n",
            "  inflating: Collection5/last_26.txt  \n",
            "  inflating: Collection5/last_27.ann  \n",
            "  inflating: Collection5/last_27.txt  \n",
            "  inflating: Collection5/last_28.ann  \n",
            "  inflating: Collection5/last_28.txt  \n",
            "  inflating: Collection5/last_29.ann  \n",
            "  inflating: Collection5/last_29.txt  \n",
            "  inflating: Collection5/last_30_new.ann  \n",
            "  inflating: Collection5/last_30_new.txt  \n",
            "  inflating: Collection5/last_31.ann  \n",
            "  inflating: Collection5/last_31.txt  \n",
            "  inflating: Collection5/last_32.ann  \n",
            "  inflating: Collection5/last_32.txt  \n",
            "  inflating: Collection5/last_33.ann  \n",
            "  inflating: Collection5/last_33.txt  \n",
            "  inflating: Collection5/last_34.ann  \n",
            "  inflating: Collection5/last_34.txt  \n",
            "  inflating: Collection5/last_35.ann  \n",
            "  inflating: Collection5/last_35.txt  \n",
            "  inflating: Collection5/last_36.ann  \n",
            "  inflating: Collection5/last_36.txt  \n",
            "  inflating: Collection5/last_37.ann  \n",
            "  inflating: Collection5/last_37.txt  \n",
            "  inflating: Collection5/last_38.ann  \n",
            "  inflating: Collection5/last_38.txt  \n",
            "  inflating: Collection5/last_39.ann  \n",
            "  inflating: Collection5/last_39.txt  \n",
            "  inflating: Collection5/last_40.ann  \n",
            "  inflating: Collection5/last_40.txt  \n",
            "  inflating: Collection5/last_41.ann  \n",
            "  inflating: Collection5/last_41.txt  \n",
            "  inflating: Collection5/last_42.ann  \n",
            "  inflating: Collection5/last_42.txt  \n",
            "  inflating: Collection5/last_43.ann  \n",
            "  inflating: Collection5/last_43.txt  \n",
            "  inflating: Collection5/last_44.ann  \n",
            "  inflating: Collection5/last_44.txt  \n",
            "  inflating: Collection5/last_45.ann  \n",
            "  inflating: Collection5/last_45.txt  \n",
            "  inflating: Collection5/last_46.ann  \n",
            "  inflating: Collection5/last_46.txt  \n",
            "  inflating: Collection5/last_47.ann  \n",
            "  inflating: Collection5/last_47.txt  \n",
            "  inflating: Collection5/last_48.ann  \n",
            "  inflating: Collection5/last_48.txt  \n",
            "  inflating: Collection5/last_49.ann  \n",
            "  inflating: Collection5/last_49.txt  \n",
            "  inflating: Collection5/last_50.ann  \n",
            "  inflating: Collection5/last_50.txt  \n",
            "  inflating: Collection5/last_51.ann  \n",
            "  inflating: Collection5/last_51.txt  \n",
            "  inflating: Collection5/last_52.ann  \n",
            "  inflating: Collection5/last_52.txt  \n",
            "  inflating: Collection5/last_53.ann  \n",
            "  inflating: Collection5/last_53.txt  \n",
            "  inflating: Collection5/last_54.ann  \n",
            "  inflating: Collection5/last_54.txt  \n",
            "  inflating: Collection5/last_55.ann  \n",
            "  inflating: Collection5/last_55.txt  \n",
            "  inflating: Collection5/last_56.ann  \n",
            "  inflating: Collection5/last_56.txt  \n",
            "  inflating: Collection5/last_57.ann  \n",
            "  inflating: Collection5/last_57.txt  \n",
            "  inflating: Collection5/last_58.ann  \n",
            "  inflating: Collection5/last_58.txt  \n",
            "  inflating: Collection5/last_59.ann  \n",
            "  inflating: Collection5/last_59.txt  \n",
            "  inflating: Collection5/last_60.ann  \n",
            "  inflating: Collection5/last_60.txt  \n",
            "  inflating: Collection5/last_61.ann  \n",
            "  inflating: Collection5/last_61.txt  \n",
            "  inflating: Collection5/last_62.ann  \n",
            "  inflating: Collection5/last_62.txt  \n",
            "  inflating: Collection5/last_63.ann  \n",
            "  inflating: Collection5/last_63.txt  \n",
            "  inflating: Collection5/last_64.ann  \n",
            "  inflating: Collection5/last_64.txt  \n",
            "  inflating: Collection5/last_65.ann  \n",
            "  inflating: Collection5/last_65.txt  \n",
            "  inflating: Collection5/last_66.ann  \n",
            "  inflating: Collection5/last_66.txt  \n",
            "  inflating: Collection5/last_67.ann  \n",
            "  inflating: Collection5/last_67.txt  \n",
            "  inflating: Collection5/last_68.ann  \n",
            "  inflating: Collection5/last_68.txt  \n",
            "  inflating: Collection5/last_69.ann  \n",
            "  inflating: Collection5/last_69.txt  \n",
            "  inflating: Collection5/last_70.ann  \n",
            "  inflating: Collection5/last_70.txt  \n",
            "  inflating: Collection5/last_71.ann  \n",
            "  inflating: Collection5/last_71.txt  \n",
            "  inflating: Collection5/last_72.ann  \n",
            "  inflating: Collection5/last_72.txt  \n",
            "  inflating: Collection5/last_73.ann  \n",
            "  inflating: Collection5/last_73.txt  \n",
            "  inflating: Collection5/last_74.ann  \n",
            "  inflating: Collection5/last_74.txt  \n",
            "  inflating: Collection5/last_75.ann  \n",
            "  inflating: Collection5/last_75.txt  \n",
            "  inflating: Collection5/lenoblast.ann  \n",
            "  inflating: Collection5/lenoblast.txt  \n",
            "  inflating: Collection5/maykl dzhekson.ann  \n",
            "  inflating: Collection5/maykl dzhekson.txt  \n",
            "  inflating: Collection5/mvd.ann     \n",
            "  inflating: Collection5/mvd.txt     \n",
            "  inflating: Collection5/mvd2.ann    \n",
            "  inflating: Collection5/mvd2.txt    \n",
            "  inflating: Collection5/rosobrnadzor.ann  \n",
            "  inflating: Collection5/rosobrnadzor.txt  \n",
            "  inflating: Collection5/ryadovoy chelah.ann  \n",
            "  inflating: Collection5/ryadovoy chelah.txt  \n",
            "  inflating: Collection5/semenenko.ann  \n",
            "  inflating: Collection5/semenenko.txt  \n",
            "  inflating: Collection5/shojgu1.ann  \n",
            "  inflating: Collection5/shojgu1.txt  \n",
            "  inflating: Collection5/shojgu3.ann  \n",
            "  inflating: Collection5/shojgu3.txt  \n",
            "  inflating: Collection5/shojgu4.ann  \n",
            "  inflating: Collection5/shojgu4.txt  \n",
            "  inflating: Collection5/shojgu6.ann  \n",
            "  inflating: Collection5/shojgu6.txt  \n",
            "  inflating: Collection5/si_tzjanpin.ann  \n",
            "  inflating: Collection5/si_tzjanpin.txt  \n",
            "  inflating: Collection5/sobjanin2.ann  \n",
            "  inflating: Collection5/sobjanin2.txt  \n",
            "  inflating: Collection5/turkmenija.ann  \n",
            "  inflating: Collection5/turkmenija.txt  \n",
            "  inflating: Collection5/uchitel.ann  \n",
            "  inflating: Collection5/uchitel.txt  \n"
          ]
        }
      ],
      "source": [
        "!unzip collection5.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "3b7b10b8",
      "metadata": {
        "id": "3b7b10b8"
      },
      "outputs": [],
      "source": [
        "records = load_ne5('Collection5/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "1ed34d49",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "1ed34d49",
        "outputId": "74008fe2-43c4-47dd-d7d5-1380e1949114"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"Единая Россия\" предложила 12 новых председателей комитетов Госдумы из своих 15. Партия \"Единая Россия\" предложила 12 новых председателей комитетов Государственной думы VI созыва из своих 15. Об этом журналистам сообщил секретарь президиума генерального совета \"Единой России\" Сергей Неверов. По его словам, на пост главы комитета по конституционному законодательству и государственному строительству предложена кандидатура Владимира Плигина (сохранил пост), комитета по гражданскому, процессуальному, уголовному и арбитражному законодательству - Павла Крашенинникова (сохранил пост), комитета по труду и социальной политики и делам ветеранов - Андрея Исаева (сохранил пост); по бюджету и налогам - Андрея Макарова, по финансовому рынку - Натальи Бурыкиной; по экономической политике, инновационному развитию и предпринимательству - Игоря Руденского; по федеративному устройству - Виктора Кидяева, по регламенту и организации работы Госдумы - Ильдара Габдрахманова, по делам национальностей - Гаджимеда Сафаралиева, по безопасности и противодействию коррупции - Ирины Яровой, по культуре - Станислава Говорухина, по аграрной политике - Николая Панкова, по образованию - Владимира Бурматова, по транспорту - Евгения Москвичева, по международным делам - Алексея Пушкова. С.Неверов подчеркнул, что шесть комитетов достанутся КПРФ, и по четыре - \"Справедливой России\" и ЛДПР.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "document = next(records)\n",
        "text = document.text\n",
        "# text\n",
        "text = re.sub('\\r\\n\\r\\n',' ',text)\n",
        "text = re.sub('\\r\\n',' ',text)\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "4b54137f",
      "metadata": {
        "id": "4b54137f"
      },
      "outputs": [],
      "source": [
        "document.text = text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "8d56f538",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d56f538",
        "outputId": "4a7eab5f-de4e-4c7a-809a-a50bf73f76af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('``', '``'),\n",
              " ('Единая', 'NN'),\n",
              " ('Россия', 'NN'),\n",
              " (\"''\", \"''\"),\n",
              " ('предложила', '$'),\n",
              " ('12', 'CD'),\n",
              " ('новых', 'NNP'),\n",
              " ('председателей', 'NNP'),\n",
              " ('комитетов', 'NNP'),\n",
              " ('Госдумы', 'NNP'),\n",
              " ('из', 'NNP'),\n",
              " ('своих', 'VBD'),\n",
              " ('15', 'CD'),\n",
              " ('.', '.'),\n",
              " ('Партия', 'VB'),\n",
              " ('``', '``'),\n",
              " ('Единая', 'JJ'),\n",
              " ('Россия', 'NN'),\n",
              " (\"''\", \"''\"),\n",
              " ('предложила', '$'),\n",
              " ('12', 'CD'),\n",
              " ('новых', 'NNP'),\n",
              " ('председателей', 'NNP'),\n",
              " ('комитетов', 'NNP'),\n",
              " ('Государственной', 'NNP'),\n",
              " ('думы', 'NNP'),\n",
              " ('VI', 'NNP'),\n",
              " ('созыва', 'NNP'),\n",
              " ('из', 'NNP'),\n",
              " ('своих', 'VBD'),\n",
              " ('15', 'CD'),\n",
              " ('.', '.'),\n",
              " ('Об', 'VB'),\n",
              " ('этом', 'JJ'),\n",
              " ('журналистам', 'NNP'),\n",
              " ('сообщил', 'NNP'),\n",
              " ('секретарь', 'NNP'),\n",
              " ('президиума', 'NNP'),\n",
              " ('генерального', 'NNP'),\n",
              " ('совета', 'NNP'),\n",
              " ('``', '``'),\n",
              " ('Единой', 'FW'),\n",
              " ('России', 'NN'),\n",
              " (\"''\", \"''\"),\n",
              " ('Сергей', 'NN'),\n",
              " ('Неверов', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('По', 'VB'),\n",
              " ('его', 'JJ'),\n",
              " ('словам', 'NNP'),\n",
              " (',', ','),\n",
              " ('на', 'NNP'),\n",
              " ('пост', 'NNP'),\n",
              " ('главы', 'NNP'),\n",
              " ('комитета', 'NNP'),\n",
              " ('по', 'NNP'),\n",
              " ('конституционному', 'NNP'),\n",
              " ('законодательству', 'NNP'),\n",
              " ('и', 'NNP'),\n",
              " ('государственному', 'NNP'),\n",
              " ('строительству', 'NNP'),\n",
              " ('предложена', 'NNP'),\n",
              " ('кандидатура', 'NNP'),\n",
              " ('Владимира', 'NNP'),\n",
              " ('Плигина', 'NNP'),\n",
              " ('(', '('),\n",
              " ('сохранил', 'NNP'),\n",
              " ('пост', 'NNP'),\n",
              " (')', ')'),\n",
              " (',', ','),\n",
              " ('комитета', 'JJ'),\n",
              " ('по', 'NNP'),\n",
              " ('гражданскому', 'NNP'),\n",
              " (',', ','),\n",
              " ('процессуальному', 'NNP'),\n",
              " (',', ','),\n",
              " ('уголовному', 'NNP'),\n",
              " ('и', 'NNP'),\n",
              " ('арбитражному', 'NNP'),\n",
              " ('законодательству', 'NNP'),\n",
              " ('-', ':'),\n",
              " ('Павла', 'NN'),\n",
              " ('Крашенинникова', 'NN'),\n",
              " ('(', '('),\n",
              " ('сохранил', 'NNP'),\n",
              " ('пост', 'NNP'),\n",
              " (')', ')'),\n",
              " (',', ','),\n",
              " ('комитета', 'JJ'),\n",
              " ('по', 'NNP'),\n",
              " ('труду', 'NNP'),\n",
              " ('и', 'NNP'),\n",
              " ('социальной', 'NNP'),\n",
              " ('политики', 'NNP'),\n",
              " ('и', 'NNP'),\n",
              " ('делам', 'NNP'),\n",
              " ('ветеранов', 'NNP'),\n",
              " ('-', ':'),\n",
              " ('Андрея', 'NN'),\n",
              " ('Исаева', 'NN'),\n",
              " ('(', '('),\n",
              " ('сохранил', 'NNP'),\n",
              " ('пост', 'NNP'),\n",
              " (')', ')'),\n",
              " (';', ':'),\n",
              " ('по', 'CC'),\n",
              " ('бюджету', 'VB'),\n",
              " ('и', 'NNP'),\n",
              " ('налогам', 'NNP'),\n",
              " ('-', ':'),\n",
              " ('Андрея', 'NN'),\n",
              " ('Макарова', 'NN'),\n",
              " (',', ','),\n",
              " ('по', 'NNP'),\n",
              " ('финансовому', 'NNP'),\n",
              " ('рынку', 'NNP'),\n",
              " ('-', ':'),\n",
              " ('Натальи', 'NN'),\n",
              " ('Бурыкиной', 'NN'),\n",
              " (';', ':'),\n",
              " ('по', 'CC'),\n",
              " ('экономической', 'NNP'),\n",
              " ('политике', 'NNP'),\n",
              " (',', ','),\n",
              " ('инновационному', 'NNP'),\n",
              " ('развитию', 'NNP'),\n",
              " ('и', 'NNP'),\n",
              " ('предпринимательству', 'NNP'),\n",
              " ('-', ':'),\n",
              " ('Игоря', 'NN'),\n",
              " ('Руденского', 'NN'),\n",
              " (';', ':'),\n",
              " ('по', 'CC'),\n",
              " ('федеративному', 'VB'),\n",
              " ('устройству', 'NNP'),\n",
              " ('-', ':'),\n",
              " ('Виктора', 'NN'),\n",
              " ('Кидяева', 'NN'),\n",
              " (',', ','),\n",
              " ('по', 'NNP'),\n",
              " ('регламенту', 'NNP'),\n",
              " ('и', 'NNP'),\n",
              " ('организации', 'NNP'),\n",
              " ('работы', 'NNP'),\n",
              " ('Госдумы', 'NNP'),\n",
              " ('-', ':'),\n",
              " ('Ильдара', 'NN'),\n",
              " ('Габдрахманова', 'NN'),\n",
              " (',', ','),\n",
              " ('по', 'NNP'),\n",
              " ('делам', 'NNP'),\n",
              " ('национальностей', 'NNP'),\n",
              " ('-', ':'),\n",
              " ('Гаджимеда', 'NN'),\n",
              " ('Сафаралиева', 'NN'),\n",
              " (',', ','),\n",
              " ('по', 'NNP'),\n",
              " ('безопасности', 'NNP'),\n",
              " ('и', 'NNP'),\n",
              " ('противодействию', 'NNP'),\n",
              " ('коррупции', 'NNP'),\n",
              " ('-', ':'),\n",
              " ('Ирины', 'NN'),\n",
              " ('Яровой', 'NN'),\n",
              " (',', ','),\n",
              " ('по', 'NNP'),\n",
              " ('культуре', 'NNP'),\n",
              " ('-', ':'),\n",
              " ('Станислава', 'NN'),\n",
              " ('Говорухина', 'NN'),\n",
              " (',', ','),\n",
              " ('по', 'NNP'),\n",
              " ('аграрной', 'NNP'),\n",
              " ('политике', 'NNP'),\n",
              " ('-', ':'),\n",
              " ('Николая', 'NN'),\n",
              " ('Панкова', 'NN'),\n",
              " (',', ','),\n",
              " ('по', 'NNP'),\n",
              " ('образованию', 'NNP'),\n",
              " ('-', ':'),\n",
              " ('Владимира', 'NN'),\n",
              " ('Бурматова', 'NN'),\n",
              " (',', ','),\n",
              " ('по', 'NNP'),\n",
              " ('транспорту', 'NNP'),\n",
              " ('-', ':'),\n",
              " ('Евгения', 'NN'),\n",
              " ('Москвичева', 'NN'),\n",
              " (',', ','),\n",
              " ('по', 'NNP'),\n",
              " ('международным', 'NNP'),\n",
              " ('делам', 'NNP'),\n",
              " ('-', ':'),\n",
              " ('Алексея', 'NN'),\n",
              " ('Пушкова', 'NN'),\n",
              " ('.', '.'),\n",
              " ('С.Неверов', 'JJ'),\n",
              " ('подчеркнул', 'NN'),\n",
              " (',', ','),\n",
              " ('что', 'NNP'),\n",
              " ('шесть', 'NNP'),\n",
              " ('комитетов', 'NNP'),\n",
              " ('достанутся', 'NNP'),\n",
              " ('КПРФ', 'NNP'),\n",
              " (',', ','),\n",
              " ('и', 'NNP'),\n",
              " ('по', 'NNP'),\n",
              " ('четыре', 'NNP'),\n",
              " ('-', ':'),\n",
              " ('``', '``'),\n",
              " ('Справедливой', 'FW'),\n",
              " ('России', 'NN'),\n",
              " (\"''\", \"''\"),\n",
              " ('и', 'NN'),\n",
              " ('ЛДПР', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "nltk.pos_tag(nltk.word_tokenize(text)) # Как предварительно очистить все статьи в словаре."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8f85b30",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8f85b30",
        "outputId": "a98d9c81-c8de-4a3e-95ef-a44b6d6cb7b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('Алексея', 'GPE'),\n",
              " ('Андрея', 'GPE'),\n",
              " ('Бурматова', 'PERSON'),\n",
              " ('Бурыкиной', 'ORGANIZATION'),\n",
              " ('Виктора', 'GPE'),\n",
              " ('Владимира', 'GPE'),\n",
              " ('Габдрахманова', 'PERSON'),\n",
              " ('Гаджимеда', 'GPE'),\n",
              " ('Говорухина', 'ORGANIZATION'),\n",
              " ('Госдумы', 'PERSON'),\n",
              " ('Евгения', 'GPE'),\n",
              " ('Игоря', 'GPE'),\n",
              " ('Ильдара', 'GPE'),\n",
              " ('Ирины', 'GPE'),\n",
              " ('Исаева', 'GPE'),\n",
              " ('Кидяева', 'PERSON'),\n",
              " ('ЛДПР', 'ORGANIZATION'),\n",
              " ('Макарова', 'PERSON'),\n",
              " ('Москвичева', 'ORGANIZATION'),\n",
              " ('Натальи', 'GPE'),\n",
              " ('Николая', 'GPE'),\n",
              " ('Павла', 'GPE'),\n",
              " ('Панкова', 'PERSON'),\n",
              " ('Пушкова', 'PERSON'),\n",
              " ('Россия', 'PERSON'),\n",
              " ('Руденского', 'ORGANIZATION'),\n",
              " ('Сафаралиева', 'PERSON'),\n",
              " ('Сергей Неверов', 'PERSON'),\n",
              " ('Станислава', 'GPE'),\n",
              " ('Яровой', 'PERSON')}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "{(' '.join(c[0] for c in chunk), chunk.label() ) for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(text))) if hasattr(chunk, 'label') }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f60eb27",
      "metadata": {
        "id": "0f60eb27"
      },
      "source": [
        "**В целом - работает. Но ошибки встречаются ('Россиия', 'PERSON').**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "6ae94b92",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ae94b92",
        "outputId": "85c5898f-f6ec-4ced-b152-f673872aaccf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Ne5Span(\n",
              "     index='T1',\n",
              "     type='ORG',\n",
              "     start=1,\n",
              "     stop=14,\n",
              "     text='Единая Россия'\n",
              " ),\n",
              " Ne5Span(\n",
              "     index='T2',\n",
              "     type='ORG',\n",
              "     start=60,\n",
              "     stop=67,\n",
              "     text='Госдумы'\n",
              " ),\n",
              " Ne5Span(\n",
              "     index='T3',\n",
              "     type='ORG',\n",
              "     start=92,\n",
              "     stop=105,\n",
              "     text='Единая Россия'\n",
              " ),\n",
              " Ne5Span(\n",
              "     index='T4',\n",
              "     type='ORG',\n",
              "     start=151,\n",
              "     stop=171,\n",
              "     text='Государственной думы'\n",
              " ),\n",
              " Ne5Span(\n",
              "     index='T5',\n",
              "     type='ORG',\n",
              "     start=265,\n",
              "     stop=278,\n",
              "     text='Единой России'\n",
              " ),\n",
              " Ne5Span(\n",
              "     index='T6',\n",
              "     type='PER',\n",
              "     start=280,\n",
              "     stop=294,\n",
              "     text='Сергей Неверов'\n",
              " ),\n",
              " Ne5Span(\n",
              "     index='T7',\n",
              "     type='PER',\n",
              "     start=430,\n",
              "     stop=447,\n",
              "     text='Владимира Плигина'\n",
              " ),\n",
              " Ne5Span(\n",
              "     index='T8',\n",
              "     type='PER',\n",
              "     start=553,\n",
              "     stop=573,\n",
              "     text='Павла Крашенинникова'\n",
              " ),\n",
              " Ne5Span(\n",
              "     index='T9',\n",
              "     type='PER',\n",
              "     start=651,\n",
              "     stop=664,\n",
              "     text='Андрея Исаева'\n",
              " ),\n",
              " Ne5Span(\n",
              "     index='T10',\n",
              "     type='PER',\n",
              "     start=705,\n",
              "     stop=720,\n",
              "     text='Андрея Макарова'\n",
              " ),\n",
              " Ne5Span(\n",
              "     index='T11',\n",
              "     type='PER',\n",
              "     start=745,\n",
              "     stop=762,\n",
              "     text='Натальи Бурыкиной'\n",
              " ),\n",
              " Ne5Span(\n",
              "     index='T12',\n",
              "     type='PER',\n",
              "     start=839,\n",
              "     stop=855,\n",
              "     text='Игоря Руденского'\n",
              " ),\n",
              " Ne5Span(\n",
              "     index='T13',\n",
              "     type='PER',\n",
              "     start=887,\n",
              "     stop=902,\n",
              "     text='Виктора Кидяева'\n",
              " ),\n",
              " Ne5Span(\n",
              "     index='T14',\n",
              "     type='ORG',\n",
              "     start=939,\n",
              "     stop=946,\n",
              "     text='Госдумы'\n",
              " ),\n",
              " Ne5Span(\n",
              "     index='T15',\n",
              "     type='PER',\n",
              "     start=949,\n",
              "     stop=970,\n",
              "     text='Ильдара Габдрахманова'\n",
              " ),\n",
              " Ne5Span(\n",
              "     index='T16',\n",
              "     type='PER',\n",
              "     start=999,\n",
              "     stop=1020,\n",
              "     text='Гаджимеда Сафаралиева'\n",
              " ),\n",
              " Ne5Span(\n",
              "     index='T17',\n",
              "     type='PER',\n",
              "     start=1068,\n",
              "     stop=1080,\n",
              "     text='Ирины Яровой'\n",
              " ),\n",
              " Ne5Span(\n",
              "     index='T18',\n",
              "     type='PER',\n",
              "     start=1096,\n",
              "     stop=1117,\n",
              "     text='Станислава Говорухина'\n",
              " ),\n",
              " Ne5Span(\n",
              "     index='T19',\n",
              "     type='PER',\n",
              "     start=1142,\n",
              "     stop=1157,\n",
              "     text='Николая Панкова'\n",
              " ),\n",
              " Ne5Span(\n",
              "     index='T20',\n",
              "     type='PER',\n",
              "     start=1176,\n",
              "     stop=1195,\n",
              "     text='Владимира Бурматова'\n",
              " ),\n",
              " Ne5Span(\n",
              "     index='T21',\n",
              "     type='PER',\n",
              "     start=1213,\n",
              "     stop=1231,\n",
              "     text='Евгения Москвичева'\n",
              " ),\n",
              " Ne5Span(\n",
              "     index='T22',\n",
              "     type='PER',\n",
              "     start=1258,\n",
              "     stop=1273,\n",
              "     text='Алексея Пушкова'\n",
              " ),\n",
              " Ne5Span(\n",
              "     index='T23',\n",
              "     type='PER',\n",
              "     start=1278,\n",
              "     stop=1287,\n",
              "     text='С.Неверов'\n",
              " ),\n",
              " Ne5Span(\n",
              "     index='T24',\n",
              "     type='ORG',\n",
              "     start=1331,\n",
              "     stop=1335,\n",
              "     text='КПРФ'\n",
              " ),\n",
              " Ne5Span(\n",
              "     index='T25',\n",
              "     type='ORG',\n",
              "     start=1352,\n",
              "     stop=1371,\n",
              "     text='Справедливой России'\n",
              " ),\n",
              " Ne5Span(\n",
              "     index='T26',\n",
              "     type='ORG',\n",
              "     start=1375,\n",
              "     stop=1379,\n",
              "     text='ЛДПР'\n",
              " )]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "document.spans"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fea661f3",
      "metadata": {
        "id": "fea661f3"
      },
      "source": [
        "### SpaCy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "b0c57a7b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0c57a7b",
        "outputId": "f2ce0269-c371-4c5d-9ec3-ab79d73d2795"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-10-16 10:38:32.515460: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting ru-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_sm-3.7.0/ru_core_news_sm-3.7.0-py3-none-any.whl (15.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from ru-core-news-sm==3.7.0) (3.7.1)\n",
            "Requirement already satisfied: pymorphy3>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ru-core-news-sm==3.7.0) (1.2.1)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from pymorphy3>=1.0.0->ru-core-news-sm==3.7.0) (0.7.2)\n",
            "Requirement already satisfied: docopt-ng>=0.6 in /usr/local/lib/python3.10/dist-packages (from pymorphy3>=1.0.0->ru-core-news-sm==3.7.0) (0.9.0)\n",
            "Requirement already satisfied: pymorphy3-dicts-ru in /usr/local/lib/python3.10/dist-packages (from pymorphy3>=1.0.0->ru-core-news-sm==3.7.0) (2.4.417150.4580142)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.3.3)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (4.64.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.23.5)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.1.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('ru_core_news_sm')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download ru_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "c40ac25f",
      "metadata": {
        "id": "c40ac25f"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "import ru_core_news_sm\n",
        "from spacy.lang.ru.examples import sentences\n",
        "from spacy.lang.ru import Russian"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "8f1dd8ce",
      "metadata": {
        "id": "8f1dd8ce"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"ru_core_news_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "684e49f6",
      "metadata": {
        "id": "684e49f6"
      },
      "outputs": [],
      "source": [
        "ny_bb = text\n",
        "article = nlp(ny_bb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "7d78c8aa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "7d78c8aa",
        "outputId": "1246a858-d43c-45a3-faec-f0c5c2e368c8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">&quot;\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Единая Россия\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              "&quot; предложила 12 новых председателей комитетов \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Госдумы\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " из своих 15. Партия &quot;\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Единая Россия\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              "&quot; предложила 12 новых председателей комитетов \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Государственной думы\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " VI созыва из своих 15. Об этом журналистам сообщил секретарь президиума генерального совета &quot;\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Единой России\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              "&quot; \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Сергей Неверов\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              ". По его словам, на пост главы комитета по конституционному законодательству и государственному строительству предложена кандидатура \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Владимира Плигина\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              " (сохранил пост), комитета по гражданскому, процессуальному, уголовному и арбитражному законодательству - \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Павла Крашенинникова\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              " (сохранил пост), комитета по труду и социальной политики и делам ветеранов - \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Андрея Исаева\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              " (сохранил пост); по бюджету и налогам - \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Андрея Макарова\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              ", по финансовому рынку - \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Натальи Бурыкиной\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              "; по экономической политике, инновационному развитию и предпринимательству - Игоря Руденского; по федеративному устройству - \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Виктора Кидяева\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              ", по регламенту и организации работы \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Госдумы - Ильдара Габдрахманова\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", по делам национальностей - \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Гаджимеда Сафаралиева\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              ", по безопасности и противодействию коррупции - \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Ирины Яровой\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              ", по культуре - \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Станислава Говорухина\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              ", по аграрной политике - \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Николая Панкова\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              ", по образованию - \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Владимира Бурматова\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              ", по транспорту - \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Евгения Москвичева\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              ", по международным делам - \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Алексея Пушкова\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              ". \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    С.Неверов\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              " подчеркнул, что шесть комитетов достанутся \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    КПРФ\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", и по четыре - &quot;\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Справедливой России\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              "&quot; и \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ЛДПР\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ".</div></span>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "displacy.render(article, jupyter=True, style='ent')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19963f3a",
      "metadata": {
        "id": "19963f3a"
      },
      "source": [
        "**На этом тексте библиотека SpaCy без ошибок.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adb93a50",
      "metadata": {
        "id": "adb93a50"
      },
      "source": [
        "**Посмотрим на список токенов, частей речи и сущностей.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "953d3a4c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "953d3a4c",
        "outputId": "3dd63fb5-f420-4fc5-aab1-2b7a17a8962c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\" PUNCT punct\n",
            "Единая ADJ amod\n",
            "Россия PROPN nsubj\n",
            "\" PUNCT punct\n",
            "предложила VERB ROOT\n",
            "12 NUM nummod\n",
            "новых ADJ amod\n",
            "председателей NOUN obj\n",
            "комитетов NOUN nmod\n",
            "Госдумы PROPN nmod\n",
            "из ADP case\n",
            "своих DET det\n",
            "15 NUM nummod\n",
            ". PUNCT punct\n",
            "Партия NOUN nsubj\n",
            "\" PUNCT punct\n",
            "Единая ADJ amod\n",
            "Россия PROPN appos\n",
            "\" PUNCT punct\n",
            "предложила VERB ROOT\n",
            "12 NUM nummod\n",
            "новых ADJ amod\n",
            "председателей NOUN obj\n",
            "комитетов NOUN nmod\n",
            "Государственной ADJ amod\n",
            "думы NOUN nmod\n",
            "VI ADJ amod\n",
            "созыва NOUN nmod\n",
            "из ADP case\n",
            "своих DET det\n",
            "15 NUM nummod\n",
            ". PUNCT punct\n",
            "Об ADP case\n",
            "этом PRON obl\n",
            "журналистам NOUN iobj\n",
            "сообщил VERB ROOT\n",
            "секретарь NOUN nsubj\n",
            "президиума NOUN nmod\n",
            "генерального ADJ amod\n",
            "совета NOUN nmod\n",
            "\" PUNCT punct\n",
            "Единой ADJ amod\n",
            "России PROPN nmod\n",
            "\" PUNCT punct\n",
            "Сергей PROPN appos\n",
            "Неверов PROPN flat:name\n",
            ". PUNCT punct\n",
            "По ADP case\n",
            "его DET det\n",
            "словам NOUN parataxis\n",
            ", PUNCT punct\n",
            "на ADP case\n",
            "пост NOUN obl\n",
            "главы NOUN nmod\n",
            "комитета NOUN nmod\n",
            "по ADP case\n",
            "конституционному ADJ amod\n",
            "законодательству NOUN nmod\n",
            "и CCONJ cc\n",
            "государственному ADJ amod\n",
            "строительству NOUN conj\n",
            "предложена VERB ROOT\n",
            "кандидатура NOUN nsubj:pass\n",
            "Владимира PROPN nmod\n",
            "Плигина PROPN flat:name\n",
            "( PUNCT punct\n",
            "сохранил VERB parataxis\n",
            "пост NOUN obj\n",
            ") PUNCT punct\n",
            ", PUNCT punct\n",
            "комитета NOUN conj\n",
            "по ADP case\n",
            "гражданскому ADJ amod\n",
            ", PUNCT punct\n",
            "процессуальному ADJ conj\n",
            ", PUNCT punct\n",
            "уголовному ADJ conj\n",
            "и CCONJ cc\n",
            "арбитражному ADJ conj\n",
            "законодательству NOUN nmod\n",
            "- NOUN nmod\n",
            "Павла PROPN nmod\n",
            "Крашенинникова PROPN nmod\n",
            "( PUNCT punct\n",
            "сохранил VERB parataxis\n",
            "пост NOUN obj\n",
            ") PUNCT punct\n",
            ", PUNCT punct\n",
            "комитета NOUN conj\n",
            "по ADP case\n",
            "труду NOUN nmod\n",
            "и CCONJ cc\n",
            "социальной ADJ amod\n",
            "политики NOUN conj\n",
            "и CCONJ cc\n",
            "делам NOUN conj\n",
            "ветеранов NOUN nmod\n",
            "- NOUN nmod\n",
            "Андрея PROPN nmod\n",
            "Исаева PROPN flat:name\n",
            "( PUNCT punct\n",
            "сохранил VERB parataxis\n",
            "пост NOUN obj\n",
            ") PUNCT punct\n",
            "; PUNCT punct\n",
            "по ADP case\n",
            "бюджету NOUN conj\n",
            "и CCONJ cc\n",
            "налогам NOUN conj\n",
            "- NOUN conj\n",
            "Андрея PROPN nmod\n",
            "Макарова PROPN flat:name\n",
            ", PUNCT punct\n",
            "по ADP case\n",
            "финансовому ADJ amod\n",
            "рынку NOUN conj\n",
            "- NOUN conj\n",
            "Натальи PROPN appos\n",
            "Бурыкиной PROPN flat:name\n",
            "; PUNCT punct\n",
            "по ADP case\n",
            "экономической ADJ amod\n",
            "политике NOUN obl\n",
            ", PUNCT punct\n",
            "инновационному ADJ amod\n",
            "развитию NOUN conj\n",
            "и CCONJ cc\n",
            "предпринимательству NOUN conj\n",
            "- NOUN conj\n",
            "Игоря PROPN nmod\n",
            "Руденского PROPN nmod\n",
            "; PUNCT punct\n",
            "по ADP case\n",
            "федеративному ADJ amod\n",
            "устройству NOUN obl\n",
            "- NOUN nmod\n",
            "Виктора PROPN nmod\n",
            "Кидяева PROPN flat:name\n",
            ", PUNCT punct\n",
            "по ADP case\n",
            "регламенту NOUN conj\n",
            "и CCONJ cc\n",
            "организации NOUN conj\n",
            "работы NOUN nmod\n",
            "Госдумы PROPN nmod\n",
            "- PROPN nmod\n",
            "Ильдара PROPN nmod\n",
            "Габдрахманова PROPN flat:name\n",
            ", PUNCT punct\n",
            "по ADP case\n",
            "делам NOUN case\n",
            "национальностей NOUN nmod\n",
            "- NOUN nmod\n",
            "Гаджимеда PROPN nmod\n",
            "Сафаралиева PROPN nmod\n",
            ", PUNCT punct\n",
            "по ADP case\n",
            "безопасности NOUN conj\n",
            "и CCONJ cc\n",
            "противодействию NOUN conj\n",
            "коррупции NOUN nmod\n",
            "- NOUN nmod\n",
            "Ирины PROPN nmod\n",
            "Яровой PROPN nmod\n",
            ", PUNCT punct\n",
            "по ADP case\n",
            "культуре NOUN case\n",
            "- NOUN nmod\n",
            "Станислава PROPN nmod\n",
            "Говорухина PROPN nmod\n",
            ", PUNCT punct\n",
            "по ADP case\n",
            "аграрной ADJ amod\n",
            "политике NOUN iobj\n",
            "- NOUN nmod\n",
            "Николая PROPN nmod\n",
            "Панкова PROPN flat:name\n",
            ", PUNCT punct\n",
            "по ADP case\n",
            "образованию NOUN parataxis\n",
            "- NOUN nmod\n",
            "Владимира PROPN nmod\n",
            "Бурматова PROPN flat:name\n",
            ", PUNCT punct\n",
            "по ADP case\n",
            "транспорту NOUN conj\n",
            "- NOUN nmod\n",
            "Евгения PROPN appos\n",
            "Москвичева PROPN flat:name\n",
            ", PUNCT punct\n",
            "по ADP case\n",
            "международным ADJ amod\n",
            "делам NOUN parataxis\n",
            "- NOUN nmod\n",
            "Алексея PROPN appos\n",
            "Пушкова PROPN flat:name\n",
            ". PUNCT punct\n",
            "С.Неверов PROPN nsubj\n",
            "подчеркнул VERB ROOT\n",
            ", PUNCT punct\n",
            "что SCONJ mark\n",
            "шесть NUM nummod:gov\n",
            "комитетов NOUN nsubj\n",
            "достанутся VERB ccomp\n",
            "КПРФ PROPN nsubj\n",
            ", PUNCT punct\n",
            "и CCONJ cc\n",
            "по ADP case\n",
            "четыре NUM nummod:gov\n",
            "- ADP nummod:gov\n",
            "\" PUNCT punct\n",
            "Справедливой ADJ amod\n",
            "России PROPN conj\n",
            "\" PUNCT punct\n",
            "и CCONJ cc\n",
            "ЛДПР PROPN conj\n",
            ". PUNCT punct\n"
          ]
        }
      ],
      "source": [
        "for token in article:\n",
        "    print(token.text, token.pos_, token.dep_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4df676bc",
      "metadata": {
        "id": "4df676bc"
      },
      "source": [
        "### DeepPavlov"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "b168514f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b168514f",
        "outputId": "1dda873b-2cbb-42e3-fc7a-dcd6e640e44c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.10/dist-packages (0.9)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from pymorphy2) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.10/dist-packages (from pymorphy2) (2.4.417127.4579844)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.10/dist-packages (from pymorphy2) (0.6.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pymorphy2 #==0.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "05a4faf5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05a4faf5",
        "outputId": "eef83267-1355-498d-f7e7-ec9d5699327e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.9.3)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.10/dist-packages (1.3.7)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (7.0.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.24.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.56.4)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.7.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.5.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.7)\n",
            "Requirement already satisfied: pydantic>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from inflect) (1.10.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (67.7.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (3.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
            "Requirement already satisfied: deeppavlov in /usr/local/lib/python3.10/dist-packages (1.3.0)\n",
            "Requirement already satisfied: fastapi<=0.89.1,>=0.47.0 in /usr/local/lib/python3.10/dist-packages (from deeppavlov) (0.89.1)\n",
            "Requirement already satisfied: filelock<3.10.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from deeppavlov) (3.9.1)\n",
            "Requirement already satisfied: nltk<3.10.0,>=3.2.4 in /usr/local/lib/python3.10/dist-packages (from deeppavlov) (3.8.1)\n",
            "Requirement already satisfied: numpy<1.24 in /usr/local/lib/python3.10/dist-packages (from deeppavlov) (1.23.5)\n",
            "Requirement already satisfied: pandas<1.6.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from deeppavlov) (1.5.3)\n",
            "Requirement already satisfied: prometheus-client<=1.16.0,>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from deeppavlov) (0.17.1)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from deeppavlov) (1.10.13)\n",
            "Requirement already satisfied: pybind11==2.10.3 in /usr/local/lib/python3.10/dist-packages (from deeppavlov) (2.10.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from deeppavlov) (2.31.0)\n",
            "Requirement already satisfied: scikit-learn<1.1.0,>=0.24 in /usr/local/lib/python3.10/dist-packages (from deeppavlov) (1.0.2)\n",
            "Requirement already satisfied: scipy<1.10.0 in /usr/local/lib/python3.10/dist-packages (from deeppavlov) (1.9.3)\n",
            "Requirement already satisfied: tqdm<4.65.0,>=4.42.0 in /usr/local/lib/python3.10/dist-packages (from deeppavlov) (4.64.1)\n",
            "Requirement already satisfied: uvicorn<0.19.0,>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from deeppavlov) (0.18.3)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from deeppavlov) (0.41.2)\n",
            "Requirement already satisfied: starlette==0.22.0 in /usr/local/lib/python3.10/dist-packages (from fastapi<=0.89.1,>=0.47.0->deeppavlov) (0.22.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette==0.22.0->fastapi<=0.89.1,>=0.47.0->deeppavlov) (3.7.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<3.10.0,>=3.2.4->deeppavlov) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<3.10.0,>=3.2.4->deeppavlov) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<3.10.0,>=3.2.4->deeppavlov) (2023.6.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<1.6.0,>=1.0.0->deeppavlov) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<1.6.0,>=1.0.0->deeppavlov) (2023.3.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->deeppavlov) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.19.0->deeppavlov) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.19.0->deeppavlov) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.19.0->deeppavlov) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.19.0->deeppavlov) (2023.7.22)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.1.0,>=0.24->deeppavlov) (3.2.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn<0.19.0,>=0.13.0->deeppavlov) (0.14.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<1.6.0,>=1.0.0->deeppavlov) (1.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette==0.22.0->fastapi<=0.89.1,>=0.47.0->deeppavlov) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette==0.22.0->fastapi<=0.89.1,>=0.47.0->deeppavlov) (1.1.3)\n"
          ]
        }
      ],
      "source": [
        "# !pip uninstall -y tensorflow tensorflow-gpu\n",
        "!pip install numpy scipy librosa unidecode inflect librosa transformers\n",
        "!pip install deeppavlov"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "A8IgqhdYEeKs",
        "outputId": "d00a0b37-f3e6-4aa6-8cf1-cae63288b97b"
      },
      "id": "A8IgqhdYEeKs",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"Единая Россия\" предложила 12 новых председателей комитетов Госдумы из своих 15. Партия \"Единая Россия\" предложила 12 новых председателей комитетов Государственной думы VI созыва из своих 15. Об этом журналистам сообщил секретарь президиума генерального совета \"Единой России\" Сергей Неверов. По его словам, на пост главы комитета по конституционному законодательству и государственному строительству предложена кандидатура Владимира Плигина (сохранил пост), комитета по гражданскому, процессуальному, уголовному и арбитражному законодательству - Павла Крашенинникова (сохранил пост), комитета по труду и социальной политики и делам ветеранов - Андрея Исаева (сохранил пост); по бюджету и налогам - Андрея Макарова, по финансовому рынку - Натальи Бурыкиной; по экономической политике, инновационному развитию и предпринимательству - Игоря Руденского; по федеративному устройству - Виктора Кидяева, по регламенту и организации работы Госдумы - Ильдара Габдрахманова, по делам национальностей - Гаджимеда Сафаралиева, по безопасности и противодействию коррупции - Ирины Яровой, по культуре - Станислава Говорухина, по аграрной политике - Николая Панкова, по образованию - Владимира Бурматова, по транспорту - Евгения Москвичева, по международным делам - Алексея Пушкова. С.Неверов подчеркнул, что шесть комитетов достанутся КПРФ, и по четыре - \"Справедливой России\" и ЛДПР.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from deeppavlov import build_model\n",
        "ner_model = build_model('ner_ontonotes_bert', download=True, install=True)\n",
        "ner_model(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bm_rhgOuBoC",
        "outputId": "d7feb80a-d954-4abc-fda6-b07e53b69754"
      },
      "id": "7bm_rhgOuBoC",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-10-16 10:42:51.762 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/v1/ner/ner_ontonotes_bert_torch_crf.tar.gz download because of matching hashes\n",
            "INFO:deeppavlov.download:Skipped http://files.deeppavlov.ai/v1/ner/ner_ontonotes_bert_torch_crf.tar.gz download because of matching hashes\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "2023-10-16 10:42:53.954 WARNING in 'deeppavlov.core.models.torch_model'['torch_model'] at line 96: Unable to place component TorchTransformersSequenceTagger on GPU, since no CUDA GPUs are available. Using CPU.\n",
            "WARNING:deeppavlov.core.models.torch_model:Unable to place component TorchTransformersSequenceTagger on GPU, since no CUDA GPUs are available. Using CPU.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[['\"'],\n",
              "  ['Е'],\n",
              "  ['д'],\n",
              "  ['и'],\n",
              "  ['н'],\n",
              "  ['а'],\n",
              "  ['я'],\n",
              "  [],\n",
              "  ['Р'],\n",
              "  ['о'],\n",
              "  ['с'],\n",
              "  ['с'],\n",
              "  ['и'],\n",
              "  ['я'],\n",
              "  ['\"'],\n",
              "  [],\n",
              "  ['п'],\n",
              "  ['р'],\n",
              "  ['е'],\n",
              "  ['д'],\n",
              "  ['л'],\n",
              "  ['о'],\n",
              "  ['ж'],\n",
              "  ['и'],\n",
              "  ['л'],\n",
              "  ['а'],\n",
              "  [],\n",
              "  ['1'],\n",
              "  ['2'],\n",
              "  [],\n",
              "  ['н'],\n",
              "  ['о'],\n",
              "  ['в'],\n",
              "  ['ы'],\n",
              "  ['х'],\n",
              "  [],\n",
              "  ['п'],\n",
              "  ['р'],\n",
              "  ['е'],\n",
              "  ['д'],\n",
              "  ['с'],\n",
              "  ['е'],\n",
              "  ['д'],\n",
              "  ['а'],\n",
              "  ['т'],\n",
              "  ['е'],\n",
              "  ['л'],\n",
              "  ['е'],\n",
              "  ['й'],\n",
              "  [],\n",
              "  ['к'],\n",
              "  ['о'],\n",
              "  ['м'],\n",
              "  ['и'],\n",
              "  ['т'],\n",
              "  ['е'],\n",
              "  ['т'],\n",
              "  ['о'],\n",
              "  ['в'],\n",
              "  [],\n",
              "  ['Г'],\n",
              "  ['о'],\n",
              "  ['с'],\n",
              "  ['д'],\n",
              "  ['у'],\n",
              "  ['м'],\n",
              "  ['ы'],\n",
              "  [],\n",
              "  ['и'],\n",
              "  ['з'],\n",
              "  [],\n",
              "  ['с'],\n",
              "  ['в'],\n",
              "  ['о'],\n",
              "  ['и'],\n",
              "  ['х'],\n",
              "  [],\n",
              "  ['1'],\n",
              "  ['5'],\n",
              "  ['.'],\n",
              "  [],\n",
              "  ['П'],\n",
              "  ['а'],\n",
              "  ['р'],\n",
              "  ['т'],\n",
              "  ['и'],\n",
              "  ['я'],\n",
              "  [],\n",
              "  ['\"'],\n",
              "  ['Е'],\n",
              "  ['д'],\n",
              "  ['и'],\n",
              "  ['н'],\n",
              "  ['а'],\n",
              "  ['я'],\n",
              "  [],\n",
              "  ['Р'],\n",
              "  ['о'],\n",
              "  ['с'],\n",
              "  ['с'],\n",
              "  ['и'],\n",
              "  ['я'],\n",
              "  ['\"'],\n",
              "  [],\n",
              "  ['п'],\n",
              "  ['р'],\n",
              "  ['е'],\n",
              "  ['д'],\n",
              "  ['л'],\n",
              "  ['о'],\n",
              "  ['ж'],\n",
              "  ['и'],\n",
              "  ['л'],\n",
              "  ['а'],\n",
              "  [],\n",
              "  ['1'],\n",
              "  ['2'],\n",
              "  [],\n",
              "  ['н'],\n",
              "  ['о'],\n",
              "  ['в'],\n",
              "  ['ы'],\n",
              "  ['х'],\n",
              "  [],\n",
              "  ['п'],\n",
              "  ['р'],\n",
              "  ['е'],\n",
              "  ['д'],\n",
              "  ['с'],\n",
              "  ['е'],\n",
              "  ['д'],\n",
              "  ['а'],\n",
              "  ['т'],\n",
              "  ['е'],\n",
              "  ['л'],\n",
              "  ['е'],\n",
              "  ['й'],\n",
              "  [],\n",
              "  ['к'],\n",
              "  ['о'],\n",
              "  ['м'],\n",
              "  ['и'],\n",
              "  ['т'],\n",
              "  ['е'],\n",
              "  ['т'],\n",
              "  ['о'],\n",
              "  ['в'],\n",
              "  [],\n",
              "  ['Г'],\n",
              "  ['о'],\n",
              "  ['с'],\n",
              "  ['у'],\n",
              "  ['д'],\n",
              "  ['а'],\n",
              "  ['р'],\n",
              "  ['с'],\n",
              "  ['т'],\n",
              "  ['в'],\n",
              "  ['е'],\n",
              "  ['н'],\n",
              "  ['н'],\n",
              "  ['о'],\n",
              "  ['й'],\n",
              "  [],\n",
              "  ['д'],\n",
              "  ['у'],\n",
              "  ['м'],\n",
              "  ['ы'],\n",
              "  [],\n",
              "  ['V'],\n",
              "  ['I'],\n",
              "  [],\n",
              "  ['с'],\n",
              "  ['о'],\n",
              "  ['з'],\n",
              "  ['ы'],\n",
              "  ['в'],\n",
              "  ['а'],\n",
              "  [],\n",
              "  ['и'],\n",
              "  ['з'],\n",
              "  [],\n",
              "  ['с'],\n",
              "  ['в'],\n",
              "  ['о'],\n",
              "  ['и'],\n",
              "  ['х'],\n",
              "  [],\n",
              "  ['1'],\n",
              "  ['5'],\n",
              "  ['.'],\n",
              "  [],\n",
              "  ['О'],\n",
              "  ['б'],\n",
              "  [],\n",
              "  ['э'],\n",
              "  ['т'],\n",
              "  ['о'],\n",
              "  ['м'],\n",
              "  [],\n",
              "  ['ж'],\n",
              "  ['у'],\n",
              "  ['р'],\n",
              "  ['н'],\n",
              "  ['а'],\n",
              "  ['л'],\n",
              "  ['и'],\n",
              "  ['с'],\n",
              "  ['т'],\n",
              "  ['а'],\n",
              "  ['м'],\n",
              "  [],\n",
              "  ['с'],\n",
              "  ['о'],\n",
              "  ['о'],\n",
              "  ['б'],\n",
              "  ['щ'],\n",
              "  ['и'],\n",
              "  ['л'],\n",
              "  [],\n",
              "  ['с'],\n",
              "  ['е'],\n",
              "  ['к'],\n",
              "  ['р'],\n",
              "  ['е'],\n",
              "  ['т'],\n",
              "  ['а'],\n",
              "  ['р'],\n",
              "  ['ь'],\n",
              "  [],\n",
              "  ['п'],\n",
              "  ['р'],\n",
              "  ['е'],\n",
              "  ['з'],\n",
              "  ['и'],\n",
              "  ['д'],\n",
              "  ['и'],\n",
              "  ['у'],\n",
              "  ['м'],\n",
              "  ['а'],\n",
              "  [],\n",
              "  ['г'],\n",
              "  ['е'],\n",
              "  ['н'],\n",
              "  ['е'],\n",
              "  ['р'],\n",
              "  ['а'],\n",
              "  ['л'],\n",
              "  ['ь'],\n",
              "  ['н'],\n",
              "  ['о'],\n",
              "  ['г'],\n",
              "  ['о'],\n",
              "  [],\n",
              "  ['с'],\n",
              "  ['о'],\n",
              "  ['в'],\n",
              "  ['е'],\n",
              "  ['т'],\n",
              "  ['а'],\n",
              "  [],\n",
              "  ['\"'],\n",
              "  ['Е'],\n",
              "  ['д'],\n",
              "  ['и'],\n",
              "  ['н'],\n",
              "  ['о'],\n",
              "  ['й'],\n",
              "  [],\n",
              "  ['Р'],\n",
              "  ['о'],\n",
              "  ['с'],\n",
              "  ['с'],\n",
              "  ['и'],\n",
              "  ['и'],\n",
              "  ['\"'],\n",
              "  [],\n",
              "  ['С'],\n",
              "  ['е'],\n",
              "  ['р'],\n",
              "  ['г'],\n",
              "  ['е'],\n",
              "  ['й'],\n",
              "  [],\n",
              "  ['Н'],\n",
              "  ['е'],\n",
              "  ['в'],\n",
              "  ['е'],\n",
              "  ['р'],\n",
              "  ['о'],\n",
              "  ['в'],\n",
              "  ['.'],\n",
              "  [],\n",
              "  ['П'],\n",
              "  ['о'],\n",
              "  [],\n",
              "  ['е'],\n",
              "  ['г'],\n",
              "  ['о'],\n",
              "  [],\n",
              "  ['с'],\n",
              "  ['л'],\n",
              "  ['о'],\n",
              "  ['в'],\n",
              "  ['а'],\n",
              "  ['м'],\n",
              "  [','],\n",
              "  [],\n",
              "  ['н'],\n",
              "  ['а'],\n",
              "  [],\n",
              "  ['п'],\n",
              "  ['о'],\n",
              "  ['с'],\n",
              "  ['т'],\n",
              "  [],\n",
              "  ['г'],\n",
              "  ['л'],\n",
              "  ['а'],\n",
              "  ['в'],\n",
              "  ['ы'],\n",
              "  [],\n",
              "  ['к'],\n",
              "  ['о'],\n",
              "  ['м'],\n",
              "  ['и'],\n",
              "  ['т'],\n",
              "  ['е'],\n",
              "  ['т'],\n",
              "  ['а'],\n",
              "  [],\n",
              "  ['п'],\n",
              "  ['о'],\n",
              "  [],\n",
              "  ['к'],\n",
              "  ['о'],\n",
              "  ['н'],\n",
              "  ['с'],\n",
              "  ['т'],\n",
              "  ['и'],\n",
              "  ['т'],\n",
              "  ['у'],\n",
              "  ['ц'],\n",
              "  ['и'],\n",
              "  ['о'],\n",
              "  ['н'],\n",
              "  ['н'],\n",
              "  ['о'],\n",
              "  ['м'],\n",
              "  ['у'],\n",
              "  [],\n",
              "  ['з'],\n",
              "  ['а'],\n",
              "  ['к'],\n",
              "  ['о'],\n",
              "  ['н'],\n",
              "  ['о'],\n",
              "  ['д'],\n",
              "  ['а'],\n",
              "  ['т'],\n",
              "  ['е'],\n",
              "  ['л'],\n",
              "  ['ь'],\n",
              "  ['с'],\n",
              "  ['т'],\n",
              "  ['в'],\n",
              "  ['у'],\n",
              "  [],\n",
              "  ['и'],\n",
              "  [],\n",
              "  ['г'],\n",
              "  ['о'],\n",
              "  ['с'],\n",
              "  ['у'],\n",
              "  ['д'],\n",
              "  ['а'],\n",
              "  ['р'],\n",
              "  ['с'],\n",
              "  ['т'],\n",
              "  ['в'],\n",
              "  ['е'],\n",
              "  ['н'],\n",
              "  ['н'],\n",
              "  ['о'],\n",
              "  ['м'],\n",
              "  ['у'],\n",
              "  [],\n",
              "  ['с'],\n",
              "  ['т'],\n",
              "  ['р'],\n",
              "  ['о'],\n",
              "  ['и'],\n",
              "  ['т'],\n",
              "  ['е'],\n",
              "  ['л'],\n",
              "  ['ь'],\n",
              "  ['с'],\n",
              "  ['т'],\n",
              "  ['в'],\n",
              "  ['у'],\n",
              "  [],\n",
              "  ['п'],\n",
              "  ['р'],\n",
              "  ['е'],\n",
              "  ['д'],\n",
              "  ['л'],\n",
              "  ['о'],\n",
              "  ['ж'],\n",
              "  ['е'],\n",
              "  ['н'],\n",
              "  ['а'],\n",
              "  [],\n",
              "  ['к'],\n",
              "  ['а'],\n",
              "  ['н'],\n",
              "  ['д'],\n",
              "  ['и'],\n",
              "  ['д'],\n",
              "  ['а'],\n",
              "  ['т'],\n",
              "  ['у'],\n",
              "  ['р'],\n",
              "  ['а'],\n",
              "  [],\n",
              "  ['В'],\n",
              "  ['л'],\n",
              "  ['а'],\n",
              "  ['д'],\n",
              "  ['и'],\n",
              "  ['м'],\n",
              "  ['и'],\n",
              "  ['р'],\n",
              "  ['а'],\n",
              "  [],\n",
              "  ['П'],\n",
              "  ['л'],\n",
              "  ['и'],\n",
              "  ['г'],\n",
              "  ['и'],\n",
              "  ['н'],\n",
              "  ['а'],\n",
              "  [],\n",
              "  ['('],\n",
              "  ['с'],\n",
              "  ['о'],\n",
              "  ['х'],\n",
              "  ['р'],\n",
              "  ['а'],\n",
              "  ['н'],\n",
              "  ['и'],\n",
              "  ['л'],\n",
              "  [],\n",
              "  ['п'],\n",
              "  ['о'],\n",
              "  ['с'],\n",
              "  ['т'],\n",
              "  [')'],\n",
              "  [','],\n",
              "  [],\n",
              "  ['к'],\n",
              "  ['о'],\n",
              "  ['м'],\n",
              "  ['и'],\n",
              "  ['т'],\n",
              "  ['е'],\n",
              "  ['т'],\n",
              "  ['а'],\n",
              "  [],\n",
              "  ['п'],\n",
              "  ['о'],\n",
              "  [],\n",
              "  ['г'],\n",
              "  ['р'],\n",
              "  ['а'],\n",
              "  ['ж'],\n",
              "  ['д'],\n",
              "  ['а'],\n",
              "  ['н'],\n",
              "  ['с'],\n",
              "  ['к'],\n",
              "  ['о'],\n",
              "  ['м'],\n",
              "  ['у'],\n",
              "  [','],\n",
              "  [],\n",
              "  ['п'],\n",
              "  ['р'],\n",
              "  ['о'],\n",
              "  ['ц'],\n",
              "  ['е'],\n",
              "  ['с'],\n",
              "  ['с'],\n",
              "  ['у'],\n",
              "  ['а'],\n",
              "  ['л'],\n",
              "  ['ь'],\n",
              "  ['н'],\n",
              "  ['о'],\n",
              "  ['м'],\n",
              "  ['у'],\n",
              "  [','],\n",
              "  [],\n",
              "  ['у'],\n",
              "  ['г'],\n",
              "  ['о'],\n",
              "  ['л'],\n",
              "  ['о'],\n",
              "  ['в'],\n",
              "  ['н'],\n",
              "  ['о'],\n",
              "  ['м'],\n",
              "  ['у'],\n",
              "  [],\n",
              "  ['и'],\n",
              "  [],\n",
              "  ['а'],\n",
              "  ['р'],\n",
              "  ['б'],\n",
              "  ['и'],\n",
              "  ['т'],\n",
              "  ['р'],\n",
              "  ['а'],\n",
              "  ['ж'],\n",
              "  ['н'],\n",
              "  ['о'],\n",
              "  ['м'],\n",
              "  ['у'],\n",
              "  [],\n",
              "  ['з'],\n",
              "  ['а'],\n",
              "  ['к'],\n",
              "  ['о'],\n",
              "  ['н'],\n",
              "  ['о'],\n",
              "  ['д'],\n",
              "  ['а'],\n",
              "  ['т'],\n",
              "  ['е'],\n",
              "  ['л'],\n",
              "  ['ь'],\n",
              "  ['с'],\n",
              "  ['т'],\n",
              "  ['в'],\n",
              "  ['у'],\n",
              "  [],\n",
              "  ['-'],\n",
              "  [],\n",
              "  ['П'],\n",
              "  ['а'],\n",
              "  ['в'],\n",
              "  ['л'],\n",
              "  ['а'],\n",
              "  [],\n",
              "  ['К'],\n",
              "  ['р'],\n",
              "  ['а'],\n",
              "  ['ш'],\n",
              "  ['е'],\n",
              "  ['н'],\n",
              "  ['и'],\n",
              "  ['н'],\n",
              "  ['н'],\n",
              "  ['и'],\n",
              "  ['к'],\n",
              "  ['о'],\n",
              "  ['в'],\n",
              "  ['а'],\n",
              "  [],\n",
              "  ['('],\n",
              "  ['с'],\n",
              "  ['о'],\n",
              "  ['х'],\n",
              "  ['р'],\n",
              "  ['а'],\n",
              "  ['н'],\n",
              "  ['и'],\n",
              "  ['л'],\n",
              "  [],\n",
              "  ['п'],\n",
              "  ['о'],\n",
              "  ['с'],\n",
              "  ['т'],\n",
              "  [')'],\n",
              "  [','],\n",
              "  [],\n",
              "  ['к'],\n",
              "  ['о'],\n",
              "  ['м'],\n",
              "  ['и'],\n",
              "  ['т'],\n",
              "  ['е'],\n",
              "  ['т'],\n",
              "  ['а'],\n",
              "  [],\n",
              "  ['п'],\n",
              "  ['о'],\n",
              "  [],\n",
              "  ['т'],\n",
              "  ['р'],\n",
              "  ['у'],\n",
              "  ['д'],\n",
              "  ['у'],\n",
              "  [],\n",
              "  ['и'],\n",
              "  [],\n",
              "  ['с'],\n",
              "  ['о'],\n",
              "  ['ц'],\n",
              "  ['и'],\n",
              "  ['а'],\n",
              "  ['л'],\n",
              "  ['ь'],\n",
              "  ['н'],\n",
              "  ['о'],\n",
              "  ['й'],\n",
              "  [],\n",
              "  ['п'],\n",
              "  ['о'],\n",
              "  ['л'],\n",
              "  ['и'],\n",
              "  ['т'],\n",
              "  ['и'],\n",
              "  ['к'],\n",
              "  ['и'],\n",
              "  [],\n",
              "  ['и'],\n",
              "  [],\n",
              "  ['д'],\n",
              "  ['е'],\n",
              "  ['л'],\n",
              "  ['а'],\n",
              "  ['м'],\n",
              "  [],\n",
              "  ['в'],\n",
              "  ['е'],\n",
              "  ['т'],\n",
              "  ['е'],\n",
              "  ['р'],\n",
              "  ['а'],\n",
              "  ['н'],\n",
              "  ['о'],\n",
              "  ['в'],\n",
              "  [],\n",
              "  ['-'],\n",
              "  [],\n",
              "  ['А'],\n",
              "  ['н'],\n",
              "  ['д'],\n",
              "  ['р'],\n",
              "  ['е'],\n",
              "  ['я'],\n",
              "  [],\n",
              "  ['И'],\n",
              "  ['с'],\n",
              "  ['а'],\n",
              "  ['е'],\n",
              "  ['в'],\n",
              "  ['а'],\n",
              "  [],\n",
              "  ['('],\n",
              "  ['с'],\n",
              "  ['о'],\n",
              "  ['х'],\n",
              "  ['р'],\n",
              "  ['а'],\n",
              "  ['н'],\n",
              "  ['и'],\n",
              "  ['л'],\n",
              "  [],\n",
              "  ['п'],\n",
              "  ['о'],\n",
              "  ['с'],\n",
              "  ['т'],\n",
              "  [')'],\n",
              "  [';'],\n",
              "  [],\n",
              "  ['п'],\n",
              "  ['о'],\n",
              "  [],\n",
              "  ['б'],\n",
              "  ['ю'],\n",
              "  ['д'],\n",
              "  ['ж'],\n",
              "  ['е'],\n",
              "  ['т'],\n",
              "  ['у'],\n",
              "  [],\n",
              "  ['и'],\n",
              "  [],\n",
              "  ['н'],\n",
              "  ['а'],\n",
              "  ['л'],\n",
              "  ['о'],\n",
              "  ['г'],\n",
              "  ['а'],\n",
              "  ['м'],\n",
              "  [],\n",
              "  ['-'],\n",
              "  [],\n",
              "  ['А'],\n",
              "  ['н'],\n",
              "  ['д'],\n",
              "  ['р'],\n",
              "  ['е'],\n",
              "  ['я'],\n",
              "  [],\n",
              "  ['М'],\n",
              "  ['а'],\n",
              "  ['к'],\n",
              "  ['а'],\n",
              "  ['р'],\n",
              "  ['о'],\n",
              "  ['в'],\n",
              "  ['а'],\n",
              "  [','],\n",
              "  [],\n",
              "  ['п'],\n",
              "  ['о'],\n",
              "  [],\n",
              "  ['ф'],\n",
              "  ['и'],\n",
              "  ['н'],\n",
              "  ['а'],\n",
              "  ['н'],\n",
              "  ['с'],\n",
              "  ['о'],\n",
              "  ['в'],\n",
              "  ['о'],\n",
              "  ['м'],\n",
              "  ['у'],\n",
              "  [],\n",
              "  ['р'],\n",
              "  ['ы'],\n",
              "  ['н'],\n",
              "  ['к'],\n",
              "  ['у'],\n",
              "  [],\n",
              "  ['-'],\n",
              "  [],\n",
              "  ['Н'],\n",
              "  ['а'],\n",
              "  ['т'],\n",
              "  ['а'],\n",
              "  ['л'],\n",
              "  ['ь'],\n",
              "  ['и'],\n",
              "  [],\n",
              "  ['Б'],\n",
              "  ['у'],\n",
              "  ['р'],\n",
              "  ['ы'],\n",
              "  ['к'],\n",
              "  ['и'],\n",
              "  ['н'],\n",
              "  ['о'],\n",
              "  ['й'],\n",
              "  [';'],\n",
              "  [],\n",
              "  ['п'],\n",
              "  ['о'],\n",
              "  [],\n",
              "  ['э'],\n",
              "  ['к'],\n",
              "  ['о'],\n",
              "  ['н'],\n",
              "  ['о'],\n",
              "  ['м'],\n",
              "  ['и'],\n",
              "  ['ч'],\n",
              "  ['е'],\n",
              "  ['с'],\n",
              "  ['к'],\n",
              "  ['о'],\n",
              "  ['й'],\n",
              "  [],\n",
              "  ['п'],\n",
              "  ['о'],\n",
              "  ['л'],\n",
              "  ['и'],\n",
              "  ['т'],\n",
              "  ['и'],\n",
              "  ['к'],\n",
              "  ['е'],\n",
              "  [','],\n",
              "  [],\n",
              "  ['и'],\n",
              "  ['н'],\n",
              "  ['н'],\n",
              "  ['о'],\n",
              "  ['в'],\n",
              "  ['а'],\n",
              "  ['ц'],\n",
              "  ['и'],\n",
              "  ['о'],\n",
              "  ['н'],\n",
              "  ['н'],\n",
              "  ['о'],\n",
              "  ['м'],\n",
              "  ['у'],\n",
              "  [],\n",
              "  ['р'],\n",
              "  ['а'],\n",
              "  ['з'],\n",
              "  ['в'],\n",
              "  ['и'],\n",
              "  ['т'],\n",
              "  ['и'],\n",
              "  ['ю'],\n",
              "  [],\n",
              "  ['и'],\n",
              "  [],\n",
              "  ['п'],\n",
              "  ['р'],\n",
              "  ['е'],\n",
              "  ['д'],\n",
              "  ['п'],\n",
              "  ['р'],\n",
              "  ['и'],\n",
              "  ['н'],\n",
              "  ['и'],\n",
              "  ['м'],\n",
              "  ['а'],\n",
              "  ['т'],\n",
              "  ['е'],\n",
              "  ['л'],\n",
              "  ['ь'],\n",
              "  ['с'],\n",
              "  ['т'],\n",
              "  ['в'],\n",
              "  ['у'],\n",
              "  [],\n",
              "  ['-'],\n",
              "  [],\n",
              "  ['И'],\n",
              "  ['г'],\n",
              "  ['о'],\n",
              "  ['р'],\n",
              "  ['я'],\n",
              "  [],\n",
              "  ['Р'],\n",
              "  ['у'],\n",
              "  ['д'],\n",
              "  ['е'],\n",
              "  ['н'],\n",
              "  ['с'],\n",
              "  ['к'],\n",
              "  ['о'],\n",
              "  ['г'],\n",
              "  ['о'],\n",
              "  [';'],\n",
              "  [],\n",
              "  ['п'],\n",
              "  ['о'],\n",
              "  [],\n",
              "  ['ф'],\n",
              "  ['е'],\n",
              "  ['д'],\n",
              "  ['е'],\n",
              "  ['р'],\n",
              "  ['а'],\n",
              "  ['т'],\n",
              "  ['и'],\n",
              "  ['в'],\n",
              "  ['н'],\n",
              "  ['о'],\n",
              "  ['м'],\n",
              "  ['у'],\n",
              "  [],\n",
              "  ['у'],\n",
              "  ['с'],\n",
              "  ['т'],\n",
              "  ['р'],\n",
              "  ['о'],\n",
              "  ['й'],\n",
              "  ['с'],\n",
              "  ['т'],\n",
              "  ['в'],\n",
              "  ['у'],\n",
              "  [],\n",
              "  ['-'],\n",
              "  [],\n",
              "  ['В'],\n",
              "  ['и'],\n",
              "  ['к'],\n",
              "  ['т'],\n",
              "  ['о'],\n",
              "  ['р'],\n",
              "  ['а'],\n",
              "  [],\n",
              "  ['К'],\n",
              "  ['и'],\n",
              "  ['д'],\n",
              "  ['я'],\n",
              "  ['е'],\n",
              "  ['в'],\n",
              "  ['а'],\n",
              "  [','],\n",
              "  [],\n",
              "  ['п'],\n",
              "  ['о'],\n",
              "  [],\n",
              "  ['р'],\n",
              "  ['е'],\n",
              "  ['г'],\n",
              "  ['л'],\n",
              "  ['а'],\n",
              "  ['м'],\n",
              "  ['е'],\n",
              "  ['н'],\n",
              "  ['т'],\n",
              "  ['у'],\n",
              "  [],\n",
              "  ['и'],\n",
              "  [],\n",
              "  ['о'],\n",
              "  ['р'],\n",
              "  ['г'],\n",
              "  ['а'],\n",
              "  ['н'],\n",
              "  ['и'],\n",
              "  ['з'],\n",
              "  ['а'],\n",
              "  ['ц'],\n",
              "  ['и'],\n",
              "  ['и'],\n",
              "  [],\n",
              "  ['р'],\n",
              "  ['а'],\n",
              "  ['б'],\n",
              "  ['о'],\n",
              "  ['т'],\n",
              "  ['ы'],\n",
              "  [],\n",
              "  ['Г'],\n",
              "  ['о'],\n",
              "  ['с'],\n",
              "  ['д'],\n",
              "  ['у'],\n",
              "  ['м'],\n",
              "  ['ы'],\n",
              "  [],\n",
              "  ['-'],\n",
              "  [],\n",
              "  ['И'],\n",
              "  ['л'],\n",
              "  ['ь'],\n",
              "  ['д'],\n",
              "  ['а'],\n",
              "  ['р'],\n",
              "  ['а'],\n",
              "  [],\n",
              "  ['Г'],\n",
              "  ['а'],\n",
              "  ['б'],\n",
              "  ['д'],\n",
              "  ['р'],\n",
              "  ['а'],\n",
              "  ['х'],\n",
              "  ['м'],\n",
              "  ['а'],\n",
              "  ['н'],\n",
              "  ['о'],\n",
              "  ['в'],\n",
              "  ['а'],\n",
              "  [','],\n",
              "  [],\n",
              "  ['п'],\n",
              "  ['о'],\n",
              "  [],\n",
              "  ['д'],\n",
              "  ['е'],\n",
              "  ['л'],\n",
              "  ['а'],\n",
              "  ['м'],\n",
              "  [],\n",
              "  ['н'],\n",
              "  ['а'],\n",
              "  ['ц'],\n",
              "  ['и'],\n",
              "  ['о'],\n",
              "  ['н'],\n",
              "  ['а'],\n",
              "  ['л'],\n",
              "  ['ь'],\n",
              "  ['н'],\n",
              "  ['о'],\n",
              "  ['с'],\n",
              "  ['т'],\n",
              "  ['е'],\n",
              "  ['й'],\n",
              "  [],\n",
              "  ['-'],\n",
              "  [],\n",
              "  ['Г'],\n",
              "  ['а'],\n",
              "  ['д'],\n",
              "  ['ж'],\n",
              "  ['и'],\n",
              "  ['м'],\n",
              "  ['е'],\n",
              "  ...],\n",
              " [['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['B-CARDINAL'],\n",
              "  ['B-CARDINAL'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['B-CARDINAL'],\n",
              "  ['B-CARDINAL'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['B-CARDINAL'],\n",
              "  ['B-CARDINAL'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['B-CARDINAL'],\n",
              "  ['B-CARDINAL'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  [],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ['O'],\n",
              "  ...]]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db417380",
      "metadata": {
        "id": "db417380"
      },
      "source": [
        "**Написать свой NER**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "fab90252",
      "metadata": {
        "id": "fab90252"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report,f1_score, accuracy_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "from tensorflow.keras.layers import GlobalMaxPooling1D, Conv1D, GRU, LSTM, Dropout, Input\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "from razdel import tokenize\n",
        "from corus import load_ne5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "415bd60b",
      "metadata": {
        "id": "415bd60b"
      },
      "outputs": [],
      "source": [
        "def get_classification_report(y_test_true, y_test_pred):\n",
        "    print(classification_report(y_test_true, y_test_pred))\n",
        "\n",
        "    print('CONFUSION MATRIX\\n')\n",
        "    print(pd.crosstab(y_test_true, y_test_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f736e89",
      "metadata": {
        "id": "8f736e89"
      },
      "source": [
        "Воспользуемся размеченным корпусом текстов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "ce1caafa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce1caafa",
        "outputId": "4ecdd81f-4b8c-4ada-8b0d-37f289c7eb70"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ne5Markup(\n",
              "    id='487',\n",
              "    text='\"Единая Россия\" предложила 12 новых председателей комитетов Госдумы из своих 15.\\r\\n\\r\\nПартия \"Единая Россия\" предложила 12 новых председателей комитетов Государственной думы VI созыва из своих 15. Об этом журналистам сообщил секретарь президиума генерального совета \"Единой России\" Сергей Неверов.\\r\\n\\r\\nПо его словам, на пост главы комитета по конституционному законодательству и государственному строительству предложена кандидатура Владимира Плигина (сохранил пост), комитета по гражданскому, процессуальному, уголовному и арбитражному законодательству - Павла Крашенинникова (сохранил пост), комитета по труду и социальной политики и делам ветеранов - Андрея Исаева (сохранил пост); по бюджету и налогам - Андрея Макарова, по финансовому рынку - Натальи Бурыкиной; по экономической политике, инновационному развитию и предпринимательству - Игоря Руденского; по федеративному устройству - Виктора Кидяева, по регламенту и организации работы Госдумы - Ильдара Габдрахманова, по делам национальностей - Гаджимеда Сафаралиева, по безопасности и противодействию коррупции - Ирины Яровой, по культуре - Станислава Говорухина, по аграрной политике - Николая Панкова, по образованию - Владимира Бурматова, по транспорту - Евгения Москвичева, по международным делам - Алексея Пушкова.\\r\\n\\r\\nС.Неверов подчеркнул, что шесть комитетов достанутся КПРФ, и по четыре - \"Справедливой России\" и ЛДПР.',\n",
              "    spans=[Ne5Span(\n",
              "         index='T1',\n",
              "         type='ORG',\n",
              "         start=1,\n",
              "         stop=14,\n",
              "         text='Единая Россия'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T2',\n",
              "         type='ORG',\n",
              "         start=60,\n",
              "         stop=67,\n",
              "         text='Госдумы'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T3',\n",
              "         type='ORG',\n",
              "         start=92,\n",
              "         stop=105,\n",
              "         text='Единая Россия'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T4',\n",
              "         type='ORG',\n",
              "         start=151,\n",
              "         stop=171,\n",
              "         text='Государственной думы'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T5',\n",
              "         type='ORG',\n",
              "         start=265,\n",
              "         stop=278,\n",
              "         text='Единой России'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T6',\n",
              "         type='PER',\n",
              "         start=280,\n",
              "         stop=294,\n",
              "         text='Сергей Неверов'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T7',\n",
              "         type='PER',\n",
              "         start=430,\n",
              "         stop=447,\n",
              "         text='Владимира Плигина'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T8',\n",
              "         type='PER',\n",
              "         start=553,\n",
              "         stop=573,\n",
              "         text='Павла Крашенинникова'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T9',\n",
              "         type='PER',\n",
              "         start=651,\n",
              "         stop=664,\n",
              "         text='Андрея Исаева'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T10',\n",
              "         type='PER',\n",
              "         start=705,\n",
              "         stop=720,\n",
              "         text='Андрея Макарова'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T11',\n",
              "         type='PER',\n",
              "         start=745,\n",
              "         stop=762,\n",
              "         text='Натальи Бурыкиной'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T12',\n",
              "         type='PER',\n",
              "         start=839,\n",
              "         stop=855,\n",
              "         text='Игоря Руденского'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T13',\n",
              "         type='PER',\n",
              "         start=887,\n",
              "         stop=902,\n",
              "         text='Виктора Кидяева'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T14',\n",
              "         type='ORG',\n",
              "         start=939,\n",
              "         stop=946,\n",
              "         text='Госдумы'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T15',\n",
              "         type='PER',\n",
              "         start=949,\n",
              "         stop=970,\n",
              "         text='Ильдара Габдрахманова'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T16',\n",
              "         type='PER',\n",
              "         start=999,\n",
              "         stop=1020,\n",
              "         text='Гаджимеда Сафаралиева'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T17',\n",
              "         type='PER',\n",
              "         start=1068,\n",
              "         stop=1080,\n",
              "         text='Ирины Яровой'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T18',\n",
              "         type='PER',\n",
              "         start=1096,\n",
              "         stop=1117,\n",
              "         text='Станислава Говорухина'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T19',\n",
              "         type='PER',\n",
              "         start=1142,\n",
              "         stop=1157,\n",
              "         text='Николая Панкова'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T20',\n",
              "         type='PER',\n",
              "         start=1176,\n",
              "         stop=1195,\n",
              "         text='Владимира Бурматова'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T21',\n",
              "         type='PER',\n",
              "         start=1213,\n",
              "         stop=1231,\n",
              "         text='Евгения Москвичева'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T22',\n",
              "         type='PER',\n",
              "         start=1258,\n",
              "         stop=1273,\n",
              "         text='Алексея Пушкова'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T23',\n",
              "         type='PER',\n",
              "         start=1278,\n",
              "         stop=1287,\n",
              "         text='С.Неверов'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T24',\n",
              "         type='ORG',\n",
              "         start=1331,\n",
              "         stop=1335,\n",
              "         text='КПРФ'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T25',\n",
              "         type='ORG',\n",
              "         start=1352,\n",
              "         stop=1371,\n",
              "         text='Справедливой России'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T26',\n",
              "         type='ORG',\n",
              "         start=1375,\n",
              "         stop=1379,\n",
              "         text='ЛДПР'\n",
              "     )]\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "records = load_ne5('Collection5/')\n",
        "next(records)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "d37687b8",
      "metadata": {
        "id": "d37687b8"
      },
      "outputs": [],
      "source": [
        "words_docs = []\n",
        "for ix, rec in enumerate(records):\n",
        "    words = []\n",
        "    for token in tokenize(rec.text):\n",
        "        type_ent = 'OUT'\n",
        "        for ent in rec.spans:\n",
        "            if (token.start >= ent.start) and (token.stop <= ent.stop):\n",
        "                type_ent = ent.type\n",
        "                break\n",
        "        words.append([token.text, type_ent])\n",
        "    words_docs.extend(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "a673c399",
      "metadata": {
        "id": "a673c399"
      },
      "outputs": [],
      "source": [
        "df_words = pd.DataFrame(words_docs, columns=['word', 'tag'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "b10753c1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b10753c1",
        "outputId": "e94ca4c1-3884-4a4f-d738-3da7e3a723ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OUT         219044\n",
              "PER          21165\n",
              "ORG          13637\n",
              "LOC           4568\n",
              "GEOPOLIT      4356\n",
              "MEDIA         2482\n",
              "Name: tag, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "df_words['tag'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "73629a93",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "73629a93",
        "outputId": "2cf051ab-25d1-4ac4-8319-3061e7110079"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         word       tag\n",
              "0   Оппозиция       OUT\n",
              "1    обвинила       OUT\n",
              "2  президента       OUT\n",
              "3      Египта  GEOPOLIT\n",
              "4           в       OUT"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-85287c8d-3f4f-4df3-842b-04a2c457f913\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Оппозиция</td>\n",
              "      <td>OUT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>обвинила</td>\n",
              "      <td>OUT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>президента</td>\n",
              "      <td>OUT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Египта</td>\n",
              "      <td>GEOPOLIT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>в</td>\n",
              "      <td>OUT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85287c8d-3f4f-4df3-842b-04a2c457f913')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-85287c8d-3f4f-4df3-842b-04a2c457f913 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-85287c8d-3f4f-4df3-842b-04a2c457f913');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3dccfca4-ac1c-4aa3-8e85-97cf57d14baf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3dccfca4-ac1c-4aa3-8e85-97cf57d14baf')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3dccfca4-ac1c-4aa3-8e85-97cf57d14baf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "df_words.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "5ba950f8",
      "metadata": {
        "id": "5ba950f8"
      },
      "outputs": [],
      "source": [
        "from sklearn import model_selection, preprocessing, linear_model\n",
        "\n",
        "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(df_words['word'], df_words['tag'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22ce0fc0",
      "metadata": {
        "id": "22ce0fc0"
      },
      "source": [
        "**Закодируем целевую переменную**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "6f1c0863",
      "metadata": {
        "id": "6f1c0863"
      },
      "outputs": [],
      "source": [
        "encoder = preprocessing.LabelEncoder()\n",
        "train_y = encoder.fit_transform(train_y)\n",
        "valid_y = encoder.fit_transform(valid_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07e95132",
      "metadata": {
        "id": "07e95132"
      },
      "source": [
        "Посмотрим на классы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "b02d77ef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b02d77ef",
        "outputId": "00eb8cd8-92ca-4b20-cf0f-61d94897bec8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['GEOPOLIT', 'LOC', 'MEDIA', 'ORG', 'OUT', 'PER'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "encoder.classes_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "442df467",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "442df467",
        "outputId": "cbfa7ea0-d7bd-432a-9725-e4ac3363a3a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "train_x.apply(len).max(axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "db388c05",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db388c05",
        "outputId": "ed98f8b5-eb7d-4a83-e2c9-8ed595743aac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "175295               С\n",
              "45229                с\n",
              "200532              из\n",
              "63124           Вадиму\n",
              "2919       инициативой\n",
              "              ...     \n",
              "113609               -\n",
              "214226     организаций\n",
              "23602              При\n",
              "56684     департамента\n",
              "166825           будут\n",
              "Name: word, Length: 66313, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "valid_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "d48a289c",
      "metadata": {
        "id": "d48a289c"
      },
      "outputs": [],
      "source": [
        "train_data = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
        "valid_data = tf.data.Dataset.from_tensor_slices((valid_x, valid_y))\n",
        "\n",
        "train_data = train_data.batch(16)\n",
        "valid_data = valid_data.batch(16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "e300a2eb",
      "metadata": {
        "id": "e300a2eb"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "train_data = train_data.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "valid_data = valid_data.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "5a283f69",
      "metadata": {
        "id": "5a283f69"
      },
      "outputs": [],
      "source": [
        "def custom_standardization(input_data):\n",
        "    # Здесь может быть предобработка текста\n",
        "    return input_data\n",
        "\n",
        "vocab_size = 30000\n",
        "seq_len = 10\n",
        "\n",
        "vectorize_layer = TextVectorization(\n",
        "                            standardize=custom_standardization,\n",
        "                            max_tokens=vocab_size,\n",
        "                            output_mode='int',\n",
        "                            #ngrams=(1, 3),\n",
        "                            output_sequence_length=seq_len)\n",
        "\n",
        "# Make a text-only dataset (no labels) and call adapt to build the vocabulary.\n",
        "text_data = train_data.map(lambda x, y: x)\n",
        "vectorize_layer.adapt(text_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "63599c7d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63599c7d",
        "outputId": "94a6761e-f013-4680-ccdd-27d2438b392f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29941"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "len(vectorize_layer.get_vocabulary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "3dd0b8a4",
      "metadata": {
        "id": "3dd0b8a4"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 64\n",
        "\n",
        "class modelNER(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(modelNER, self).__init__()\n",
        "        self.emb = Embedding(vocab_size, embedding_dim)\n",
        "        self.gPool = GlobalMaxPooling1D()\n",
        "        self.fc1 = Dense(300, activation='relu')\n",
        "        self.fc2 = Dense(50, activation='relu')\n",
        "        self.fc3 = Dense(6, activation='softmax') # [OUT, PER, ORG, LOC, GEOPOLIT, MEDIA]\n",
        "\n",
        "    def call(self, x):\n",
        "        x = vectorize_layer(x)\n",
        "        x = self.emb(x)\n",
        "        pool_x = self.gPool(x)\n",
        "\n",
        "        fc_x = self.fc1(pool_x)\n",
        "        fc_x = self.fc2(fc_x)\n",
        "\n",
        "        concat_x = tf.concat([pool_x, fc_x], axis=1)\n",
        "        prob = self.fc3(concat_x)\n",
        "        return prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "c67528cb",
      "metadata": {
        "id": "c67528cb"
      },
      "outputs": [],
      "source": [
        "mmodel = modelNER()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "126922ad",
      "metadata": {
        "id": "126922ad"
      },
      "outputs": [],
      "source": [
        "mmodel.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "bd5ce01c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd5ce01c",
        "outputId": "2f2b86c9-f2af-4205-fc6c-d517397ad710"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "12434/12434 [==============================] - 148s 12ms/step - loss: 0.2950 - accuracy: 0.9144 - val_loss: 0.2060 - val_accuracy: 0.9389\n",
            "Epoch 2/3\n",
            "12434/12434 [==============================] - 140s 11ms/step - loss: 0.1257 - accuracy: 0.9625 - val_loss: 0.2392 - val_accuracy: 0.8953\n",
            "Epoch 3/3\n",
            "12434/12434 [==============================] - 137s 11ms/step - loss: 0.1096 - accuracy: 0.9653 - val_loss: 0.2705 - val_accuracy: 0.8880\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d41f4944af0>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "mmodel.fit( train_data,\n",
        "            validation_data=valid_data,\n",
        "            epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "a2c848ac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2c848ac",
        "outputId": "7ff18280-2f1f-4daf-8f82-f109074d18ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2073/2073 [==============================] - 4s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "pred_y = mmodel.predict(valid_x)\n",
        "y_pred_classes = np.argmax(pred_y,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "46e410a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46e410a0",
        "outputId": "396af099-2162-4385-e961-f36b4b757660"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9034458143947679"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "f1 = f1_score(valid_y, y_pred_classes, average= \"weighted\")\n",
        "f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "cfa441d6",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfa441d6",
        "outputId": "911ae034-e810-4106-f3e7-6b972779472e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['GEOPOLIT' 'LOC' 'MEDIA' 'ORG' 'OUT' 'PER']\r\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.91      0.90      1085\n",
            "           1       0.87      0.78      0.82      1127\n",
            "           2       0.93      0.77      0.84       619\n",
            "           3       0.30      0.68      0.42      3387\n",
            "           4       0.97      0.92      0.94     54910\n",
            "           5       0.98      0.71      0.82      5185\n",
            "\n",
            "    accuracy                           0.89     66313\n",
            "   macro avg       0.82      0.79      0.79     66313\n",
            "weighted avg       0.93      0.89      0.90     66313\n",
            "\n",
            "CONFUSION MATRIX\n",
            "\n",
            "col_0    0    1    2     3      4     5\n",
            "row_0                                  \n",
            "0      987   19    1    69      9     0\n",
            "1       19  879    3   174     50     2\n",
            "2        9    6  475    62     67     0\n",
            "3       90   29   17  2292    942    17\n",
            "4       10   75   15  4148  50600    62\n",
            "5        1    0    0   895    633  3656\n"
          ]
        }
      ],
      "source": [
        "print(f\"Classes: {encoder.classes_}\\r\\n\")\n",
        "\n",
        "get_classification_report(valid_y, y_pred_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79b3a3a1",
      "metadata": {
        "id": "79b3a3a1"
      },
      "source": [
        "#### Обучим нейронную сеть на биграммах и триграммах."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "0028eb49",
      "metadata": {
        "id": "0028eb49"
      },
      "outputs": [],
      "source": [
        "def custom_standardization(input_data):\n",
        "    # Здесь может быть предобработка текста.\n",
        "    return input_data\n",
        "\n",
        "vocab_size = 30000\n",
        "seq_len = 10\n",
        "\n",
        "vectorize_layer = TextVectorization(\n",
        "                            standardize=custom_standardization,\n",
        "                            max_tokens=vocab_size,\n",
        "                            output_mode='int',\n",
        "                            ngrams=(1, 3),\n",
        "                            output_sequence_length=seq_len)\n",
        "\n",
        "# Make a text-only dataset (no labels) and call adapt to build the vocabulary.\n",
        "text_data = train_data.map(lambda x, y: x)\n",
        "vectorize_layer.adapt(text_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "0e8bf7a0",
      "metadata": {
        "id": "0e8bf7a0"
      },
      "outputs": [],
      "source": [
        "mmodel = modelNER()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "0ee8780c",
      "metadata": {
        "id": "0ee8780c"
      },
      "outputs": [],
      "source": [
        "mmodel.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "fb7b51bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb7b51bc",
        "outputId": "53b0edd8-da23-4bc0-b31b-8bb100b8a304"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "12434/12434 [==============================] - 140s 11ms/step - loss: 0.2952 - accuracy: 0.9142 - val_loss: 0.2048 - val_accuracy: 0.9397\n",
            "Epoch 2/3\n",
            "12434/12434 [==============================] - 139s 11ms/step - loss: 0.1255 - accuracy: 0.9625 - val_loss: 0.2473 - val_accuracy: 0.8951\n",
            "Epoch 3/3\n",
            "12434/12434 [==============================] - 143s 12ms/step - loss: 0.1091 - accuracy: 0.9654 - val_loss: 0.2082 - val_accuracy: 0.9416\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d41f4053c40>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "mmodel.fit( train_data,\n",
        "            validation_data=valid_data,\n",
        "            epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "c54693eb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c54693eb",
        "outputId": "936bddd9-5462-44b1-e114-d0b1c1dad269"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2073/2073 [==============================] - 4s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "pred_y = mmodel.predict(valid_x)\n",
        "y_pred_classes = np.argmax(pred_y,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "eb0d7f81",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb0d7f81",
        "outputId": "0a714940-4526-4da8-faa6-9929758b527d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9372984811999705"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "f1 = f1_score(valid_y, y_pred_classes, average= \"weighted\")\n",
        "f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "ac196045",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac196045",
        "outputId": "d1209e8d-b477-41f8-ca74-717aaa89f7c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['GEOPOLIT' 'LOC' 'MEDIA' 'ORG' 'OUT' 'PER']\r\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.91      0.90      1085\n",
            "           1       0.87      0.78      0.82      1127\n",
            "           2       0.93      0.76      0.84       619\n",
            "           3       0.87      0.57      0.69      3387\n",
            "           4       0.94      0.99      0.97     54910\n",
            "           5       0.98      0.71      0.82      5185\n",
            "\n",
            "    accuracy                           0.94     66313\n",
            "   macro avg       0.91      0.79      0.84     66313\n",
            "weighted avg       0.94      0.94      0.94     66313\n",
            "\n",
            "CONFUSION MATRIX\n",
            "\n",
            "col_0    0    1    2     3      4     5\n",
            "row_0                                  \n",
            "0      986   23    1    27     48     0\n",
            "1       17  878    2    22    206     2\n",
            "2        9    5  473    18    114     0\n",
            "3       87   33   16  1920   1314    17\n",
            "4       10   70   16   224  54528    62\n",
            "5        1    0    0     2   1524  3658\n"
          ]
        }
      ],
      "source": [
        "print(f\"Classes: {encoder.classes_}\\r\\n\")\n",
        "\n",
        "get_classification_report(valid_y, y_pred_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db0704d0",
      "metadata": {
        "id": "db0704d0"
      },
      "source": [
        "### Результьат выше у сети, которая обучалась на N-граммах."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}